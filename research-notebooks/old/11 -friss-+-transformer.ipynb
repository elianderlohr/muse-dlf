{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Waumhn_ldoGu"
   },
   "source": [
    "## Classifier - Try 11\n",
    "\n",
    "Classify articles frames using aggregated SRL and sentence embeddings.\n",
    "\n",
    "1. Try multi attention header for better identifying how each sentence corresponds to the full article frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21919,
     "status": "ok",
     "timestamp": 1696623996213,
     "user": {
      "displayName": "Elias Anderlohr",
      "userId": "15301978580987406749"
     },
     "user_tz": -120
    },
    "id": "LM7e9jI4doGx",
    "outputId": "602ef0fa-e5fd-4626-be99-3fdef780fd4c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['README.md',\n",
       " 'notebooks',\n",
       " 'grid_search_metrics.csv',\n",
       " 'FRISS_X_srl.pkl',\n",
       " '.git',\n",
       " 'assets',\n",
       " 'test.csv',\n",
       " 'friss',\n",
       " 'models',\n",
       " '.ipynb_checkpoints',\n",
       " 'data',\n",
       " '.gitignore',\n",
       " 'frameaxis']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = \"data/data/en/train-labels-subtask-2.txt\"\n",
    "articles_path = \"data/data/en/train-articles-subtask-2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1296
    },
    "executionInfo": {
     "elapsed": 3772,
     "status": "ok",
     "timestamp": 1696624002536,
     "user": {
      "displayName": "Elias Anderlohr",
      "userId": "15301978580987406749"
     },
     "user_tz": -120
    },
    "id": "DG_Xix7gdoGy",
    "outputId": "d6fad26e-e6f7-4c20-f4bb-c7b01d51eb33",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>frames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>832959523</td>\n",
       "      <td>Morality,Security_and_defense,Policy_prescript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>833039623</td>\n",
       "      <td>Political,Crime_and_punishment,External_regula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>833032367</td>\n",
       "      <td>Political,Crime_and_punishment,Fairness_and_eq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>814777937</td>\n",
       "      <td>Political,Morality,Fairness_and_equality,Exter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>821744708</td>\n",
       "      <td>Policy_prescription_and_evaluation,Political,L...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                             frames\n",
       "0   832959523  Morality,Security_and_defense,Policy_prescript...\n",
       "1   833039623  Political,Crime_and_punishment,External_regula...\n",
       "2   833032367  Political,Crime_and_punishment,Fairness_and_eq...\n",
       "3   814777937  Political,Morality,Fairness_and_equality,Exter...\n",
       "4   821744708  Policy_prescription_and_evaluation,Political,L..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dev-labels-subtask-2.txt file\n",
    "labels_df = pd.read_csv(labels_path, sep=\"\\t\")\n",
    "\n",
    "# Rename the columns for easier processing\n",
    "labels_df.columns = [\"article_id\", \"frames\"]\n",
    "\n",
    "\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 359378,
     "status": "ok",
     "timestamp": 1696624361911,
     "user": {
      "displayName": "Elias Anderlohr",
      "userId": "15301978580987406749"
     },
     "user_tz": -120
    },
    "id": "wYeJBUyAdoGz",
    "outputId": "7bd17fad-1fda-4be9-8c66-a85f51e5f517",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>frames</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>832959523</td>\n",
       "      <td>Morality,Security_and_defense,Policy_prescript...</td>\n",
       "      <td>How Theresa May Botched\\n\\nThose were the time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>833039623</td>\n",
       "      <td>Political,Crime_and_punishment,External_regula...</td>\n",
       "      <td>Robert Mueller III Rests His Case—Dems NEVER W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>833032367</td>\n",
       "      <td>Political,Crime_and_punishment,Fairness_and_eq...</td>\n",
       "      <td>Robert Mueller Not Recommending Any More Indic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>814777937</td>\n",
       "      <td>Political,Morality,Fairness_and_equality,Exter...</td>\n",
       "      <td>The Far Right Is Trying to Co-opt the Yellow V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>821744708</td>\n",
       "      <td>Policy_prescription_and_evaluation,Political,L...</td>\n",
       "      <td>‘Special place in hell’ for those who promoted...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                             frames  \\\n",
       "0   832959523  Morality,Security_and_defense,Policy_prescript...   \n",
       "1   833039623  Political,Crime_and_punishment,External_regula...   \n",
       "2   833032367  Political,Crime_and_punishment,Fairness_and_eq...   \n",
       "3   814777937  Political,Morality,Fairness_and_equality,Exter...   \n",
       "4   821744708  Policy_prescription_and_evaluation,Political,L...   \n",
       "\n",
       "                                             content  \n",
       "0  How Theresa May Botched\\n\\nThose were the time...  \n",
       "1  Robert Mueller III Rests His Case—Dems NEVER W...  \n",
       "2  Robert Mueller Not Recommending Any More Indic...  \n",
       "3  The Far Right Is Trying to Co-opt the Yellow V...  \n",
       "4  ‘Special place in hell’ for those who promoted...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A function to read the article text given its ID\n",
    "def get_article_content(article_id):\n",
    "    try:\n",
    "        with open(f\"{articles_path}/article{article_id}.txt\", \"r\") as f:\n",
    "            return f.read()\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "\n",
    "df = labels_df\n",
    "\n",
    "# Apply the function to get the article content\n",
    "df[\"content\"] = df[\"article_id\"].apply(get_article_content)\n",
    "\n",
    "# Drop rows where content could not be found\n",
    "df.dropna(subset=[\"content\"], inplace=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1696624361912,
     "user": {
      "displayName": "Elias Anderlohr",
      "userId": "15301978580987406749"
     },
     "user_tz": -120
    },
    "id": "fU66l4twdoGz",
    "outputId": "48f06d3d-e677-4d16-dadb-aae312d25342",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>frames</th>\n",
       "      <th>content</th>\n",
       "      <th>frames_list</th>\n",
       "      <th>Morality</th>\n",
       "      <th>Security_and_defense</th>\n",
       "      <th>Policy_prescription_and_evaluation</th>\n",
       "      <th>Legality_Constitutionality_and_jurisprudence</th>\n",
       "      <th>Economic</th>\n",
       "      <th>Political</th>\n",
       "      <th>Crime_and_punishment</th>\n",
       "      <th>External_regulation_and_reputation</th>\n",
       "      <th>Public_opinion</th>\n",
       "      <th>Fairness_and_equality</th>\n",
       "      <th>Capacity_and_resources</th>\n",
       "      <th>Quality_of_life</th>\n",
       "      <th>Cultural_identity</th>\n",
       "      <th>Health_and_safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>832959523</td>\n",
       "      <td>Morality,Security_and_defense,Policy_prescript...</td>\n",
       "      <td>How Theresa May Botched\\n\\nThose were the time...</td>\n",
       "      <td>[Morality, Security_and_defense, Policy_prescr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>833039623</td>\n",
       "      <td>Political,Crime_and_punishment,External_regula...</td>\n",
       "      <td>Robert Mueller III Rests His Case—Dems NEVER W...</td>\n",
       "      <td>[Political, Crime_and_punishment, External_reg...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>833032367</td>\n",
       "      <td>Political,Crime_and_punishment,Fairness_and_eq...</td>\n",
       "      <td>Robert Mueller Not Recommending Any More Indic...</td>\n",
       "      <td>[Political, Crime_and_punishment, Fairness_and...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>814777937</td>\n",
       "      <td>Political,Morality,Fairness_and_equality,Exter...</td>\n",
       "      <td>The Far Right Is Trying to Co-opt the Yellow V...</td>\n",
       "      <td>[Political, Morality, Fairness_and_equality, E...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>821744708</td>\n",
       "      <td>Policy_prescription_and_evaluation,Political,L...</td>\n",
       "      <td>‘Special place in hell’ for those who promoted...</td>\n",
       "      <td>[Policy_prescription_and_evaluation, Political...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                             frames  \\\n",
       "0   832959523  Morality,Security_and_defense,Policy_prescript...   \n",
       "1   833039623  Political,Crime_and_punishment,External_regula...   \n",
       "2   833032367  Political,Crime_and_punishment,Fairness_and_eq...   \n",
       "3   814777937  Political,Morality,Fairness_and_equality,Exter...   \n",
       "4   821744708  Policy_prescription_and_evaluation,Political,L...   \n",
       "\n",
       "                                             content  \\\n",
       "0  How Theresa May Botched\\n\\nThose were the time...   \n",
       "1  Robert Mueller III Rests His Case—Dems NEVER W...   \n",
       "2  Robert Mueller Not Recommending Any More Indic...   \n",
       "3  The Far Right Is Trying to Co-opt the Yellow V...   \n",
       "4  ‘Special place in hell’ for those who promoted...   \n",
       "\n",
       "                                         frames_list  Morality  \\\n",
       "0  [Morality, Security_and_defense, Policy_prescr...         1   \n",
       "1  [Political, Crime_and_punishment, External_reg...         0   \n",
       "2  [Political, Crime_and_punishment, Fairness_and...         0   \n",
       "3  [Political, Morality, Fairness_and_equality, E...         1   \n",
       "4  [Policy_prescription_and_evaluation, Political...         0   \n",
       "\n",
       "   Security_and_defense  Policy_prescription_and_evaluation  \\\n",
       "0                     1                                   1   \n",
       "1                     0                                   1   \n",
       "2                     0                                   0   \n",
       "3                     1                                   0   \n",
       "4                     0                                   1   \n",
       "\n",
       "   Legality_Constitutionality_and_jurisprudence  Economic  Political  \\\n",
       "0                                             1         1          0   \n",
       "1                                             1         0          1   \n",
       "2                                             1         0          1   \n",
       "3                                             0         1          1   \n",
       "4                                             1         0          1   \n",
       "\n",
       "   Crime_and_punishment  External_regulation_and_reputation  Public_opinion  \\\n",
       "0                     0                                   0               0   \n",
       "1                     1                                   1               1   \n",
       "2                     1                                   1               0   \n",
       "3                     0                                   1               1   \n",
       "4                     0                                   1               0   \n",
       "\n",
       "   Fairness_and_equality  Capacity_and_resources  Quality_of_life  \\\n",
       "0                      0                       0                0   \n",
       "1                      0                       0                0   \n",
       "2                      1                       0                0   \n",
       "3                      1                       0                0   \n",
       "4                      0                       0                0   \n",
       "\n",
       "   Cultural_identity  Health_and_safety  \n",
       "0                  0                  0  \n",
       "1                  0                  0  \n",
       "2                  0                  0  \n",
       "3                  0                  0  \n",
       "4                  0                  0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the frames column into a list of frames\n",
    "df[\"frames_list\"] = df[\"frames\"].str.split(\",\")\n",
    "\n",
    "# create for each frame a new column with the frame as name and 1 if the frame is present in the article and 0 if not\n",
    "for frame in df[\"frames_list\"].explode().unique():\n",
    "    df[frame] = df[\"frames_list\"].apply(lambda x: 1 if frame in x else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>frames</th>\n",
       "      <th>content</th>\n",
       "      <th>frames_list</th>\n",
       "      <th>Morality</th>\n",
       "      <th>Security_and_defense</th>\n",
       "      <th>Policy_prescription_and_evaluation</th>\n",
       "      <th>Legality_Constitutionality_and_jurisprudence</th>\n",
       "      <th>Economic</th>\n",
       "      <th>Political</th>\n",
       "      <th>Crime_and_punishment</th>\n",
       "      <th>External_regulation_and_reputation</th>\n",
       "      <th>Public_opinion</th>\n",
       "      <th>Fairness_and_equality</th>\n",
       "      <th>Capacity_and_resources</th>\n",
       "      <th>Quality_of_life</th>\n",
       "      <th>Cultural_identity</th>\n",
       "      <th>Health_and_safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>833039623</td>\n",
       "      <td>Political,Crime_and_punishment,External_regula...</td>\n",
       "      <td>Robert Mueller III Rests His Case—Dems NEVER W...</td>\n",
       "      <td>[Political, Crime_and_punishment, External_reg...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>833032367</td>\n",
       "      <td>Political,Crime_and_punishment,Fairness_and_eq...</td>\n",
       "      <td>Robert Mueller Not Recommending Any More Indic...</td>\n",
       "      <td>[Political, Crime_and_punishment, Fairness_and...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>814777937</td>\n",
       "      <td>Political,Morality,Fairness_and_equality,Exter...</td>\n",
       "      <td>The Far Right Is Trying to Co-opt the Yellow V...</td>\n",
       "      <td>[Political, Morality, Fairness_and_equality, E...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>821744708</td>\n",
       "      <td>Policy_prescription_and_evaluation,Political,L...</td>\n",
       "      <td>‘Special place in hell’ for those who promoted...</td>\n",
       "      <td>[Policy_prescription_and_evaluation, Political...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>833036489</td>\n",
       "      <td>Political,External_regulation_and_reputation,P...</td>\n",
       "      <td>Bill Maher says he doesn't need Mueller report...</td>\n",
       "      <td>[Political, External_regulation_and_reputation...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                             frames  \\\n",
       "1   833039623  Political,Crime_and_punishment,External_regula...   \n",
       "2   833032367  Political,Crime_and_punishment,Fairness_and_eq...   \n",
       "3   814777937  Political,Morality,Fairness_and_equality,Exter...   \n",
       "4   821744708  Policy_prescription_and_evaluation,Political,L...   \n",
       "5   833036489  Political,External_regulation_and_reputation,P...   \n",
       "\n",
       "                                             content  \\\n",
       "1  Robert Mueller III Rests His Case—Dems NEVER W...   \n",
       "2  Robert Mueller Not Recommending Any More Indic...   \n",
       "3  The Far Right Is Trying to Co-opt the Yellow V...   \n",
       "4  ‘Special place in hell’ for those who promoted...   \n",
       "5  Bill Maher says he doesn't need Mueller report...   \n",
       "\n",
       "                                         frames_list  Morality  \\\n",
       "1  [Political, Crime_and_punishment, External_reg...         0   \n",
       "2  [Political, Crime_and_punishment, Fairness_and...         0   \n",
       "3  [Political, Morality, Fairness_and_equality, E...         1   \n",
       "4  [Policy_prescription_and_evaluation, Political...         0   \n",
       "5  [Political, External_regulation_and_reputation...         0   \n",
       "\n",
       "   Security_and_defense  Policy_prescription_and_evaluation  \\\n",
       "1                     0                                   1   \n",
       "2                     0                                   0   \n",
       "3                     1                                   0   \n",
       "4                     0                                   1   \n",
       "5                     0                                   1   \n",
       "\n",
       "   Legality_Constitutionality_and_jurisprudence  Economic  Political  \\\n",
       "1                                             1         0          1   \n",
       "2                                             1         0          1   \n",
       "3                                             0         1          1   \n",
       "4                                             1         0          1   \n",
       "5                                             1         0          1   \n",
       "\n",
       "   Crime_and_punishment  External_regulation_and_reputation  Public_opinion  \\\n",
       "1                     1                                   1               1   \n",
       "2                     1                                   1               0   \n",
       "3                     0                                   1               1   \n",
       "4                     0                                   1               0   \n",
       "5                     0                                   1               1   \n",
       "\n",
       "   Fairness_and_equality  Capacity_and_resources  Quality_of_life  \\\n",
       "1                      0                       0                0   \n",
       "2                      1                       0                0   \n",
       "3                      1                       0                0   \n",
       "4                      0                       0                0   \n",
       "5                      0                       0                0   \n",
       "\n",
       "   Cultural_identity  Health_and_safety  \n",
       "1                  0                  0  \n",
       "2                  0                  0  \n",
       "3                  0                  0  \n",
       "4                  0                  0  \n",
       "5                  0                  0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = df[(df['Political'] == 1) | (df['Crime_and_punishment'] == 1)]\n",
    "\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1696624361912,
     "user": {
      "displayName": "Elias Anderlohr",
      "userId": "15301978580987406749"
     },
     "user_tz": -120
    },
    "id": "FdAZUIg6doG0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df[\"content\"]\n",
    "y = df.drop(columns=[\"article_id\", \"frames\", \"frames_list\", \"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1696624361912,
     "user": {
      "displayName": "Elias Anderlohr",
      "userId": "15301978580987406749"
     },
     "user_tz": -120
    },
    "id": "HlL31uTzdoG0",
    "outputId": "e732ffad-597e-42c6-f687-62693490fa18",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    How Theresa May Botched\\n\\nThose were the time...\n",
       "1    Robert Mueller III Rests His Case—Dems NEVER W...\n",
       "2    Robert Mueller Not Recommending Any More Indic...\n",
       "3    The Far Right Is Trying to Co-opt the Yellow V...\n",
       "4    ‘Special place in hell’ for those who promoted...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1696624361912,
     "user": {
      "displayName": "Elias Anderlohr",
      "userId": "15301978580987406749"
     },
     "user_tz": -120
    },
    "id": "cDBgYDTidoG0",
    "outputId": "9c0094db-e682-4e25-bb33-76005f2e7ed5",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Morality</th>\n",
       "      <th>Security_and_defense</th>\n",
       "      <th>Policy_prescription_and_evaluation</th>\n",
       "      <th>Legality_Constitutionality_and_jurisprudence</th>\n",
       "      <th>Economic</th>\n",
       "      <th>Political</th>\n",
       "      <th>Crime_and_punishment</th>\n",
       "      <th>External_regulation_and_reputation</th>\n",
       "      <th>Public_opinion</th>\n",
       "      <th>Fairness_and_equality</th>\n",
       "      <th>Capacity_and_resources</th>\n",
       "      <th>Quality_of_life</th>\n",
       "      <th>Cultural_identity</th>\n",
       "      <th>Health_and_safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Morality  Security_and_defense  Policy_prescription_and_evaluation  \\\n",
       "0         1                     1                                   1   \n",
       "1         0                     0                                   1   \n",
       "2         0                     0                                   0   \n",
       "3         1                     1                                   0   \n",
       "4         0                     0                                   1   \n",
       "\n",
       "   Legality_Constitutionality_and_jurisprudence  Economic  Political  \\\n",
       "0                                             1         1          0   \n",
       "1                                             1         0          1   \n",
       "2                                             1         0          1   \n",
       "3                                             0         1          1   \n",
       "4                                             1         0          1   \n",
       "\n",
       "   Crime_and_punishment  External_regulation_and_reputation  Public_opinion  \\\n",
       "0                     0                                   0               0   \n",
       "1                     1                                   1               1   \n",
       "2                     1                                   1               0   \n",
       "3                     0                                   1               1   \n",
       "4                     0                                   1               0   \n",
       "\n",
       "   Fairness_and_equality  Capacity_and_resources  Quality_of_life  \\\n",
       "0                      0                       0                0   \n",
       "1                      0                       0                0   \n",
       "2                      1                       0                0   \n",
       "3                      1                       0                0   \n",
       "4                      0                       0                0   \n",
       "\n",
       "   Cultural_identity  Health_and_safety  \n",
       "0                  0                  0  \n",
       "1                  0                  0  \n",
       "2                  0                  0  \n",
       "3                  0                  0  \n",
       "4                  0                  0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1696624371765,
     "user": {
      "displayName": "Elias Anderlohr",
      "userId": "15301978580987406749"
     },
     "user_tz": -120
    },
    "id": "QhcR4ySddoG1",
    "outputId": "1ab79474-cc3b-490e-da77-ae0877c58266",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(432, 432)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.to_csv(\"../notebooks/classifier/y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='transformers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract SRL Embeddings from articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: pycuda in /usr/local/lib/python3.9/dist-packages (2023.1)\n",
      "Requirement already satisfied: mako in /usr/local/lib/python3.9/dist-packages (from pycuda) (1.3.0)\n",
      "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.9/dist-packages (from pycuda) (2023.1.1)\n",
      "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from pycuda) (1.4.4)\n",
      "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.9/dist-packages (from pytools>=2011.2->pycuda) (4.4.0)\n",
      "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from pytools>=2011.2->pycuda) (2.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from mako->pycuda) (2.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: allennlp in /usr/local/lib/python3.9/dist-packages (2.10.1)\n",
      "Requirement already satisfied: allennlp-models in /usr/local/lib/python3.9/dist-packages (2.10.1)\n",
      "Requirement already satisfied: lmdb>=1.2.1 in /usr/local/lib/python3.9/dist-packages (from allennlp) (1.4.1)\n",
      "Requirement already satisfied: fairscale==0.4.6 in /usr/local/lib/python3.9/dist-packages (from allennlp) (0.4.6)\n",
      "Requirement already satisfied: traitlets>5.1.1 in /usr/local/lib/python3.9/dist-packages (from allennlp) (5.8.1)\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.12.0 in /usr/local/lib/python3.9/dist-packages (from allennlp) (3.20.3)\n",
      "Requirement already satisfied: pytest>=6.2.5 in /usr/local/lib/python3.9/dist-packages (from allennlp) (7.2.1)\n",
      "Requirement already satisfied: cached-path<1.2.0,>=1.1.3 in /usr/local/lib/python3.9/dist-packages (from allennlp) (1.1.6)\n",
      "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.9/dist-packages (from allennlp) (1.9.2)\n",
      "Requirement already satisfied: base58>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from allennlp) (2.1.1)\n",
      "Requirement already satisfied: more-itertools>=8.12.0 in /usr/local/lib/python3.9/dist-packages (from allennlp) (10.1.0)\n",
      "Requirement already satisfied: torch<1.13.0,>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from allennlp) (1.12.1+cu116)\n",
      "Requirement already satisfied: nltk>=3.6.5 in /usr/local/lib/python3.9/dist-packages (from allennlp) (3.7)\n",
      "Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.9/dist-packages (from allennlp) (1.1.0)\n",
      "Requirement already satisfied: filelock<3.8,>=3.3 in /usr/local/lib/python3.9/dist-packages (from allennlp) (3.7.1)\n",
      "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.9/dist-packages (from allennlp) (2.28.2)\n",
      "Requirement already satisfied: numpy>=1.21.4 in /usr/local/lib/python3.9/dist-packages (from allennlp) (1.23.4)\n",
      "Requirement already satisfied: h5py>=3.6.0 in /usr/local/lib/python3.9/dist-packages (from allennlp) (3.8.0)\n",
      "Requirement already satisfied: torchvision<0.14.0,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from allennlp) (0.13.1+cu116)\n",
      "Requirement already satisfied: transformers<4.21,>=4.1 in /usr/local/lib/python3.9/dist-packages (from allennlp) (4.20.1)\n",
      "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.9/dist-packages (from allennlp) (2.6.2.2)\n",
      "Requirement already satisfied: wandb<0.13.0,>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from allennlp) (0.12.21)\n",
      "Requirement already satisfied: jsonnet>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from allennlp) (0.20.0)\n",
      "Requirement already satisfied: spacy<3.4,>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from allennlp) (3.3.3)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.9/dist-packages (from allennlp) (0.1.1)\n",
      "Requirement already satisfied: sentencepiece>=0.1.96 in /usr/local/lib/python3.9/dist-packages (from allennlp) (0.1.97)\n",
      "Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from allennlp) (1.1.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.16 in /usr/local/lib/python3.9/dist-packages (from allennlp) (0.10.1)\n",
      "Requirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from allennlp) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.62 in /usr/local/lib/python3.9/dist-packages (from allennlp) (4.64.1)\n",
      "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.9/dist-packages (from allennlp) (0.3.5.1)\n",
      "Requirement already satisfied: py-rouge==1.1 in /usr/local/lib/python3.9/dist-packages (from allennlp-models) (1.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (from allennlp-models) (2.4.0)\n",
      "Requirement already satisfied: conllu==4.4.2 in /usr/local/lib/python3.9/dist-packages (from allennlp-models) (4.4.2)\n",
      "Requirement already satisfied: ftfy in /usr/local/lib/python3.9/dist-packages (from allennlp-models) (6.1.3)\n",
      "Requirement already satisfied: word2number>=1.1 in /usr/local/lib/python3.9/dist-packages (from allennlp-models) (1.1)\n",
      "Requirement already satisfied: rich<13.0,>=12.1 in /usr/local/lib/python3.9/dist-packages (from cached-path<1.2.0,>=1.1.3->allennlp) (12.6.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0,>=1.32.0 in /usr/local/lib/python3.9/dist-packages (from cached-path<1.2.0,>=1.1.3->allennlp) (2.13.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from cached-path<1.2.0,>=1.1.3->allennlp) (1.24.90)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.0.16->allennlp) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.0.16->allennlp) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.0.16->allennlp) (5.4.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk>=3.6.5->allennlp) (2022.10.31)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk>=3.6.5->allennlp) (8.1.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk>=3.6.5->allennlp) (1.2.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.9/dist-packages (from pytest>=6.2.5->allennlp) (1.0.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from pytest>=6.2.5->allennlp) (2.0.1)\n",
      "Requirement already satisfied: iniconfig in /usr/local/lib/python3.9/dist-packages (from pytest>=6.2.5->allennlp) (2.0.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/dist-packages (from pytest>=6.2.5->allennlp) (23.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.9/dist-packages (from pytest>=6.2.5->allennlp) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.28->allennlp) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.28->allennlp) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.28->allennlp) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.28->allennlp) (2.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.1->allennlp) (3.1.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.4.5)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (6.3.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.10.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.12)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.10.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.7)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (66.1.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.3.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.7.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.4)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.1.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (8.0.17)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.8.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision<0.14.0,>=0.8.1->allennlp) (9.2.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers<4.21,>=4.1->allennlp) (0.12.1)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.3.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (3.1.30)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (5.9.4)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (0.4.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.14.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.0.11)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/lib/python3/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.14.0)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (0.1.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (2023.1.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (10.0.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (3.2.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (3.8.3)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (0.18.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (0.70.13)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (1.5.0)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.9/dist-packages (from ftfy->allennlp-models) (0.2.12)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.90 in /usr/local/lib/python3.9/dist-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.27.90)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.6.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->allennlp-models) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->allennlp-models) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->allennlp-models) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->allennlp-models) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->allennlp-models) (1.3.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp) (4.0.10)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.9/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.14.0)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.6.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.5.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.3.3)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.23.3 in /usr/local/lib/python3.9/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.23.4)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp) (2.14.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp) (0.9.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.4,>=2.1.0->allennlp) (2.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->allennlp-models) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->allennlp-models) (2.8.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp) (5.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.61.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (4.7.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.4.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pycuda\n",
    "!pip install allennlp allennlp-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 device(s) found.\n",
      "0 NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "import pycuda\n",
    "from pycuda import compiler\n",
    "import pycuda.driver as drv\n",
    "\n",
    "drv.init()\n",
    "print(\"%d device(s) found.\" % drv.Device.count())\n",
    "           \n",
    "for ordinal in range(drv.Device.count()):\n",
    "    dev = drv.Device(ordinal)\n",
    "    print (ordinal, dev.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "from allennlp_models.structured_prediction.models import srl_bert\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def batched_extract_srl_components(sentences, predictor):\n",
    "    # Prepare the batched input for the predictor\n",
    "    batched_input = [{'sentence': sentence} for sentence in sentences]\n",
    "    batched_srl = predictor.predict_batch_json(batched_input)\n",
    "    \n",
    "    # Extract SRL components from the batched predictions\n",
    "    results = []\n",
    "    for srl in batched_srl:\n",
    "        best_extracted_data = None\n",
    "        second_best_extracted_data = None\n",
    "        for verb_entry in srl['verbs']:\n",
    "            tags = verb_entry['tags']\n",
    "            arg0_indices = [i for i, tag in enumerate(tags) if tag in ['B-ARG0', 'I-ARG0']]\n",
    "            arg1_indices = [i for i, tag in enumerate(tags) if tag in ['B-ARG1', 'I-ARG1']]\n",
    "\n",
    "            if arg0_indices and arg1_indices:\n",
    "                best_extracted_data = {\n",
    "                    'predicate': verb_entry['verb'],\n",
    "                    'ARG0': ' '.join([srl['words'][i] for i in arg0_indices]),\n",
    "                    'ARG1': ' '.join([srl['words'][i] for i in arg1_indices])\n",
    "                }\n",
    "                break\n",
    "            elif (arg0_indices or arg1_indices) and not second_best_extracted_data:\n",
    "                second_best_extracted_data = {\n",
    "                    'predicate': verb_entry['verb'],\n",
    "                    'ARG0': ' '.join([srl['words'][i] for i in arg0_indices]) if arg0_indices else '',\n",
    "                    'ARG1': ' '.join([srl['words'][i] for i in arg1_indices]) if arg1_indices else ''\n",
    "                }\n",
    "\n",
    "        if best_extracted_data:\n",
    "            results.append(best_extracted_data)\n",
    "        elif second_best_extracted_data:\n",
    "            results.append(second_best_extracted_data)\n",
    "            \n",
    "    return results\n",
    "\n",
    "def optimized_extract_srl(X, predictor, batch_size=32):\n",
    "    total_articles = len(X)\n",
    "    processed_articles = 0\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for article in X:\n",
    "        sentences = sent_tokenize(article)\n",
    "        article_srls = []\n",
    "\n",
    "        for i in range(0, len(sentences), batch_size):\n",
    "            batched_sentences = sentences[i:i+batch_size]\n",
    "            article_srls.extend(batched_extract_srl_components(batched_sentences, predictor))\n",
    "\n",
    "        all_results.append(article_srls)\n",
    "        processed_articles += 1\n",
    "        print(f\"Processed article {processed_articles}/{total_articles}\")\n",
    "\n",
    "    return pd.Series(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def get_X_srl(X, recalculate=False, pickle_path=\"../notebooks/classifier/X_srl_filtered.pkl\"):\n",
    "    \"\"\"\n",
    "    Returns the X_srl either by loading from a pickled file or recalculating.\n",
    "    \"\"\"\n",
    "    if recalculate or not os.path.exists(pickle_path):\n",
    "        print(\"Recalculate SRL\")\n",
    "        # Load predictor\n",
    "        predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\", cuda_device=0)\n",
    "        X_srl = optimized_extract_srl(X, predictor)\n",
    "        with open(pickle_path, 'wb') as f:\n",
    "            pickle.dump(X_srl, f)\n",
    "    else:\n",
    "        print(\"Load SRL from Pickle\")\n",
    "        with open(pickle_path, 'rb') as f:\n",
    "            X_srl = pickle.load(f)\n",
    "    return X_srl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def free_gpu():\n",
    "    print(torch.cuda.mem_get_info())\n",
    "    print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/distributed/distributed_c10d.py:181: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([2755, 130])\n",
      "<class 'torch.Tensor'> torch.Size([30522, 768])\n",
      "<class 'torch.Tensor'> torch.Size([512, 768])\n",
      "<class 'torch.Tensor'> torch.Size([2, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([1, 512])\n",
      "<class 'torch.Tensor'> torch.Size([1, 512])\n",
      "<class 'torch.Tensor'> torch.Size([130, 768])\n",
      "<class 'torch.Tensor'> torch.Size([130])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([19, 145])\n",
      "<class 'torch.Tensor'> torch.Size([19, 145, 130])\n",
      "<class 'torch.Tensor'> torch.Size([19, 145, 130])\n",
      "<class 'torch.Tensor'> torch.Size([19, 145])\n",
      "<class 'torch.Tensor'> torch.Size([19, 145])\n",
      "<class 'torch.Tensor'> torch.Size([19, 145])\n",
      "<class 'torch.Tensor'> torch.Size([130, 768])\n",
      "<class 'torch.Tensor'> torch.Size([130])\n",
      "<class 'torch.Tensor'> torch.Size([1, 512])\n",
      "<class 'torch.Tensor'> torch.Size([1, 512])\n",
      "<class 'torch.Tensor'> torch.Size([30522, 768])\n",
      "<class 'torch.Tensor'> torch.Size([512, 768])\n",
      "<class 'torch.Tensor'> torch.Size([2, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "def list_gpu_tensors():\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            if torch.is_tensor(obj):\n",
    "                if obj.is_cuda:\n",
    "                    obj = obj.cpu()\n",
    "                    obj = obj.to(\"cpu\")\n",
    "                    print(type(obj), obj.size())\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "list_gpu_tensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "class ArticleDataset(Dataset):\n",
    "    def __init__(self, X, X_srl, tokenizer, labels=None, max_sentences_per_article=32, max_sentence_length=32, max_arg_length=16):\n",
    "        self.X = X\n",
    "        self.X_srl = X_srl\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_sentences_per_article = max_sentences_per_article\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.max_arg_length = max_arg_length\n",
    "        nltk.download('punkt')  # Download the Punkt tokenizer model for sentence splitting\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def _truncate_or_pad(self, lst, target_length, pad_value=0):\n",
    "        \"\"\"\n",
    "        Truncate or pad the input list to match the target length.\n",
    "        \"\"\"\n",
    "        if len(lst) > target_length:\n",
    "            return lst[:target_length]\n",
    "        else:\n",
    "            return lst + [pad_value] * (target_length - len(lst))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        article = self.X.iloc[idx]\n",
    "        srl = self.X_srl.iloc[idx]\n",
    "\n",
    "        # Split the article into sentences\n",
    "        sentences = nltk.sent_tokenize(article)\n",
    "        sentences = sentences[:self.max_sentences_per_article]  # Limit the number of sentences\n",
    "\n",
    "        # Tokenize and pad/truncate the sentences\n",
    "        sentence_ids = [self.tokenizer.encode(sentence, add_special_tokens=True, max_length=self.max_sentence_length, truncation=True, padding='max_length') for sentence in sentences]\n",
    "        while len(sentence_ids) < self.max_sentences_per_article:\n",
    "            sentence_ids.append([0] * self.max_sentence_length)\n",
    "\n",
    "        # Tokenize and pad/truncate the SRL items\n",
    "        predicate_ids = [self.tokenizer.encode(predicate, add_special_tokens=True, max_length=self.max_arg_length, truncation=True, padding='max_length') for predicate in [item['predicate'] for item in srl]]\n",
    "        arg0_ids = [self.tokenizer.encode(arg0, add_special_tokens=True, max_length=self.max_arg_length, truncation=True, padding='max_length') for arg0 in [item.get('arg0', '') for item in srl]]\n",
    "        arg1_ids = [self.tokenizer.encode(arg1, add_special_tokens=True, max_length=self.max_arg_length, truncation=True, padding='max_length') for arg1 in [item.get('arg1', '') for item in srl]]\n",
    "        \n",
    "        predicate_ids = predicate_ids[:self.max_sentences_per_article]\n",
    "        arg0_ids = arg0_ids[:self.max_sentences_per_article]\n",
    "        arg1_ids = arg1_ids[:self.max_sentences_per_article]  \n",
    "        \n",
    "        while len(predicate_ids) < self.max_sentences_per_article:\n",
    "            predicate_ids.append([0] * self.max_arg_length)\n",
    "        while len(arg0_ids) < self.max_sentences_per_article:\n",
    "            arg0_ids.append([0] * self.max_arg_length)\n",
    "        while len(arg1_ids) < self.max_sentences_per_article:\n",
    "            arg1_ids.append([0] * self.max_arg_length)\n",
    "\n",
    "        data = {\n",
    "            'sentence_ids': torch.tensor(sentence_ids, dtype=torch.long),\n",
    "            'predicate_ids': torch.tensor(predicate_ids, dtype=torch.long),\n",
    "            'arg0_ids': torch.tensor(arg0_ids, dtype=torch.long),\n",
    "            'arg1_ids': torch.tensor(arg1_ids, dtype=torch.long)\n",
    "        }\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            data['labels'] = self.labels.iloc[idx]\n",
    "        \n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    # Extract individual lists from the batch\n",
    "    sentence_ids = [item['sentence_ids'] for item in batch]\n",
    "    predicate_ids = [item['predicate_ids'] for item in batch]\n",
    "    arg0_ids = [item['arg0_ids'] for item in batch]\n",
    "    arg1_ids = [item['arg1_ids'] for item in batch]\n",
    "    \n",
    "    # Pad each list\n",
    "    sentence_ids = torch.nn.utils.rnn.pad_sequence(sentence_ids, batch_first=True, padding_value=0)\n",
    "    predicate_ids = torch.nn.utils.rnn.pad_sequence(predicate_ids, batch_first=True, padding_value=0)\n",
    "    arg0_ids = torch.nn.utils.rnn.pad_sequence(arg0_ids, batch_first=True, padding_value=0)\n",
    "    arg1_ids = torch.nn.utils.rnn.pad_sequence(arg1_ids, batch_first=True, padding_value=0)\n",
    "\n",
    "    # Conditionally extract and add labels\n",
    "    output_dict = {\n",
    "        'sentence_ids': sentence_ids,\n",
    "        'predicate_ids': predicate_ids,\n",
    "        'arg0_ids': arg0_ids,\n",
    "        'arg1_ids': arg1_ids\n",
    "    }\n",
    "    \n",
    "    if 'labels' in batch[0]:\n",
    "        labels = [item['labels'] for item in batch]\n",
    "        output_dict['labels'] = torch.Tensor(labels)\n",
    "\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "def get_datasets_dataloaders(X, y, tokenizer, recalculate_srl=False, pickle_path=\"../notebooks/X_srl_filtered.pkl\", batch_size=16, max_sentences_per_article=32, max_sentence_length=32, max_arg_length=16):\n",
    "    # Get X_srl\n",
    "    X_srl = get_X_srl(X, recalculate=recalculate_srl, pickle_path=pickle_path)\n",
    "    \n",
    "    test_size = 0.1\n",
    "    \n",
    "    # Assuming X, X_srl, and y are already defined and have the same number of samples\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Calculate class distributions for y_train and y_test in percentage\n",
    "    train_dist_percent = (y_train.sum() / y_train.shape[0]) * 100\n",
    "    test_dist_percent = (y_test.sum() / y_test.shape[0]) * 100\n",
    "\n",
    "    # Create a DataFrame to display them side by side\n",
    "    dist_comparison = pd.DataFrame({\n",
    "        'Class': train_dist_percent.index,\n",
    "        'Train Distribution (%)': train_dist_percent.values,\n",
    "        'Test Distribution (%)': test_dist_percent.values\n",
    "    })\n",
    "    \n",
    "    print(dist_comparison)\n",
    "    \n",
    "    X_srl_train, X_srl_test, _, _ = train_test_split(X_srl, y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Create the dataset\n",
    "    train_dataset = ArticleDataset(X_train, X_srl_train, tokenizer, y_train, max_sentences_per_article, max_sentence_length, max_arg_length)\n",
    "    test_dataset = ArticleDataset(X_test, X_srl_test, tokenizer, y_test, max_sentences_per_article, max_sentence_length, max_arg_length)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "    \n",
    "    print(\"CREATION DONE\")\n",
    "    return train_dataset, test_dataset, train_dataloader, test_dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Thu Nov 23 17:05:18 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 30%   62C    P2   115W / 300W |  20633MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_dataloader(article, tokenizer, batch_size=4):\n",
    "    X = pd.Series([article])\n",
    "    y = None  # No labels for this single article\n",
    "    \n",
    "    predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\", cuda_device=0)\n",
    "    # Directly use the optimized_extract_srl function since we don't need to cache for single articles\n",
    "    X_srl = optimized_extract_srl(X, predictor)\n",
    "    \n",
    "    # Create the dataset\n",
    "    dataset = ArticleDataset(X, X_srl, tokenizer, y)\n",
    "    \n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Model\n",
    "The Model consist out of various Layers.\n",
    "\n",
    "1. SRL_Embedding\n",
    "2. Autoencoder\n",
    "3. FRISSLoss\n",
    "4. Unsupervised\n",
    "5. Supervised\n",
    "6. FRISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SRL_Embeddings\n",
    "\n",
    "The layer takes tensors of token IDs with the shape [batch_size, max_num_sentences, max_num_tokens] for the sentence, predicates, arg0 and arg1 and returns for each sentence an embedding with shape [batch_size, embedding_dim] for the sentence, predicate, arg0 and arg1. \n",
    "\n",
    "The single embedding for the sentence is extracted by taking the [CLS] token embedding. For the predicate, arg0 and arg1 by taking the mean over all word embeddings in this list of tokens. \n",
    "\n",
    "> Possible improvements: Better way of extracting the single embedding for predicate, arg0 and arg1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12, 768]) torch.Size([2, 12, 768]) torch.Size([2, 12, 768]) torch.Size([2, 12, 768])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class SRL_Embeddings(nn.Module):\n",
    "    def __init__(self, bert_model_name=\"bert-base-uncased\"):\n",
    "        super(SRL_Embeddings, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(bert_model_name)\n",
    "        self.embedding_dim = 768  # for bert-base-uncased\n",
    "\n",
    "    def forward(self, sentence_ids, predicate_ids, arg0_ids, arg1_ids):\n",
    "        with torch.no_grad():\n",
    "            # Extract embeddings directly using BERT\n",
    "            # Adjust dimensions to 2D for BERT input, then reshape back to 3D\n",
    "            sentence_embeddings_3d = self.bert_model(sentence_ids.view(-1, sentence_ids.size(-1)))[0].view(sentence_ids.size(0), sentence_ids.size(1), -1, self.embedding_dim)\n",
    "            predicate_embeddings_3d = self.bert_model(predicate_ids.view(-1, predicate_ids.size(-1)))[0].view(predicate_ids.size(0), predicate_ids.size(1), -1, self.embedding_dim)\n",
    "            arg0_embeddings_3d = self.bert_model(arg0_ids.view(-1, arg0_ids.size(-1)))[0].view(arg0_ids.size(0), arg0_ids.size(1), -1, self.embedding_dim)\n",
    "            arg1_embeddings_3d = self.bert_model(arg1_ids.view(-1, arg1_ids.size(-1)))[0].view(arg1_ids.size(0), arg1_ids.size(1), -1, self.embedding_dim)\n",
    "\n",
    "        # Use [CLS] token embedding for sentences\n",
    "        sentence_embeddings = sentence_embeddings_3d[:, :, 0, :]\n",
    "\n",
    "        # Average token embeddings for predicates, ARG0, and ARG1\n",
    "        predicate_embeddings = predicate_embeddings_3d.mean(dim=2)\n",
    "        arg0_embeddings = arg0_embeddings_3d.mean(dim=2)\n",
    "        arg1_embeddings = arg1_embeddings_3d.mean(dim=2)\n",
    "        \n",
    "        return sentence_embeddings, predicate_embeddings, arg0_embeddings, arg1_embeddings\n",
    "\n",
    "# Generate dummy data for the SRL_Embeddings\n",
    "batch_size = 2\n",
    "num_sentences = 12\n",
    "sentence_length = 8\n",
    "predicate_length = 8\n",
    "arg0_length = 8\n",
    "arg1_length = 8\n",
    "\n",
    "# Dummy data for sentences, predicates, arg0, and arg1\n",
    "sentence_ids = torch.randint(0, 10000, (batch_size, num_sentences, sentence_length))\n",
    "predicate_ids = torch.randint(0, 10000, (batch_size, num_sentences, predicate_length))\n",
    "arg0_ids = torch.randint(0, 10000, (batch_size, num_sentences, arg0_length))\n",
    "arg1_ids = torch.randint(0, 10000, (batch_size, num_sentences, arg1_length))\n",
    "\n",
    "srl_embeddings = SRL_Embeddings()\n",
    "\n",
    "sentence_embeddings, predicate_embeddings, arg0_embeddings, arg1_embeddings = srl_embeddings(sentence_ids, predicate_ids, arg0_ids, arg1_ids)\n",
    "\n",
    "print(sentence_embeddings.shape, predicate_embeddings.shape, arg0_embeddings.shape, arg1_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Autoencoder\n",
    "\n",
    "The layer takes tensors for `v` (size: [batch_size, embedding_dim]), `v_sentence` (size: [batch_size, embedding_dim]), `tau` (type: _float_), and `identifier` (type: _str_). Where `v` is the embedding of either predicate, arg0 or arg1 identified by the `identifier` parameter. The `v_sentence` is the sentence embedding and `tau` defined the tau for annealing the gumpel softmax.\n",
    "\n",
    "The forward function returns `vhat` (size: [batch_size, embedding_dim]), `dz` (size: [batch_size, embedding_dim]), `gz` (size: [batch_size, embedding_dim]) and `F` (size: [K, embedding_dim]).\n",
    "\n",
    "- `vhat`: Reconstructed embedding of SRL\n",
    "- `dz`: Descriptor weights\n",
    "- `gz`: Gumbel softmax from logits\n",
    "- `F`: Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shapes:\n",
      "p -> vhat: torch.Size([2, 768]), d: torch.Size([2, 20]), g: torch.Size([2, 20]), F: torch.Size([20, 768])\n",
      "a0 -> vhat: torch.Size([2, 768]), d: torch.Size([2, 20]), g: torch.Size([2, 20]), F: torch.Size([20, 768])\n",
      "a1 -> vhat: torch.Size([2, 768]), d: torch.Size([2, 20]), g: torch.Size([2, 20]), F: torch.Size([20, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CombinedAutoencoder(nn.Module):\n",
    "    def __init__(self, D_w, D_h, K, dropout_prob=0.3):\n",
    "        super(CombinedAutoencoder, self).__init__()\n",
    "        \n",
    "        self.D_h = D_h\n",
    "        self.K = K\n",
    "        \n",
    "        # Shared feed-forward layer for all views\n",
    "        self.feed_forward_shared = nn.Linear(2 * D_w, D_h)\n",
    "        \n",
    "        # Unique feed-forward layers for each view\n",
    "        self.feed_forward_unique = nn.ModuleDict({\n",
    "            'a0': nn.Linear(D_h, K),\n",
    "            'p': nn.Linear(D_h, K),\n",
    "            'a1': nn.Linear(D_h, K),\n",
    "        })\n",
    "\n",
    "        # Initializing F matrices for each view\n",
    "        self.F_matrices = nn.ParameterDict({\n",
    "            'a0': nn.Parameter(torch.randn(K, D_w)),\n",
    "            'p': nn.Parameter(torch.randn(K, D_w)),\n",
    "            'a1': nn.Parameter(torch.randn(K, D_w)),\n",
    "        })\n",
    "\n",
    "        # Additional layers and parameters\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.batch_norm = nn.BatchNorm1d(D_h)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def gumbel_sigmoid(self, logits, tau: float = 1, hard: bool = False, threshold: float = 0.5):\n",
    "        gumbels = (\n",
    "            -torch.empty_like(logits, memory_format=torch.legacy_contiguous_format).exponential_().log()\n",
    "        )\n",
    "        gumbels = (logits + gumbels) / tau\n",
    "        y_soft = gumbels.sigmoid()\n",
    "\n",
    "        if hard:\n",
    "            indices = (y_soft > threshold).nonzero(as_tuple=True)\n",
    "            y_hard = torch.zeros_like(logits, memory_format=torch.legacy_contiguous_format)\n",
    "            y_hard[indices[0], indices[1]] = 1.0\n",
    "            ret = y_hard - y_soft.detach() + y_soft\n",
    "        else:\n",
    "            ret = y_soft\n",
    "        return ret\n",
    "    \n",
    "    def forward(self, v_p, v_a0, v_a1, v_sentence, tau):\n",
    "        h_p, h_a0, h_a1 = self.process_through_shared(v_p, v_a0, v_a1, v_sentence)\n",
    "\n",
    "        logits_p = self.feed_forward_unique['p'](h_p)\n",
    "        logits_a0 = self.feed_forward_unique['a0'](h_a0)\n",
    "        logits_a1 = self.feed_forward_unique['a1'](h_a1)\n",
    "        \n",
    "        dz_p = torch.sigmoid(logits_p)\n",
    "        dz_a0 = torch.sigmoid(logits_a0)\n",
    "        dz_a1 = torch.sigmoid(logits_a1)\n",
    "        \n",
    "        gz_p = self.gumbel_sigmoid(dz_p, tau=tau, hard=True)\n",
    "        gz_a0 = self.gumbel_sigmoid(dz_a0, tau=tau, hard=True)\n",
    "        gz_a1 = self.gumbel_sigmoid(dz_a1, tau=tau, hard=True)\n",
    "\n",
    "        vhat_p = torch.matmul(gz_p, self.F_matrices['p'])\n",
    "        vhat_a0 = torch.matmul(gz_a0, self.F_matrices['a0'])\n",
    "        vhat_a1 = torch.matmul(gz_a1, self.F_matrices['a1'])\n",
    "\n",
    "        return {\n",
    "            \"p\": {\"vhat\": vhat_p, \"d\": dz_p, \"g\": gz_p, \"F\": self.F_matrices['p']},\n",
    "            \"a0\": {\"vhat\": vhat_a0, \"d\": dz_a0, \"g\": gz_a0, \"F\": self.F_matrices['a0']},\n",
    "            \"a1\": {\"vhat\": vhat_a1, \"d\": dz_a1, \"g\": gz_a1, \"F\": self.F_matrices['a1']}\n",
    "        }\n",
    "        \n",
    "    def process_through_shared(self, v_p, v_a0, v_a1, v_sentence):\n",
    "        concatenated_p = torch.cat((v_p, v_sentence), dim=-1)\n",
    "        concatenated_a0 = torch.cat((v_a0, v_sentence), dim=-1)\n",
    "        concatenated_a1 = torch.cat((v_a1, v_sentence), dim=-1)\n",
    "        \n",
    "        # Concatenate them along the batch dimension for a single pass through the shared layer\n",
    "        stacked_embeddings = torch.cat([concatenated_p, concatenated_a0, concatenated_a1], dim=0)\n",
    "        \n",
    "        #h_shared = self.dropout(stacked_embeddings)\n",
    "        h_shared = self.feed_forward_shared(stacked_embeddings)\n",
    "        \n",
    "        # Splitting them back to individual embeddings\n",
    "        batch_size = v_p.shape[0]\n",
    "        h_shared = h_shared.view(3, batch_size, self.D_h)\n",
    "        \n",
    "        h_p, h_a0, h_a1 = h_shared[0], h_shared[1], h_shared[2]\n",
    "        return h_p, h_a0, h_a1\n",
    "\n",
    "# Mock Data Preparation\n",
    "D_h = 768\n",
    "batch_size = 2\n",
    "embedding_dim = 768\n",
    "K = 20\n",
    "tau = 0.9\n",
    "\n",
    "# Generating mock embeddings for article, predicate, ARG0, ARG1, and their corresponding sentence embeddings\n",
    "article_embedding = torch.randn(batch_size, embedding_dim)\n",
    "v_p = torch.randn(batch_size, embedding_dim)\n",
    "v_a0 = torch.randn(batch_size, embedding_dim)\n",
    "v_a1 = torch.randn(batch_size, embedding_dim)\n",
    "\n",
    "# Testing CombinedAutoencoder\n",
    "autoencoder = CombinedAutoencoder(embedding_dim, D_h, K)\n",
    "outputs = autoencoder(v_p, v_a0, v_a1, article_embedding, tau)\n",
    "\n",
    "# Check shapes of the outputs\n",
    "print(\"Output shapes:\")\n",
    "for key, value in outputs.items():\n",
    "    print(f\"{key} -> vhat: {value['vhat'].shape}, d: {value['d'].shape}, g: {value['g'].shape}, F: {value['F'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FRISSLoss\n",
    "\n",
    "The layer calculates the unsupervised loss for predicate, arg0 and arg1. \n",
    "\n",
    "The forward function takes as input 3 dicts with the parameters `v`, `v_hat`, `g` and `F`. Where `v` is the embedding of the predicate, arg0 or arg1. The `v_hat` (size: [batch_size, embedding_dim]) is the reconstructed embedding for the predicate, arg0 and arg1. The `g` is the gumbel softmax result (size: [batch_size, embedding_dim]). The `F` (size: [K, embedding_dim]) which is the descriptor dictionary.\n",
    "\n",
    "The layer returns the loss for each batch. So the output is [batch_size]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRiSSLoss output: tensor([800874.7500, 800875.3125])\n"
     ]
    }
   ],
   "source": [
    "class FRISSLoss(nn.Module):\n",
    "    def __init__(self, lambda_orthogonality, M, t):\n",
    "        super(FRISSLoss, self).__init__()\n",
    "        \n",
    "        self.lambda_orthogonality = lambda_orthogonality\n",
    "        self.M = M\n",
    "        self.t = t\n",
    "        self.triplet_loss = nn.TripletMarginLoss(margin=M)\n",
    "\n",
    "    def contrastive_loss(self, v, vhat, negatives):\n",
    "        batch_size = vhat.size(0)\n",
    "        N = negatives.size(1)\n",
    "        loss = torch.zeros(batch_size, device=v.device)\n",
    "\n",
    "        # Calculate true distance between reconstructed and real embeddings\n",
    "        true_distance = self.l2(vhat, v)\n",
    "\n",
    "        for i in range(N):  # loop over each element in \"negatives\"\n",
    "            # Calculate negative distance for current negative embedding\n",
    "            negative_distance = self.l2(vhat, negatives[:, i])\n",
    "\n",
    "            # Compute loss based on the provided logic: l2(vhat, v) + 1 + l2(vhat, negative) and clamp to 0 if below 0\n",
    "            current_loss = 1 + true_distance - negative_distance\n",
    "            loss += torch.clamp(current_loss, min=0.0)\n",
    "\n",
    "        # Normalize the total loss by N\n",
    "        return loss / N\n",
    "\n",
    "    \n",
    "    def l2(self, u, v):\n",
    "            return torch.sqrt(torch.sum((u - v) ** 2, dim=1))\n",
    "    \n",
    "    def focal_triplet_loss(self, v, vhat_z, g, F):\n",
    "        losses = []\n",
    "        for i in range(F.size(0)):  # Iterate over each negative example\n",
    "            # For each negative, compute the loss against the anchor and positive\n",
    "            loss = self.triplet_loss(vhat_z, v, F[i].unsqueeze(0).expand(v.size(0), -1))\n",
    "            losses.append(loss)\n",
    "\n",
    "        loss_tensor = torch.stack(losses)  # This will be [20, 2]\n",
    "        loss = loss_tensor.mean(dim=0).mean()  # First mean over negatives, then mean over the batch\n",
    "        return loss\n",
    "    \n",
    "    def focal_triplet_loss_old(self, v, vhat_z, g, F):\n",
    "        _, indices = torch.topk(g, self.t, largest=False, dim=1)\n",
    "\n",
    "        F_t = torch.stack([F[indices[i]] for i in range(g.size(0))])\n",
    "        \n",
    "        g_tz = torch.stack([g[i, indices[i]] for i in range(g.size(0))])\n",
    "                    \n",
    "        g_t = g_tz / g_tz.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        # if division by zero set all nan values to 0\n",
    "        g_t[torch.isnan(g_t)] = 0\n",
    "        \n",
    "        m_t = self.M * ((1 - g_t)**2)\n",
    "\n",
    "        # Initializing loss\n",
    "        loss = torch.zeros_like(v[:, 0])\n",
    "        \n",
    "        # Iteratively adding to the loss for each negative embedding\n",
    "        for i in range(self.t):\n",
    "            current_v_t = F_t[:, i]\n",
    "            current_m_t = m_t[:, i]\n",
    "            \n",
    "            current_loss = current_m_t + self.l2(vhat_z, v) - self.l2(vhat_z, current_v_t)\n",
    "            \n",
    "            loss += torch.max(torch.zeros_like(current_loss), current_loss)\n",
    "             \n",
    "        # Normalizing\n",
    "        loss = loss / self.t\n",
    "        return loss\n",
    "\n",
    "    def orthogonality_term(self, F, reg=1e-4):\n",
    "        gram_matrix = torch.mm(F, F.T)  # Compute the Gram matrix F * F^T\n",
    "        identity_matrix = torch.eye(gram_matrix.size(0), device=gram_matrix.device)  # Create an identity matrix\n",
    "        ortho_loss = (gram_matrix - identity_matrix).abs().sum()\n",
    "        return ortho_loss\n",
    "\n",
    "\n",
    "    def forward(self, p, a0, a1, p_negatives, a0_negatives, a1_negatives):\n",
    "        # Extract components from dictionary for predicate p\n",
    "        v_p, vhat_p, d_p, g_p, F_p = p[\"v\"], p[\"vhat\"], p[\"d\"], p[\"g\"], p[\"F\"]\n",
    "        \n",
    "        # Extract components from dictionary for ARG0\n",
    "        v_a0, vhat_a0, d_a0, g_a0, F_a0 = a0[\"v\"], a0[\"vhat\"], a0[\"d\"], a0[\"g\"], a0[\"F\"]\n",
    "\n",
    "        # Extract components from dictionary for ARG1\n",
    "        v_a1, vhat_a1, d_a1, g_a1, F_a1 = a1[\"v\"], a1[\"vhat\"], a1[\"d\"], a1[\"g\"], a1[\"F\"]\n",
    "        \n",
    "         # Calculate losses for predicate\n",
    "        Ju_p = self.contrastive_loss(v_p, vhat_p, p_negatives)        \n",
    "        Jt_p = self.focal_triplet_loss(v_p, vhat_p, g_p, F_p)\n",
    "        Jz_p = Ju_p + Jt_p + self.lambda_orthogonality * self.orthogonality_term(F_p) ** 2\n",
    "        #print(Ju_p, Jt_p, self.orthogonality_term(F_p))\n",
    "        # Calculate losses for ARG0\n",
    "        Ju_a0 = self.contrastive_loss(v_a0, vhat_a0, a0_negatives)\n",
    "        Jt_a0 = self.focal_triplet_loss(v_a0, vhat_a0, g_a0, F_a0)\n",
    "        Jz_a0 = Ju_a0 + Jt_a0 + self.lambda_orthogonality * self.orthogonality_term(F_a0) ** 2\n",
    "        \n",
    "        # Calculate losses for ARG1\n",
    "        Ju_a1 = self.contrastive_loss(v_a1, vhat_a1, a1_negatives)\n",
    "        Jt_a1 = self.focal_triplet_loss(v_a1, vhat_a1, g_a1, F_a1)\n",
    "        Jz_a1 = Ju_a1 + Jt_a1 + self.lambda_orthogonality * self.orthogonality_term(F_a1) ** 2\n",
    "        \n",
    "        if torch.isnan(Jz_p).any():\n",
    "            print(\"Jz_p has nan\")\n",
    "            \n",
    "        if torch.isnan(Jz_a0).any():\n",
    "            print(\"Jz_a0 has nan\")\n",
    "            \n",
    "        if torch.isnan(Jz_a1).any():\n",
    "            print(\"Jz_a1 has nan\")\n",
    "        \n",
    "        # Aggregate the losses\n",
    "        loss = Jz_p + Jz_a0 + Jz_a1\n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "# Mock Data Preparation\n",
    "batch_size = 2\n",
    "embedding_dim = 768\n",
    "K = 15  # Number of frames/descriptors\n",
    "\n",
    "# Generating mock embeddings for article, predicate, ARG0, ARG1 and their reconstructions\n",
    "article_embedding = torch.randn(batch_size, embedding_dim)\n",
    "v_p = torch.randn(batch_size, embedding_dim)\n",
    "vhat_p = torch.randn(batch_size, embedding_dim)\n",
    "\n",
    "v_a0 = torch.randn(batch_size, embedding_dim)\n",
    "vhat_a0 = torch.randn(batch_size, embedding_dim)\n",
    "\n",
    "v_a1 = torch.randn(batch_size, embedding_dim)\n",
    "vhat_a1 = torch.randn(batch_size, embedding_dim)\n",
    "\n",
    "# Generating mock descriptor weights and descriptor matrices for predicate, ARG0, ARG1\n",
    "d_p = torch.randn(batch_size, K)\n",
    "d_a0 = torch.randn(batch_size, K)\n",
    "d_a1 = torch.randn(batch_size, K)\n",
    "\n",
    "F_p = torch.randn(K, embedding_dim)\n",
    "F_a0 = torch.randn(K, embedding_dim)\n",
    "F_a1 = torch.randn(K, embedding_dim)\n",
    "\n",
    "g_p = torch.randn(batch_size, K)\n",
    "g_a0 = torch.randn(batch_size, K)\n",
    "g_a1 = torch.randn(batch_size, K)\n",
    "\n",
    "# Generating some negative samples (let's assume 5 negative samples per batch entry)\n",
    "num_negatives = 8\n",
    "negatives_p = torch.randn(batch_size, num_negatives, embedding_dim)\n",
    "negatives_a0 = torch.randn(batch_size, num_negatives, embedding_dim)\n",
    "negatives_a1 = torch.randn(batch_size, num_negatives, embedding_dim)\n",
    "\n",
    "# Initialize loss function\n",
    "lambda_orthogonality = 1e-3\n",
    "\n",
    "t = 8  # Number of descriptors with smallest weights for negative samples\n",
    "M = t\n",
    "\n",
    "loss_fn = FRISSLoss(lambda_orthogonality, M, t)\n",
    "\n",
    "# Organizing inputs into dictionaries\n",
    "p = {\"v\": v_p, \"vhat\": vhat_p, \"d\": d_p, \"g\": g_p, \"F\": F_p}\n",
    "a0 = {\"v\": v_a0, \"vhat\": vhat_a0, \"d\": d_a0, \"g\": g_a0, \"F\": F_a0}\n",
    "a1 = {\"v\": v_a1, \"vhat\": vhat_a1, \"d\": d_a1, \"g\": g_a1, \"F\": F_a1}\n",
    "\n",
    "loss_fn = FRISSLoss(lambda_orthogonality, M, t)\n",
    "loss = loss_fn(p, a0, a1, negatives_p, negatives_a0, negatives_a1)\n",
    "print(\"FRiSSLoss output:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. FRISSUnsupervised\n",
    "\n",
    "The `FRISSUnsupervised` layer integrates multiple autoencoders and the previously described `FRISSLoss` layer to achieve an unsupervised learning process over the predicates and their arguments.\n",
    "\n",
    "### Forward Method:\n",
    "\n",
    "**Inputs**:\n",
    "1. **v_p**: Embedding of the predicate with size: [batch_size, D_w].\n",
    "2. **v_a0**: Embedding of the ARG0 (first argument) with size: [batch_size, D_w].\n",
    "3. **v_a1**: Embedding of the ARG1 (second argument) with size: [batch_size, D_w].\n",
    "4. **v_article**: Embedding of the article with size: [batch_size, D_w].\n",
    "5. **negatives**: Tensor containing negative samples with size: [batch_size, num_negatives, D_w].\n",
    "6. **tau**: A scalar parameter for the Gumbel softmax in the autoencoder.\n",
    "\n",
    "**Outputs**:\n",
    "- A dictionary `results` containing:\n",
    "    - **loss**: A tensor representing the combined unsupervised loss over the batch with size: [batch_size].\n",
    "    - **p**: Dictionary containing components for the predicate, including reconstructed embedding (`vhat`), descriptor weights (`d`), Gumbel softmax result (`g`), and the descriptor matrix (`F`).\n",
    "    - **a0**: Same as `p` but for ARG0.\n",
    "    - **a1**: Same as `p` but for ARG1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results' Shapes:\n",
      "loss: tensor([1.6568e+08, 1.6568e+08], grad_fn=<AddBackward0>)\n",
      "p -> vhat: torch.Size([2, 768]), d: torch.Size([2, 20]), g: torch.Size([2, 20]), F: torch.Size([20, 768])\n",
      "a0 -> vhat: torch.Size([2, 768]), d: torch.Size([2, 20]), g: torch.Size([2, 20]), F: torch.Size([20, 768])\n",
      "a1 -> vhat: torch.Size([2, 768]), d: torch.Size([2, 20]), g: torch.Size([2, 20]), F: torch.Size([20, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming you have already defined CombinedAutoencoder and its methods as provided earlier.\n",
    "\n",
    "class FRISSUnsupervised(nn.Module):\n",
    "    def __init__(self, D_w, D_h, K, num_frames, lambda_orthogonality, M, t, dropout_prob=0.3):\n",
    "        super(FRISSUnsupervised, self).__init__()\n",
    "\n",
    "        self.loss_fn = FRISSLoss(lambda_orthogonality, M, t)      \n",
    "        \n",
    "        # Using the CombinedAutoencoder instead of individual Autoencoders\n",
    "        self.combined_autoencoder = CombinedAutoencoder(D_w, D_h, K, dropout_prob=dropout_prob)\n",
    "\n",
    "    def forward(self, v_p, v_a0, v_a1, v_sentence, p_negatives, a0_negatives, a1_negatives, tau):\n",
    "        outputs = self.combined_autoencoder(v_p, v_a0, v_a1, v_sentence, tau)\n",
    "        \n",
    "        outputs_p = outputs[\"p\"]\n",
    "        outputs_p[\"v\"] = v_p\n",
    "        \n",
    "        outputs_a0 = outputs[\"a0\"]\n",
    "        outputs_a0[\"v\"] = v_a0\n",
    "        \n",
    "        outputs_a1 = outputs[\"a1\"]\n",
    "        outputs_a1[\"v\"] = v_a1\n",
    "        \n",
    "        loss = self.loss_fn(\n",
    "            outputs_p,\n",
    "            outputs_a0, \n",
    "            outputs_a1, \n",
    "            p_negatives, a0_negatives, a1_negatives\n",
    "        )\n",
    "\n",
    "        results = {\n",
    "            \"loss\": loss,\n",
    "            \"p\": outputs[\"p\"],\n",
    "            \"a0\": outputs[\"a0\"],\n",
    "            \"a1\": outputs[\"a1\"]\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Mock Data Preparation\n",
    "D_h = 768\n",
    "batch_size = 2\n",
    "embedding_dim = 768\n",
    "K = 20\n",
    "num_frames = 15\n",
    "tau = 0.9\n",
    "lambda_orthogonality = 0.1  # Placeholder value, please replace with your actual value\n",
    "M = 7  # Placeholder value, please replace with your actual value\n",
    "t = 7  # Placeholder value, please replace with your actual value\n",
    "\n",
    "# Generating mock embeddings for article, predicate, ARG0, ARG1, and their corresponding sentence embeddings\n",
    "article_embedding = torch.randn(batch_size, embedding_dim)\n",
    "v_p = torch.randn(batch_size, embedding_dim)\n",
    "v_a0 = torch.randn(batch_size, embedding_dim)\n",
    "v_a1 = torch.randn(batch_size, embedding_dim)\n",
    "\n",
    "# Generating some negative samples (let's assume 5 negative samples per batch entry)\n",
    "num_negatives = 10\n",
    "negatives_p = torch.randn(batch_size, num_negatives, embedding_dim)\n",
    "negatives_a0 = torch.randn(batch_size, num_negatives, embedding_dim)\n",
    "negatives_a1 = torch.randn(batch_size, num_negatives, embedding_dim)\n",
    "\n",
    "# Testing FRISSUnsupervised\n",
    "unsupervised_module = FRISSUnsupervised(embedding_dim, D_h, K, num_frames, lambda_orthogonality, M, t)\n",
    "results = unsupervised_module(v_p, v_a0, v_a1, article_embedding, negatives_p, negatives_a0, negatives_a1, tau)\n",
    "\n",
    "# Print the results' shapes for verification\n",
    "print(\"Results' Shapes:\")\n",
    "for key, value in results.items():\n",
    "    if key == \"loss\":\n",
    "        print(f\"{key}: {value}\")\n",
    "    else:\n",
    "        print(f\"{key} -> vhat: {value['vhat'].shape}, d: {value['d'].shape}, g: {value['g'].shape}, F: {value['F'].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. FRISSSupervised\n",
    "\n",
    "The layer takes the embeddings from the args and the sentence and predicts frames. \n",
    "\n",
    "The embeddings for the args are averaged for each arg individually and then averaged on args level. The final embedding is feed into a linear layer and passed through a sigmoid function. \n",
    "\n",
    "The sentence embedding is feed into a linear layer and then into a relu function. After again in a linear function and then averaged. The average embeddung is again feed into a linear layer and lastly in a signoid function. \n",
    "\n",
    "It returns a span and sentence based prediction of shape [batch_size, num_frames]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 15]), torch.Size([2, 15]), torch.Size([2, 15]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FRISSSupervised(nn.Module):\n",
    "    def __init__(self, D_w, num_sentences, K, num_frames, dropout_prob=0.3, sentence_heads=8, srl_heads=8):\n",
    "        super(FRISSSupervised, self).__init__()\n",
    "\n",
    "        self.D_w = D_w\n",
    "        \n",
    "        # Separate MultiheadAttention layers for each SRL type\n",
    "        self.attention_s = nn.MultiheadAttention(embed_dim=D_w, num_heads=sentence_heads, dropout=dropout_prob)\n",
    "        self.attention_p = nn.MultiheadAttention(embed_dim=K, num_heads=srl_heads, dropout=dropout_prob)\n",
    "        self.attention_a0 = nn.MultiheadAttention(embed_dim=K, num_heads=srl_heads, dropout=dropout_prob)\n",
    "        self.attention_a1 = nn.MultiheadAttention(embed_dim=K, num_heads=srl_heads, dropout=dropout_prob)\n",
    "        \n",
    "        self.norm_s = nn.LayerNorm(D_w)\n",
    "        self.norm_p = nn.LayerNorm(K)\n",
    "        self.norm_a0 = nn.LayerNorm(K)\n",
    "        self.norm_a1 = nn.LayerNorm(K)\n",
    "        \n",
    "        # SRL Classifier for each SRL type\n",
    "        self.srl_classifier1 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(K * 3 * num_sentences, 3 * K),\n",
    "            nn.BatchNorm1d(3 * K),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(dropout_prob)\n",
    "        )\n",
    "        \n",
    "        self.srl_classifier2 = nn.Sequential(\n",
    "            nn.Linear(3 * K, num_frames)\n",
    "        )\n",
    "        \n",
    "        # Sentence-based Classifier\n",
    "        self.sentence_classifier1 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(D_w * num_sentences, 2 * D_w),\n",
    "            nn.BatchNorm1d(2 * D_w),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(2 * D_w, D_w),\n",
    "            nn.BatchNorm1d(D_w),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(dropout_prob)\n",
    "        )\n",
    "        self.sentence_classifier2 = nn.Sequential(\n",
    "            nn.Linear(D_w, num_frames)\n",
    "        )\n",
    "        \n",
    "        # Unified Classifier (combining SRL and sentence information)\n",
    "        self.unified_classifier1 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear((D_w + 3 * K) * num_sentences, D_w * (num_sentences // 2)),\n",
    "            nn.BatchNorm1d(D_w * (num_sentences // 2)),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(dropout_prob),\n",
    "            nn.Linear(D_w * (num_sentences // 2), D_w),\n",
    "            nn.BatchNorm1d(D_w),\n",
    "            nn.Tanh(),\n",
    "            #nn.Dropout(dropout_prob),\n",
    "            nn.Linear(D_w, num_frames)\n",
    "        )\n",
    "        \n",
    "    def forward(self, d_p, d_a0, d_a1, vs):\n",
    "        batch_size = d_p.shape[0]\n",
    "        \n",
    "        # SRL Part\n",
    "        #d_p, _ = self.attention_p(d_p, d_p, d_p)\n",
    "        #d_a0, _ = self.attention_a0(d_a0, d_a0, d_a0)\n",
    "        #d_a1, _ = self.attention_a1(d_a1, d_a1, d_a1)\n",
    "\n",
    "        #d_p = self.norm_p(d_p)\n",
    "        #d_a0 = self.norm_a0(d_a0)\n",
    "        #d_a1 = self.norm_a1(d_a1)\n",
    "\n",
    "        # Concatenate and classify SRL\n",
    "        srl_cat = torch.cat((d_p, d_a0, d_a1), dim=1)\n",
    "        \n",
    "        srl_transformed = self.srl_classifier1(srl_cat)\n",
    "        \n",
    "        srl_pred = self.srl_classifier2(srl_transformed)\n",
    "        \n",
    "        # Sentence Part\n",
    "        #vs, _ = self.attention_s(vs, vs, vs)\n",
    "        #vs = self.norm_s(vs)\n",
    "        \n",
    "        s_transformed = self.sentence_classifier1(vs)\n",
    "        \n",
    "        sentence_pred = self.sentence_classifier2(s_transformed)\n",
    "        \n",
    "        # Combine SRL and sentence predictions\n",
    "        combined = torch.cat((d_p, d_a0, d_a1, vs), dim=2)\n",
    "        \n",
    "        final_output = self.unified_classifier1(combined)\n",
    "        \n",
    "        return srl_pred, sentence_pred, final_output\n",
    "\n",
    "# Mock Data Preparation\n",
    "\n",
    "batch_size = 2\n",
    "embedding_dim = 768\n",
    "num_frames = 15  # Assuming the number of frames is equal to K for simplicity\n",
    "num_sentences = 32\n",
    "K = 20\n",
    "\n",
    "# Generating mock dsz representations for predicate, ARG0, ARG1\n",
    "d_p = torch.randn(batch_size, num_sentences, K)\n",
    "d_a0 = torch.randn(batch_size, num_sentences, K)\n",
    "d_a1 = torch.randn(batch_size, num_sentences, K) \n",
    "\n",
    "# Adjusting the num_heads parameter\n",
    "srl_heads = 4\n",
    "sentence_heads = 8\n",
    "\n",
    "# Adjust the mock sentence embeddings shape\n",
    "vs = torch.randn(batch_size, num_sentences, embedding_dim)\n",
    "\n",
    "# Initialize and test the supervised module\n",
    "supervised_module = FRISSSupervised(embedding_dim, num_sentences, K, num_frames, sentence_heads=sentence_heads, srl_heads=srl_heads)\n",
    "\n",
    "# Forward pass the mock data\n",
    "yu_hat, ys_hat, combined = supervised_module(d_p, d_a0, d_a1, vs)\n",
    "yu_hat.shape, ys_hat.shape, combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. FRISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.3800e+08, grad_fn=<DivBackward0>),\n",
       " torch.Size([2, 14]),\n",
       " torch.Size([2, 14]),\n",
       " torch.Size([2, 14]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FRISS(nn.Module):\n",
    "    def __init__(self, embedding_dim, D_h, lambda_orthogonality, M, t, num_sentences, K, num_frames, dropout_prob=0.3, sentence_heads=8, srl_heads=4, bert_model_name=\"bert-base-uncased\"):\n",
    "        super(FRISS, self).__init__()\n",
    "        \n",
    "        # Aggregation layer replaced with SRL_Embeddings\n",
    "        self.aggregation = SRL_Embeddings(bert_model_name)\n",
    "        \n",
    "        # Unsupervised training module\n",
    "        self.unsupervised = FRISSUnsupervised(embedding_dim, D_h, K, num_frames, lambda_orthogonality, M, t, dropout_prob=dropout_prob)\n",
    "        \n",
    "        # Supervised training module\n",
    "        self.supervised = FRISSSupervised(embedding_dim, num_sentences, K, num_frames, dropout_prob=dropout_prob, sentence_heads=sentence_heads, srl_heads=srl_heads)\n",
    "        \n",
    "    def negative_sampling(self, embeddings, num_negatives=8):\n",
    "        batch_size, num_sentences, embedding_dim = embeddings.size()\n",
    "        negatives = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # Get all the indices which are not padded (assuming padding is represented by all-zero vectors)\n",
    "            non_padded_indices = torch.where(torch.any(embeddings[i] != 0, dim=1))[0]\n",
    "\n",
    "            # Randomly sample negative indices from non-padded embeddings\n",
    "            negative_indices = non_padded_indices[torch.randint(0, len(non_padded_indices), (num_negatives,))]\n",
    "\n",
    "            # If there are fewer non-padded embeddings than required negatives, adjust the negative samples\n",
    "            while len(negative_indices) < num_negatives:\n",
    "                additional_indices = non_padded_indices[torch.randint(0, len(non_padded_indices), (num_negatives - len(negative_indices),))]\n",
    "                negative_indices = torch.cat((negative_indices, additional_indices))\n",
    "\n",
    "            negative_samples = embeddings[i, negative_indices]\n",
    "            negatives.append(negative_samples)\n",
    "\n",
    "        return torch.stack(negatives)    \n",
    "    \n",
    "    def forward(self, sentence_ids, predicate_ids, arg0_ids, arg1_ids, tau):\n",
    "        # Convert input IDs to embeddings\n",
    "        sentence_embeddings, predicate_embeddings, arg0_embeddings, arg1_embeddings = self.aggregation(sentence_ids, predicate_ids, arg0_ids, arg1_ids)\n",
    "        \n",
    "        # Handle multiple spans by averaging predictions\n",
    "        unsupervised_losses = torch.zeros((sentence_embeddings.size(0),), device=sentence_embeddings.device)\n",
    "        \n",
    "        # Creating storage for aggregated d tensors\n",
    "        d_p_list, d_a0_list, d_a1_list = [], [], []\n",
    "        \n",
    "        # Process each span\n",
    "        for span_idx in range(sentence_embeddings.size(1)):\n",
    "            s_sentence_span = sentence_embeddings[:, span_idx, :]\n",
    "            v_p_span = predicate_embeddings[:, span_idx, :]\n",
    "            v_a0_span = arg0_embeddings[:, span_idx, :]\n",
    "            v_a1_span = arg1_embeddings[:, span_idx, :]\n",
    "            \n",
    "            negatives_p = self.negative_sampling(predicate_embeddings)\n",
    "            negatives_a0 = self.negative_sampling(arg0_embeddings)\n",
    "            negatives_a1 = self.negative_sampling(arg1_embeddings)\n",
    " \n",
    "            # Feed the embeddings to the unsupervised module\n",
    "            unsupervised_results = self.unsupervised(v_p_span, v_a0_span, v_a1_span, s_sentence_span, negatives_p, negatives_a0, negatives_a1, tau)                \n",
    "            unsupervised_losses += unsupervised_results[\"loss\"]\n",
    "            \n",
    "            if torch.isnan(unsupervised_results[\"loss\"]).any():\n",
    "                print(\"loss is nan\")\n",
    "            \n",
    "            # Use the vhat (reconstructed embeddings) for supervised predictions\n",
    "            d_p_list.append(unsupervised_results['p']['d'])\n",
    "            d_a0_list.append(unsupervised_results['a0']['d'])\n",
    "            d_a1_list.append(unsupervised_results['a1']['d'])        \n",
    "        \n",
    "        # Aggregating across all spans\n",
    "        d_p_aggregated = torch.stack(d_p_list, dim=1)\n",
    "        d_a0_aggregated = torch.stack(d_a0_list, dim=1)\n",
    "        d_a1_aggregated = torch.stack(d_a1_list, dim=1)\n",
    "        \n",
    "        span_pred, sentence_pred, combined_pred = self.supervised(d_p_aggregated, d_a0_aggregated, d_a1_aggregated, sentence_embeddings)\n",
    "        \n",
    "        if torch.isnan(span_pred).any():\n",
    "            print(\"span_pred has nan:\", span_pred)\n",
    "        \n",
    "        if torch.isnan(sentence_pred).any():\n",
    "            print(\"sentence_pred has nan:\", sentence_pred)\n",
    "        \n",
    "        # Identify valid (non-nan) losses\n",
    "        valid_losses = ~torch.isnan(unsupervised_losses)\n",
    "\n",
    "        # Sum only the valid losses\n",
    "        #unsupervised_loss = unsupervised_losses[valid_losses].sum()\n",
    "        \n",
    "        # Take average by summing the valid losses and dividing by num sentences so that padded sentences are also taken in equation\n",
    "        unsupervised_loss = unsupervised_losses[valid_losses].sum() / sentence_embeddings.shape[1]\n",
    "        \n",
    "        return unsupervised_loss, span_pred, sentence_pred, combined_pred\n",
    "\n",
    "\n",
    "# Set the necessary parameters\n",
    "batch_size = 2\n",
    "embedding_dim = 768\n",
    "K = 14  # Number of frames/descriptors\n",
    "num_frames = 14  # Assuming the number of frames is equal to K for simplicity\n",
    "D_h = 512  # Dimension of the hidden representation\n",
    "lambda_orthogonality = 0.1\n",
    "M = 8\n",
    "t = 8\n",
    "tau = 1.0\n",
    "\n",
    "# Define some mock token IDs data parameters\n",
    "max_sentences_per_article = 8\n",
    "max_sentence_length = 10\n",
    "num_sentences = max_sentences_per_article\n",
    "\n",
    "# Generating mock token IDs for predicate, ARG0, ARG1, and their corresponding sentences\n",
    "# We assume a vocab size of 30522 (standard BERT vocab size) for simplicity.\n",
    "vocab_size = 30522\n",
    "\n",
    "sentence_ids = torch.randint(0, vocab_size, (batch_size, max_sentences_per_article, max_sentence_length))\n",
    "predicate_ids = torch.randint(0, vocab_size, (batch_size, max_sentences_per_article, max_sentence_length))\n",
    "arg0_ids = torch.randint(0, vocab_size, (batch_size, max_sentences_per_article, max_sentence_length))\n",
    "arg1_ids = torch.randint(0, vocab_size, (batch_size, max_sentences_per_article, max_sentence_length))\n",
    "\n",
    "sentence_embeddings = torch.randn(batch_size, max_sentences_per_article, embedding_dim)\n",
    "predicate_embeddings = torch.randn(batch_size, max_sentences_per_article, embedding_dim)\n",
    "arg0_embeddings = torch.randn(batch_size, max_sentences_per_article, embedding_dim)\n",
    "arg1_embeddings = torch.randn(batch_size, max_sentences_per_article, embedding_dim)\n",
    "\n",
    "srl_heads = 7\n",
    "sentence_heads = 8\n",
    "\n",
    "# Initialize the FRISS model\n",
    "friss_model = FRISS(embedding_dim, D_h, lambda_orthogonality, M, t, num_sentences, K=K, num_frames=num_frames, srl_heads=srl_heads)\n",
    "\n",
    "# Forward pass the mock data\n",
    "unsupervised_loss, span_pred, sentence_pred, combined_pred = friss_model(sentence_ids, predicate_ids, arg0_ids, arg1_ids, 1)\n",
    "unsupervised_loss, span_pred.shape, sentence_pred.shape, combined_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1-Score (micro-averaged) and Average Precision Score are chosen as primary metrics for evaluating the multi-label classification task due to the following reasons:\n",
    "\n",
    "1. **F1-Score (Micro)**:\n",
    "    - The micro-averaged F1-score computes global counts of true positives, false negatives, and false positives. \n",
    "    - It provides a balance between precision (the number of correct positive results divided by the number of all positive results) and recall (the number of correct positive results divided by the number of positive results that should have been returned).\n",
    "    - Given the imbalance in the label distribution observed in the dataset, the micro-averaged F1-score is robust against this imbalance, making it a suitable metric for optimization.\n",
    "\n",
    "2. **Average Precision Score**:\n",
    "    - This metric summarizes the precision-recall curve, giving a single value that represents the average of precision values at different recall levels.\n",
    "    - It's especially valuable when class imbalances exist, as it gives more weight to the positive class (the rarer class in an imbalanced dataset).\n",
    "\n",
    "Using these metrics will ensure that the model is optimized for a balanced performance across all labels, even if some labels are rarer than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, average_precision_score\n",
    "from math import exp\n",
    "import csv\n",
    "import json\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "def train(model, train_dataloader, test_dataloader, optimizer, loss_function, batch_size=4, alpha=0.5, num_epochs=10, tau_min=1, tau_decay=0.95, device='cuda', save_path='../notebooks/', save=False):\n",
    "    tau = 1\n",
    "    \n",
    "    metrics = {\n",
    "        'f1_span_micro': [],\n",
    "        'f1_sentence_micro': [],\n",
    "        'f1_combined_micro': [],\n",
    "        'f1_span_macro': [],\n",
    "        'f1_sentence_macro': [],        \n",
    "        'f1_combined_macro': []\n",
    "    }\n",
    "    \n",
    "    scheduler = ExponentialLR(optimizer, gamma=0.95)\n",
    "    \n",
    "    iteration = 0\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        supervised_total_loss = 0\n",
    "        unsupervised_total_loss = 0\n",
    "        batch_progress = tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=\"Batches\", leave=False)\n",
    "        \n",
    "        for batch_idx, batch in batch_progress:            \n",
    "            iteration = iteration + 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            sentence_ids = batch['sentence_ids'].to(device)\n",
    "            predicate_ids = batch['predicate_ids'].to(device)\n",
    "            arg0_ids = batch['arg0_ids'].to(device)\n",
    "            arg1_ids = batch['arg1_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            assert torch.isnan(sentence_ids).sum() == 0\n",
    "            assert torch.isnan(predicate_ids).sum() == 0\n",
    "            assert torch.isnan(arg0_ids).sum() == 0\n",
    "            assert torch.isnan(arg1_ids).sum() == 0\n",
    "            \n",
    "            if sentence_ids.shape[0] != batch_size:\n",
    "                print(\"Wrong Batch Size\")\n",
    "                # IDK why but sometimes I ended up with a tensor of batch size 1 which doesn't work with the batch norm layer\n",
    "                continue   \n",
    "            \n",
    "            unsupervised_loss, span_logits, sentence_logits, combined_logits = model(sentence_ids, predicate_ids, arg0_ids, arg1_ids, tau)\n",
    "            \n",
    "            span_loss = 0\n",
    "            sentence_loss = 0\n",
    "            with torch.no_grad():\n",
    "                span_loss = loss_function(span_logits, labels.float())            \n",
    "                sentence_loss = loss_function(sentence_logits, labels.float())\n",
    "            \n",
    "            # supervised_loss = span_loss + sentence_loss\n",
    "            supervised_loss = loss_function(combined_logits, labels.float())\n",
    "            # alpha = unsupervised_loss / (supervised_loss + unsupervised_loss) # try dynamic alpha\n",
    "            \n",
    "            combined_loss = alpha * supervised_loss + (1-alpha) * unsupervised_loss\n",
    "            \n",
    "            # combined_loss = supervised_loss * unsupervised_loss\n",
    "            \n",
    "            if torch.isnan(combined_loss):\n",
    "                print(f\"NaN loss detected at epoch {epoch+1}, batch {batch_idx+1}. Stopping...\")\n",
    "                return\n",
    "        \n",
    "            combined_loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            # After the backward pass\n",
    "            if any(p.grad is not None and torch.isnan(p.grad).any() for p in model.parameters()):\n",
    "                print(f\"NaN gradients detected at epoch {epoch+1}, batch {batch_idx+1}. Stopping...\")\n",
    "                return\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += combined_loss.item()\n",
    "            supervised_total_loss += supervised_loss.item()\n",
    "            unsupervised_total_loss += unsupervised_loss.item()\n",
    "\n",
    "            batch_progress.set_description(f\"Epoch {epoch+1} ({iteration}) Total Loss: {combined_loss.item():.3f}, SRLs: {span_loss:.3f}, Sentence: {sentence_loss:.3f}, CombinedS: {supervised_loss.item():.3f}, Unsupervised: {unsupervised_loss.item():.3f}\")\n",
    "                        \n",
    "            if save:\n",
    "                # Log metrics to CSV\n",
    "                with open(save_path + 'training_metrics.csv', 'a') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow([batch_idx, epoch+1, total_loss/len(train_dataloader), supervised_total_loss/len(train_dataloader), unsupervised_total_loss/len(train_dataloader)])\n",
    "\n",
    "            # Explicitly delete tensors to free up memory\n",
    "            del sentence_ids, predicate_ids, arg0_ids, arg1_ids, labels, unsupervised_loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Combined Loss: {total_loss/len(train_dataloader)}, Supervised Loss: {supervised_total_loss/len(train_dataloader)}, Unsupervised Loss: {unsupervised_total_loss/len(train_dataloader)}\")\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        span_preds = []\n",
    "        sentence_preds = []\n",
    "        combined_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in test_dataloader:\n",
    "                sentence_ids = batch['sentence_ids'].to(device)\n",
    "                predicate_ids = batch['predicate_ids'].to(device)\n",
    "                arg0_ids = batch['arg0_ids'].to(device)\n",
    "                arg1_ids = batch['arg1_ids'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                _, span_logits, sentence_logits, combined_logits = model(sentence_ids, predicate_ids, arg0_ids, arg1_ids, tau)\n",
    "                span_pred = (torch.sigmoid(span_logits) > 0.5).float()\n",
    "                sentence_pred = (torch.sigmoid(sentence_logits) > 0.5).float()\n",
    "                combined_pred = (torch.sigmoid(combined_logits) > 0.5).float()\n",
    "\n",
    "                #print(\"SRL:\", span_pred)\n",
    "                #print(\"Sentence:\", sentence_pred)\n",
    "                \n",
    "                span_preds.append(span_pred.cpu().numpy())\n",
    "                sentence_preds.append(sentence_pred.cpu().numpy())\n",
    "                combined_preds.append(combined_pred.cpu().numpy())\n",
    "                all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "                # Explicitly delete tensors to free up memory\n",
    "                del sentence_ids, predicate_ids, arg0_ids, arg1_ids, labels, span_logits, sentence_logits, span_pred, sentence_pred, combined_pred\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        all_span_preds = np.vstack(span_preds)\n",
    "        all_sentence_preds = np.vstack(sentence_preds)\n",
    "        all_combined_preds = np.vstack(combined_preds)\n",
    "        all_labels = np.vstack(all_labels)\n",
    "\n",
    "        f1_span_micro = f1_score(all_labels, all_span_preds, average='micro')\n",
    "        f1_sentence_micro = f1_score(all_labels, all_sentence_preds, average='micro')\n",
    "        f1_combined_micro = f1_score(all_labels, all_combined_preds, average='micro')\n",
    "        \n",
    "        f1_span_macro = f1_score(all_labels, all_span_preds, average='macro')\n",
    "        f1_sentence_macro = f1_score(all_labels, all_sentence_preds, average='macro')\n",
    "        f1_combined_macro = f1_score(all_labels, all_combined_preds, average='macro')\n",
    "\n",
    "        metrics['f1_span_micro'].append(f1_span_micro)\n",
    "        metrics['f1_sentence_micro'].append(f1_sentence_micro)\n",
    "        metrics['f1_combined_micro'].append(f1_combined_micro)\n",
    "        \n",
    "        metrics['f1_span_macro'].append(f1_span_macro)\n",
    "        metrics['f1_sentence_macro'].append(f1_sentence_macro)\n",
    "        metrics['f1_combined_macro'].append(f1_combined_macro)\n",
    "\n",
    "        print(f\"Validation Metrics - micro F1 - Span/Sentence/Combined: {f1_span_micro:.4f}/{f1_sentence_micro:.4f}/{f1_combined_micro:.4f}, macro F1 - Span/Sentence/Combined: {f1_span_macro:.4f}/{f1_sentence_macro:.4f}/{f1_combined_macro:.4f}\")\n",
    "        \n",
    "        # Anneal tau at the end of the epoch\n",
    "        tau = max(tau_min, exp(-tau_decay * iteration))\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "    if save:\n",
    "        model_save_path = os.path.join(save_path, 'model1.pth')\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "    \n",
    "        with open('../notebooks/metrics.json', 'w') as f:\n",
    "            json.dump(metrics, f)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load SRL from Pickle\n",
      "                                           Class  Train Distribution (%)  \\\n",
      "0                                       Morality               47.938144   \n",
      "1                           Security_and_defense               42.783505   \n",
      "2             Policy_prescription_and_evaluation               14.690722   \n",
      "3   Legality_Constitutionality_and_jurisprudence               46.391753   \n",
      "4                                       Economic                6.185567   \n",
      "5                                      Political               54.381443   \n",
      "6                           Crime_and_punishment               53.350515   \n",
      "7             External_regulation_and_reputation               26.804124   \n",
      "8                                 Public_opinion                5.670103   \n",
      "9                          Fairness_and_equality               27.577320   \n",
      "10                        Capacity_and_resources                6.443299   \n",
      "11                               Quality_of_life               20.360825   \n",
      "12                             Cultural_identity                6.958763   \n",
      "13                             Health_and_safety               14.175258   \n",
      "\n",
      "    Test Distribution (%)  \n",
      "0               36.363636  \n",
      "1               47.727273  \n",
      "2               18.181818  \n",
      "3               50.000000  \n",
      "4                9.090909  \n",
      "5               52.272727  \n",
      "6               45.454545  \n",
      "7               36.363636  \n",
      "8                2.272727  \n",
      "9               15.909091  \n",
      "10               9.090909  \n",
      "11              18.181818  \n",
      "12               9.090909  \n",
      "13              13.636364  \n",
      "CREATION DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "num_sentences = 32\n",
    "batch_size = 24\n",
    "\n",
    "train_dataset, test_dataset, train_dataloader, test_dataloader = get_datasets_dataloaders(X, y, tokenizer, recalculate_srl=False, batch_size=batch_size, max_sentences_per_article=num_sentences, max_sentence_length=32, max_arg_length=12, pickle_path=\"notebooks/X_srl_full.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08553fb0a0b143bfb6918093e13f611f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557361bb53bb404581775c1c2db1e3d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 1/40, Combined Loss: 7222360.294117647, Supervised Loss: 9.155930350808536, Unsupervised Loss: 14444711.411764706\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.4062/0.3423/0.3613, macro F1 - Span/Sentence/Combined: 0.2507/0.2966/0.3228\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8844a6f846344566806b2fe31affd3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 2/40, Combined Loss: 6752409.705882353, Supervised Loss: 6.496042419882381, Unsupervised Loss: 13504812.94117647\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3432/0.3663, macro F1 - Span/Sentence/Combined: 0.2126/0.3006/0.3424\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17e6ece7d2c4e2d93bd019ac5b9e3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 3/40, Combined Loss: 6350659.205882353, Supervised Loss: 5.685004542855656, Unsupervised Loss: 12701312.705882354\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3270/0.3495, macro F1 - Span/Sentence/Combined: 0.2126/0.2903/0.3372\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab2ed23e2c34d7f8b3336e347430b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 4/40, Combined Loss: 6002962.205882353, Supervised Loss: 5.128018126768224, Unsupervised Loss: 12005919.294117646\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3057/0.3769, macro F1 - Span/Sentence/Combined: 0.2126/0.2739/0.3592\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7760f2fe03c24aee945ee91319cc4e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 5/40, Combined Loss: 5701579.44117647, Supervised Loss: 4.847939996158376, Unsupervised Loss: 11403154.05882353\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3209/0.4051, macro F1 - Span/Sentence/Combined: 0.2126/0.2823/0.3731\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4998bb723bc434c841d2274baeea8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 6/40, Combined Loss: 5443667.264705882, Supervised Loss: 4.487442353192498, Unsupervised Loss: 10887329.88235294\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3188/0.4107, macro F1 - Span/Sentence/Combined: 0.2126/0.2868/0.3744\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35951b40549e4282aaab9041d931ab91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 7/40, Combined Loss: 5222654.05882353, Supervised Loss: 4.136341543758617, Unsupervised Loss: 10445304.11764706\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3087/0.4425, macro F1 - Span/Sentence/Combined: 0.2126/0.2779/0.3874\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8deda90b1044e62a2d7512150dd671e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 8/40, Combined Loss: 5031974.5, Supervised Loss: 3.722836270051844, Unsupervised Loss: 10063945.235294119\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3179/0.4358, macro F1 - Span/Sentence/Combined: 0.2126/0.2842/0.3802\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb978fa040d24dd885a3bc90e443c951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 9/40, Combined Loss: 4868683.911764706, Supervised Loss: 3.4660058863022747, Unsupervised Loss: 9737364.235294119\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3130/0.4954, macro F1 - Span/Sentence/Combined: 0.2126/0.2801/0.4345\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6a4a8c23774512b75b5c4984f848ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 10/40, Combined Loss: 4728476.5, Supervised Loss: 3.272866122862872, Unsupervised Loss: 9456949.764705881\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3100/0.4640, macro F1 - Span/Sentence/Combined: 0.2126/0.2771/0.4080\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a45dad6eb44a049b9a4fb30917f205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 11/40, Combined Loss: 4604917.970588235, Supervised Loss: 3.0293194546419033, Unsupervised Loss: 9209833.05882353\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3140/0.4553, macro F1 - Span/Sentence/Combined: 0.2126/0.2812/0.4187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5815552f157c45d18fd16e3ea7f51324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 12/40, Combined Loss: 4495605.294117647, Supervised Loss: 2.971394651076373, Unsupervised Loss: 8991207.705882354\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3247/0.4783, macro F1 - Span/Sentence/Combined: 0.2126/0.2866/0.4209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e83454bec64186a8fb2f46b536af30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 13/40, Combined Loss: 4398681.05882353, Supervised Loss: 2.7167929761550007, Unsupervised Loss: 8797359.235294119\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3124/0.5118, macro F1 - Span/Sentence/Combined: 0.2126/0.2778/0.4265\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e048cdbd41ed47afa78a5008ada0f6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 14/40, Combined Loss: 4313090.029411765, Supervised Loss: 2.6354986218845142, Unsupervised Loss: 8626177.352941176\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3080/0.5046, macro F1 - Span/Sentence/Combined: 0.2126/0.2775/0.4384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b39127380c49d5a4b98c4c996f3ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 15/40, Combined Loss: 4236206.294117647, Supervised Loss: 2.455129188649795, Unsupervised Loss: 8472410.11764706\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3290/0.4965, macro F1 - Span/Sentence/Combined: 0.2126/0.2954/0.4210\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe02dff3719470a951181aad1aedea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 16/40, Combined Loss: 4166374.0588235296, Supervised Loss: 2.289219716015984, Unsupervised Loss: 8332745.882352941\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3113/0.5205, macro F1 - Span/Sentence/Combined: 0.2126/0.2784/0.4413\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde9cd70094d4ec1842e729ca09c6eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 17/40, Combined Loss: 4103239.911764706, Supervised Loss: 2.12448251247406, Unsupervised Loss: 8206477.882352941\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3240/0.5228, macro F1 - Span/Sentence/Combined: 0.2126/0.2919/0.4327\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45461a0e81d14938b1cedb230e04fbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 18/40, Combined Loss: 4046083.911764706, Supervised Loss: 1.939566268640406, Unsupervised Loss: 8092165.94117647\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3219/0.5220, macro F1 - Span/Sentence/Combined: 0.2126/0.2868/0.4272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dfa37e3bd424ff6a2bf94b7de97dc50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 19/40, Combined Loss: 3994039.6764705884, Supervised Loss: 1.9679450638153975, Unsupervised Loss: 7988077.411764706\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3144/0.5126, macro F1 - Span/Sentence/Combined: 0.2126/0.2796/0.4209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15510700f960414083e5e7282968812a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 20/40, Combined Loss: 3946477.661764706, Supervised Loss: 1.775443154222825, Unsupervised Loss: 7892953.5\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3165/0.5101, macro F1 - Span/Sentence/Combined: 0.2126/0.2832/0.4207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a719ed022e14243a79e1d992a721d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 21/40, Combined Loss: 3903079.7352941176, Supervised Loss: 1.717606313088361, Unsupervised Loss: 7806157.764705882\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3158/0.5114, macro F1 - Span/Sentence/Combined: 0.2126/0.2791/0.4212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0d5737995c461a80edca260536f7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 22/40, Combined Loss: 3863310.1911764704, Supervised Loss: 1.6493699410382439, Unsupervised Loss: 7726618.764705882\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3017/0.4973, macro F1 - Span/Sentence/Combined: 0.2126/0.2676/0.3963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ccbec51be6142929d91686c61bd3846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 23/40, Combined Loss: 3827193.338235294, Supervised Loss: 1.5409406143076279, Unsupervised Loss: 7654385.176470588\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3084/0.5160, macro F1 - Span/Sentence/Combined: 0.2126/0.2732/0.4072\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d449a3c80214a9597cf9bae062325d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 24/40, Combined Loss: 3794785.25, Supervised Loss: 1.4792662999209236, Unsupervised Loss: 7589569.088235294\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3114/0.5553, macro F1 - Span/Sentence/Combined: 0.2126/0.2762/0.4398\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56262cce506640378f4b7b13b8543e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Batch Size\n",
      "Epoch 25/40, Combined Loss: 3766174.6764705884, Supervised Loss: 1.4868373590357162, Unsupervised Loss: 7532347.882352941\n",
      "Validation Metrics - micro F1 - Span/Sentence/Combined: 0.3761/0.3248/0.5141, macro F1 - Span/Sentence/Combined: 0.2126/0.2897/0.4124\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1e2561ba0343ae994efd9c81dce611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\elias\\Documents\\Git\\MasterThesis\\notebooks\\11 -friss-+-transformer.ipynb Cell 50\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/Documents/Git/MasterThesis/notebooks/11%20-friss-%2B-transformer.ipynb#X66sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m alpha_value \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/Documents/Git/MasterThesis/notebooks/11%20-friss-%2B-transformer.ipynb#X66sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m num_epochs_value \u001b[39m=\u001b[39m \u001b[39m40\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/c%3A/Users/elias/Documents/Git/MasterThesis/notebooks/11%20-friss-%2B-transformer.ipynb#X66sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m metrics \u001b[39m=\u001b[39m train(model, train_dataloader, test_dataloader, optimizer, loss_function, batch_size\u001b[39m=\u001b[39;49mbatch_size, tau_min\u001b[39m=\u001b[39;49mtau_min, tau_decay\u001b[39m=\u001b[39;49mtau_decay, alpha\u001b[39m=\u001b[39;49malpha_value, num_epochs\u001b[39m=\u001b[39;49mnum_epochs_value, device\u001b[39m=\u001b[39;49mdevice, save\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;32mc:\\Users\\elias\\Documents\\Git\\MasterThesis\\notebooks\\11 -friss-+-transformer.ipynb Cell 50\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/Documents/Git/MasterThesis/notebooks/11%20-friss-%2B-transformer.ipynb#X66sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m unsupervised_total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/Documents/Git/MasterThesis/notebooks/11%20-friss-%2B-transformer.ipynb#X66sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m batch_progress \u001b[39m=\u001b[39m tqdm(\u001b[39menumerate\u001b[39m(train_dataloader), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(train_dataloader), desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBatches\u001b[39m\u001b[39m\"\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/c%3A/Users/elias/Documents/Git/MasterThesis/notebooks/11%20-friss-%2B-transformer.ipynb#X66sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, batch \u001b[39min\u001b[39;00m batch_progress:            \n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/Documents/Git/MasterThesis/notebooks/11%20-friss-%2B-transformer.ipynb#X66sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     iteration \u001b[39m=\u001b[39m iteration \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/Documents/Git/MasterThesis/notebooks/11%20-friss-%2B-transformer.ipynb#X66sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tqdm/notebook.py:259\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[0;32m--> 259\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    260\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m    262\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32mc:\\Users\\elias\\Documents\\Git\\MasterThesis\\notebooks\\11 -friss-+-transformer.ipynb Cell 50\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/Documents/Git/MasterThesis/notebooks/11%20-friss-%2B-transformer.ipynb#X66sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m sentences \u001b[39m=\u001b[39m sentences[:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_sentences_per_article]  \u001b[39m# Limit the number of sentences\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/Documents/Git/MasterThesis/notebooks/11%20-friss-%2B-transformer.ipynb#X66sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Tokenize and pad/truncate the sentences\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/c%3A/Users/elias/Documents/Git/MasterThesis/notebooks/11%20-friss-%2B-transformer.ipynb#X66sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m sentence_ids \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mencode(sentence, add_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, max_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_sentence_length, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m sentences]\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/Documents/Git/MasterThesis/notebooks/11%20-friss-%2B-transformer.ipynb#X66sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(sentence_ids) \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_sentences_per_article:\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/Documents/Git/MasterThesis/notebooks/11%20-friss-%2B-transformer.ipynb#X66sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     sentence_ids\u001b[39m.\u001b[39mappend([\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_sentence_length)\n",
      "\u001b[1;32mc:\\Users\\elias\\Documents\\Git\\MasterThesis\\notebooks\\11 -friss-+-transformer.ipynb Cell 50\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/Documents/Git/MasterThesis/notebooks/11%20-friss-%2B-transformer.ipynb#X66sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m sentences \u001b[39m=\u001b[39m sentences[:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_sentences_per_article]  \u001b[39m# Limit the number of sentences\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/Documents/Git/MasterThesis/notebooks/11%20-friss-%2B-transformer.ipynb#X66sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Tokenize and pad/truncate the sentences\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/c%3A/Users/elias/Documents/Git/MasterThesis/notebooks/11%20-friss-%2B-transformer.ipynb#X66sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m sentence_ids \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49mencode(sentence, add_special_tokens\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, max_length\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_sentence_length, truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmax_length\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m sentences]\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/Documents/Git/MasterThesis/notebooks/11%20-friss-%2B-transformer.ipynb#X66sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(sentence_ids) \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_sentences_per_article:\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/Documents/Git/MasterThesis/notebooks/11%20-friss-%2B-transformer.ipynb#X66sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     sentence_ids\u001b[39m.\u001b[39mappend([\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_sentence_length)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2256\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   2219\u001b[0m \u001b[39m@add_end_docstrings\u001b[39m(\n\u001b[1;32m   2220\u001b[0m     ENCODE_KWARGS_DOCSTRING,\n\u001b[1;32m   2221\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2239\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m   2240\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mint\u001b[39m]:\n\u001b[1;32m   2241\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2242\u001b[0m \u001b[39m    Converts a string to a sequence of ids (integer), using the tokenizer and vocabulary.\u001b[39;00m\n\u001b[1;32m   2243\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2254\u001b[0m \u001b[39m            method).\u001b[39;00m\n\u001b[1;32m   2255\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2256\u001b[0m     encoded_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode_plus(\n\u001b[1;32m   2257\u001b[0m         text,\n\u001b[1;32m   2258\u001b[0m         text_pair\u001b[39m=\u001b[39;49mtext_pair,\n\u001b[1;32m   2259\u001b[0m         add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2260\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m   2261\u001b[0m         truncation\u001b[39m=\u001b[39;49mtruncation,\n\u001b[1;32m   2262\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2263\u001b[0m         stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2264\u001b[0m         return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2265\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2266\u001b[0m     )\n\u001b[1;32m   2268\u001b[0m     \u001b[39mreturn\u001b[39;00m encoded_inputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2588\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2578\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2579\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2580\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[1;32m   2581\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2585\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2586\u001b[0m )\n\u001b[0;32m-> 2588\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_encode_plus(\n\u001b[1;32m   2589\u001b[0m     text\u001b[39m=\u001b[39;49mtext,\n\u001b[1;32m   2590\u001b[0m     text_pair\u001b[39m=\u001b[39;49mtext_pair,\n\u001b[1;32m   2591\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2592\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[1;32m   2593\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[1;32m   2594\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2595\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2596\u001b[0m     is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2597\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2598\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2599\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2600\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2601\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2602\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2603\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2604\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2605\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2606\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2607\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils.py:649\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[39mif\u001b[39;00m return_offsets_mapping:\n\u001b[1;32m    641\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    642\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mreturn_offset_mapping is not available when using Python tokenizers. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    643\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo use this feature, change your tokenizer to one deriving from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhttps://github.com/huggingface/transformers/pull/2674\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 649\u001b[0m first_ids \u001b[39m=\u001b[39m get_input_ids(text)\n\u001b[1;32m    650\u001b[0m second_ids \u001b[39m=\u001b[39m get_input_ids(text_pair) \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_for_model(\n\u001b[1;32m    653\u001b[0m     first_ids,\n\u001b[1;32m    654\u001b[0m     pair_ids\u001b[39m=\u001b[39msecond_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    668\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[1;32m    669\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils.py:616\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus.<locals>.get_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_input_ids\u001b[39m(text):\n\u001b[1;32m    615\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 616\u001b[0m         tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenize(text, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    617\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_tokens_to_ids(tokens)\n\u001b[1;32m    618\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(text) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(text[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils.py:514\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m     escaped_special_toks \u001b[39m=\u001b[39m [\n\u001b[1;32m    511\u001b[0m         re\u001b[39m.\u001b[39mescape(s_tok) \u001b[39mfor\u001b[39;00m s_tok \u001b[39min\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39munique_no_split_tokens \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_special_tokens)\n\u001b[1;32m    512\u001b[0m     ]\n\u001b[1;32m    513\u001b[0m     pattern \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m|\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(escaped_special_toks) \u001b[39m+\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m)|\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(.+?)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 514\u001b[0m     text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39;49msub(pattern, \u001b[39mlambda\u001b[39;49;00m m: m\u001b[39m.\u001b[39;49mgroups()[\u001b[39m0\u001b[39;49m] \u001b[39mor\u001b[39;49;00m m\u001b[39m.\u001b[39;49mgroups()[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mlower(), text)\n\u001b[1;32m    516\u001b[0m no_split_token \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39munique_no_split_tokens)\n\u001b[1;32m    517\u001b[0m tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokens_trie\u001b[39m.\u001b[39msplit(text)\n",
      "File \u001b[0;32m/usr/lib/python3.9/re.py:210\u001b[0m, in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msub\u001b[39m(pattern, repl, string, count\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m    204\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[39m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m     \u001b[39mreturn\u001b[39;00m _compile(pattern, flags)\u001b[39m.\u001b[39;49msub(repl, string, count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils.py:514\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize.<locals>.<lambda>\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m    510\u001b[0m     escaped_special_toks \u001b[39m=\u001b[39m [\n\u001b[1;32m    511\u001b[0m         re\u001b[39m.\u001b[39mescape(s_tok) \u001b[39mfor\u001b[39;00m s_tok \u001b[39min\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39munique_no_split_tokens \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_special_tokens)\n\u001b[1;32m    512\u001b[0m     ]\n\u001b[1;32m    513\u001b[0m     pattern \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m|\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(escaped_special_toks) \u001b[39m+\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m)|\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(.+?)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 514\u001b[0m     text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(pattern, \u001b[39mlambda\u001b[39;00m m: m\u001b[39m.\u001b[39mgroups()[\u001b[39m0\u001b[39m] \u001b[39mor\u001b[39;00m m\u001b[39m.\u001b[39mgroups()[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mlower(), text)\n\u001b[1;32m    516\u001b[0m no_split_token \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39munique_no_split_tokens)\n\u001b[1;32m    517\u001b[0m tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokens_trie\u001b[39m.\u001b[39msplit(text)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 768\n",
    "num_frames = 14\n",
    "\n",
    "D_h = 768 * 2\n",
    "lambda_orthogonality = 1e-3\n",
    "\n",
    "K = 14\n",
    "t = 8\n",
    "M = 8\n",
    "tau_min = 0.5\n",
    "tau_decay = 5e-4\n",
    "\n",
    "dropout_prob = 0.1\n",
    "\n",
    "sentence_heads = 8\n",
    "srl_heads = 7\n",
    "\n",
    "# Model instantiation\n",
    "model = FRISS(embedding_dim, D_h, lambda_orthogonality, M, t, num_sentences, K, num_frames, dropout_prob=dropout_prob, sentence_heads=sentence_heads, srl_heads=srl_heads)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# LOSS\n",
    "\n",
    "# Compute the `weight` parameter for each label\n",
    "label_frequencies = y.mean()\n",
    "weights = 1 / (label_frequencies + 1e-10)  # Adding a small value to avoid division by zero\n",
    "\n",
    "# Compute the `pos_weight` parameter\n",
    "pos_weights = (1 - label_frequencies) / (label_frequencies + 1e-10)\n",
    "\n",
    "# Convert the computed weights and pos_weights to PyTorch tensors\n",
    "weights_tensor = torch.tensor(weights.values, dtype=torch.float32).to(device)\n",
    "pos_weights_tensor = torch.tensor(pos_weights.values, dtype=torch.float32).to(device)\n",
    "\n",
    "loss_function = nn.BCEWithLogitsLoss(weight=weights_tensor, pos_weight=pos_weights_tensor, reduction=\"mean\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Train the model\n",
    "alpha_value = 0.5\n",
    "num_epochs_value = 40\n",
    "metrics = train(model, train_dataloader, test_dataloader, optimizer, loss_function, batch_size=batch_size, tau_min=tau_min, tau_decay=tau_decay, alpha=alpha_value, num_epochs=num_epochs_value, device=device, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 768\n",
    "num_frames = 2\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def grid_search(train_dataloader, test_dataloader, search_space, num_epochs=5):\n",
    "    # Store the results for each hyperparameter combination\n",
    "    results = {}\n",
    "    \n",
    "    # Initialize the file to write metrics\n",
    "    with open(\"../notebooks/08-model/grid_search_metrics.csv\", \"w\", newline='') as csvfile:\n",
    "        fieldnames = ['alpha', 'lr', 'D_h', 'lambda_orthogonality', 'M', 't', 'tau_min', 'tau_decay', 'epoch', 'f1_span_micro', 'f1_sentence_micro', 'avg_span_precision', 'avg_sentence_precision']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Calculate the total number of combinations\n",
    "        total_combinations = 1\n",
    "        for key, values in search_space.items():\n",
    "            total_combinations *= len(values)\n",
    "        \n",
    "        # Loop through all combinations\n",
    "        for idx, combination in enumerate(product(*search_space.values())):\n",
    "            print(f\"Training combination {idx + 1}/{total_combinations}: {combination}\")\n",
    "            \n",
    "            # Extract hyperparameters from the current combination\n",
    "            alpha, lr, tau_min, tau_decay, t, D_h, lambda_orthogonality, M = combination\n",
    "            \n",
    "            # Initialize the model with current hyperparameters\n",
    "            model = FRISS(embedding_dim, D_h, lambda_orthogonality, M, t, num_frames)\n",
    "            model.to(device)\n",
    "            \n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "            \n",
    "            # Train the model with the current hyperparameters\n",
    "            epoch_metrics = train(model, train_dataloader, test_dataloader, optimizer, tau_min=tau_min, tau_decay=tau_decay, alpha=alpha, num_epochs=num_epochs, device=device)\n",
    "            \n",
    "            # Write the metrics to the CSV file\n",
    "            for epoch, f1_span_micro in enumerate(epoch_metrics['f1_span_micro']):\n",
    "                f1_sentence_micro = epoch_metrics['f1_sentence_micro'][epoch]\n",
    "                avg_span_precision = epoch_metrics['avg_span_precision'][epoch]\n",
    "                avg_sentence_precision = epoch_metrics['avg_sentence_precision'][epoch]\n",
    "                row = {\n",
    "                    'alpha': alpha,\n",
    "                    'lr': lr,\n",
    "                    'D_h': D_h,\n",
    "                    'lambda_orthogonality': lambda_orthogonality,\n",
    "                    'M': M,\n",
    "                    't': t,\n",
    "                    'tau_min': tau_min,\n",
    "                    'tau_decay': tau_decay,\n",
    "                    'epoch': epoch + 1,\n",
    "                    'f1_span_micro': f1_span_micro,\n",
    "                    'f1_sentence_micro': f1_span_micro,\n",
    "                    'avg_span_precision': avg_span_precision,\n",
    "                    'avg_sentence_precision': avg_sentence_precision\n",
    "                }\n",
    "                writer.writerow(row)\n",
    "                csvfile.flush()\n",
    "    \n",
    "    return results\n",
    "\n",
    "search_space = {\n",
    "    'alpha': [1],#[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    'lr': [1e-5, 2e-5, 5e-4, 1e-3],\n",
    "    'tau_min': [0.1, 0.5],\n",
    "    'tau_decay': [1e-3, 5e-4, 1e-4],\n",
    "    't': [1,2],\n",
    "    'D_h': [256, 512],\n",
    "    'lambda_orthogonality': [1e-4, 5e-4, 1e-3, 5e-3, 1e-2],\n",
    "    'M': [1,2]\n",
    "}\n",
    "\n",
    "# Call the grid search function\n",
    "results = grid_search(train_dataloader, test_dataloader, search_space, num_epochs=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_path(model_class, path, device='cuda'):\n",
    "    \"\"\"\n",
    "    Loads the weights into an instance of the model class from the given path.\n",
    "    \n",
    "    Args:\n",
    "    - model_class (torch.nn.Module): The class of the model (uninitialized).\n",
    "    - path (str): Path to the saved weights.\n",
    "    - device (str): Device to load the model on ('cpu' or 'cuda').\n",
    "    \n",
    "    Returns:\n",
    "    - model (torch.nn.Module): Model with weights loaded.\n",
    "    \"\"\"\n",
    "    model = model_class().to(device)\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    #model.eval()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 8 required positional arguments: 'embedding_dim', 'D_h', 'lambda_orthogonality', 'M', 't', 'num_sentences', 'K', and 'num_frames'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFRISS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../notebooks/11-model/run_08-11_9am/model1.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [42], line 13\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[0;34m(model_class, path, device)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model_from_path\u001b[39m(model_class, path, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Loads the weights into an instance of the model class from the given path.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    - model (torch.nn.Module): Model with weights loaded.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(path, map_location\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m#model.eval()\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 8 required positional arguments: 'embedding_dim', 'D_h', 'lambda_orthogonality', 'M', 't', 'num_sentences', 'K', and 'num_frames'"
     ]
    }
   ],
   "source": [
    "model = load_model_from_path(FRISS, '../notebooks/11-model/run_08-11_9am/model1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader, y_columns, device='cuda'):\n",
    "    \"\"\"\n",
    "    Make predictions with the given model and dataloader.\n",
    "    \n",
    "    Args:\n",
    "    - model (torch.nn.Module): The model to make predictions with.\n",
    "    - dataloader (DataLoader): DataLoader for the dataset to predict on.\n",
    "    - y_columns (pandas.Index): Column names from the y dataframe which correspond to labels.\n",
    "    - device (str): Device to make predictions on ('cpu' or 'cuda').\n",
    "    \n",
    "    Returns:\n",
    "    - predicted_labels (list of lists): List containing the predicted labels for each instance.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds_span = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Move data to device\n",
    "            sentence_ids = batch['sentence_ids'].to(device)\n",
    "            predicate_ids = batch['predicate_ids'].to(device)\n",
    "            arg0_ids = batch['arg0_ids'].to(device)\n",
    "            arg1_ids = batch['arg1_ids'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            logits_span, _ = model(sentence_ids, predicate_ids, arg0_ids, arg1_ids)\n",
    "            preds_span = (torch.sigmoid(logits_span) > 0.5).float()\n",
    "\n",
    "            all_preds_span.append(preds_span.cpu().numpy())\n",
    "                \n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    predictions = np.vstack(all_preds_span)\n",
    "    \n",
    "    # Convert boolean predictions to labels\n",
    "    predicted_labels = []\n",
    "    for pred in predictions:\n",
    "        labels = list(y_columns[pred.astype(bool)])\n",
    "        predicted_labels.append(labels)\n",
    "    \n",
    "    return predicted_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# article813452859\n",
    "article = \"\"\"EU Profits From Trading With UK While London Loses Money – Political Campaigner\n",
    "\n",
    "With the Parliamentary vote on British Prime Minister Theresa May’s Brexit plan set to be held next month; President of the European Commission Jean Claude Juncker has criticised the UK’s preparations for their departure from the EU.\n",
    "But is there any chance that May's deal will make it through parliament and if it fails, how could this ongoing political deadlock finally come to an end?\n",
    "Sputnik spoke with political campaigner Michael Swadling for more…\n",
    "Sputnik: Does Theresa May have any chance of getting her deal through Parliament on the 14th January?\n",
    "Michael Swadling: I guess her only chance is if Labour decides that they want to dishonour democracy and effectively keep us in the EU.\n",
    "© AP Photo / Pablo Martinez Monsivais UK 'In Need of Leadership', May's Brexit Deal Unwelcome to Trump - US Ambassador\n",
    "There is a chance; as unfortunately there are many MPs who don't respect the vote and may just turn on it, but short of that I don't see any way the Conservatives would vote for it, and the majority is slender as it is, as the DUP is bitterly against it, and I can't see the Lib Dems voting for it, so it will only be if there are enough, what I can describe as remoaner MPs, that the deal won't be dead in the water.\n",
    "Sputnik: What could be a solution to the political chaos if the Prime Minister's deal is not approved?\n",
    "Michael Swadling: The EU withdrawal act is in place; we'll leave and revert to WTO terms and that works, that's fine.\n",
    "I often use the example of an iPhone to people; that's a piece of technology which is manufactured in China, uses American technology and these are two countries we deal with on WTO terms, this isn't a fantasy, stuck in a port somewhere, there isn't a massive tariff, this is the world that really exists today.\n",
    "When we exit the EU on WTO terms; that will be fine for whatever trading we do with the EU, just as well as it does for our trade in China.READ MORE: UK Finance Chief Bashed for Failing to Unlock Money for No-Deal Brexit — Reports\n",
    "Sputnik: Do you think that the EU needs the UK more than the UK needs the EU?\n",
    "Michael Swadling: The EU makes a profit on its trade with the UK; the UK makes a loss on its trade with the EU.\n",
    "They have a financial incentive to ensure that good trading relations continue far more than we do.\n",
    "© REUTERS / Toby Melville UK Trade Minister Says '50-50' Chance Brexit Will Not Happen – Reports\n",
    "The lifeblood and cash flow that keeps manufacturing in Europe going, comes from the city of London.\n",
    "If someone in a city in Germany wants to do a deal with someone in Japan; the financial services of that are probably going through the city of London, they're not going through Frankfurt and Paris.\n",
    "Views and opinions, expressed in the article are those of Michael Swadling and do not necessarily reflect those of Sputnik\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "test_article = get_article_dataloader(article, tokenizer)\n",
    "predict(model, test_article, y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "free_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05c4f9fa65704ea5ba7f80e879e08510": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f54181f857a4110bf9976a56c97de97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fbfe002ccd541f9b6ab62ed4eebef35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1048f064e69b46d497b65cb9b88d0142": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc871ed94e764fe884ffdafca1445bfe",
       "IPY_MODEL_b4e7e77911e5408b84d89ccaff134708",
       "IPY_MODEL_c322e99ad9504207b7cfb9ae2ca9d6b1"
      ],
      "layout": "IPY_MODEL_dd92db5892be4357a6446146d9e9a0dd"
     }
    },
    "145c8616bab245358c8052beac5bd2bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20d6b378a69744e4a327d929c391b475": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "364a4257f8a641e18b7bde39e63a618d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "409a73804fc34a63a619a42b9468be46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "475020323c07410e87d366a6f553aafb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_145c8616bab245358c8052beac5bd2bc",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ca901348dcd1428ebecc55d659fa40d1",
      "value": 28
     }
    },
    "4ddbb3fa3b924a9e9650f51204580f8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a5458551f974a94b61ff658ae59fa70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b48b8b79d6a4ff1b0655a6bfcf7a422": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c06d626b5ee4fe8bdb9be7fb879aae0",
      "placeholder": "​",
      "style": "IPY_MODEL_779202125255413cb719a43fe5d14ce7",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "5d40c6e034fd4b278969dd928cc07dff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f4b55ead6884f3790a3acfa43232fc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87907508c4eb43f3a27858f1d397ca99",
      "placeholder": "​",
      "style": "IPY_MODEL_d21ed2e527464a0ca0cb2b3b4fad928a",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "650f8e0f82e849f58a47507291b15500": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbb672669b9f4c36873048cfa1d2daf6",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cf42b39e3be94c90b3a63d05783481a3",
      "value": 231508
     }
    },
    "67ea6145091b440da6b4c5d5f8695aa9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ac495a816994aaeb8926c6c97d103ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ddbb3fa3b924a9e9650f51204580f8d",
      "placeholder": "​",
      "style": "IPY_MODEL_a115ed03534a4c64a17fa55d93a0f93a",
      "value": " 570/570 [00:00&lt;00:00, 47.0kB/s]"
     }
    },
    "71add6bf108545af8db6aeb392793759": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5f4b55ead6884f3790a3acfa43232fc9",
       "IPY_MODEL_475020323c07410e87d366a6f553aafb",
       "IPY_MODEL_e2454ec2f5904e0bacde56ae7d4089a9"
      ],
      "layout": "IPY_MODEL_0f54181f857a4110bf9976a56c97de97"
     }
    },
    "779202125255413cb719a43fe5d14ce7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "87907508c4eb43f3a27858f1d397ca99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c06d626b5ee4fe8bdb9be7fb879aae0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e13dccd922946ab873cc287fcca5baf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93fa55d130db463c8ddffc947f2e99cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a6d16261d5b4693b09acf83dcb38920": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0265a21ae504485ab59207228c1f6d6",
      "placeholder": "​",
      "style": "IPY_MODEL_8e13dccd922946ab873cc287fcca5baf",
      "value": " 232k/232k [00:00&lt;00:00, 9.51MB/s]"
     }
    },
    "a0265a21ae504485ab59207228c1f6d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a115ed03534a4c64a17fa55d93a0f93a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a74bacc051494d1ea0f4cbd656505cfe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4e7e77911e5408b84d89ccaff134708": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67ea6145091b440da6b4c5d5f8695aa9",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bef37b47c8ee49778464c05adcffa30d",
      "value": 466062
     }
    },
    "b83493088cd24629a04ec612aa522ed4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c222d2a5e4664f9b9aefed7f093d4a4e",
       "IPY_MODEL_fa94f90b735f418fb2b502f7877b5306",
       "IPY_MODEL_6ac495a816994aaeb8926c6c97d103ae"
      ],
      "layout": "IPY_MODEL_409a73804fc34a63a619a42b9468be46"
     }
    },
    "bef37b47c8ee49778464c05adcffa30d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c222d2a5e4664f9b9aefed7f093d4a4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_364a4257f8a641e18b7bde39e63a618d",
      "placeholder": "​",
      "style": "IPY_MODEL_93fa55d130db463c8ddffc947f2e99cd",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "c322e99ad9504207b7cfb9ae2ca9d6b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d40c6e034fd4b278969dd928cc07dff",
      "placeholder": "​",
      "style": "IPY_MODEL_f6b3c67d61114db5810bd78339a218d9",
      "value": " 466k/466k [00:00&lt;00:00, 1.88MB/s]"
     }
    },
    "ca901348dcd1428ebecc55d659fa40d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cf42b39e3be94c90b3a63d05783481a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d21ed2e527464a0ca0cb2b3b4fad928a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d568d9b894694b6fb432456031cee230": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbb672669b9f4c36873048cfa1d2daf6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd92db5892be4357a6446146d9e9a0dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2454ec2f5904e0bacde56ae7d4089a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20d6b378a69744e4a327d929c391b475",
      "placeholder": "​",
      "style": "IPY_MODEL_05c4f9fa65704ea5ba7f80e879e08510",
      "value": " 28.0/28.0 [00:00&lt;00:00, 1.97kB/s]"
     }
    },
    "e9ee9acc5e414c65ad10b8864cc07b07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f19c187b1e8c4bbe9fda366f24f2b79e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b48b8b79d6a4ff1b0655a6bfcf7a422",
       "IPY_MODEL_650f8e0f82e849f58a47507291b15500",
       "IPY_MODEL_9a6d16261d5b4693b09acf83dcb38920"
      ],
      "layout": "IPY_MODEL_d568d9b894694b6fb432456031cee230"
     }
    },
    "f6b3c67d61114db5810bd78339a218d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa94f90b735f418fb2b502f7877b5306": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a74bacc051494d1ea0f4cbd656505cfe",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0fbfe002ccd541f9b6ab62ed4eebef35",
      "value": 570
     }
    },
    "fc871ed94e764fe884ffdafca1445bfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a5458551f974a94b61ff658ae59fa70",
      "placeholder": "​",
      "style": "IPY_MODEL_e9ee9acc5e414c65ad10b8864cc07b07",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
