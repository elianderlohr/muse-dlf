{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Waumhn_ldoGu"
   },
   "source": [
    "## FRISS with MFC\n",
    "\n",
    "Implementation of the FRISS using the Media Frames Corpus (MFC) from Card et al. (2015). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.64.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
      "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['README.md',\n",
       " 'logs',\n",
       " 'notebooks',\n",
       " 'chunks.pkl',\n",
       " '.git',\n",
       " 'results',\n",
       " 'assets',\n",
       " 'friss',\n",
       " 'models',\n",
       " '.ipynb_checkpoints',\n",
       " 'data',\n",
       " '.gitignore',\n",
       " 'frameaxis']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = \"data/mfc/immigration_labeled.json\"\n",
    "codes_path = \"data/mfc/codes.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from path \n",
    "import json\n",
    "\n",
    "with open(labels_path) as f:\n",
    "    labels = json.load(f)\n",
    "\n",
    "with open(codes_path) as f:\n",
    "    codes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# articles list\n",
    "articles_list = []\n",
    "\n",
    "# Iterate through the data to fill the DataFrame\n",
    "for article_id, article_data in labels.items():\n",
    "    annotations_data = article_data['annotations']\n",
    "\n",
    "    irrelevant_dict = annotations_data['irrelevant']\n",
    "\n",
    "    text = article_data['text']\n",
    "    irrelevant = article_data['irrelevant']\n",
    "\n",
    "    # if primary_frame is none set to 15.0\n",
    "    if article_data['primary_frame'] is not None:\n",
    "        primary_frame = str(article_data['primary_frame']).split(\".\")[0] + \".0\"\n",
    "    else:\n",
    "        primary_frame = \"15.0\"\n",
    "\n",
    "    # get primary frame from code\n",
    "    primary_frame = str(codes[primary_frame])\n",
    "\n",
    "    # split text into sentences using nltk library\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    # iterate through sentences\n",
    "    for sentence in sentences:\n",
    "        article = {\n",
    "            'article_id': article_id,\n",
    "            'irrelevant': irrelevant,\n",
    "            'text': sentence,\n",
    "            'document_frame': primary_frame\n",
    "        }\n",
    "\n",
    "        articles_list.append(article)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "df = pd.DataFrame(articles_list, columns=['article_id', 'irrelevant', 'text', 'document_frame'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>irrelevant</th>\n",
       "      <th>text</th>\n",
       "      <th>document_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IMM-10005\\n\\nPRIMARY\\n\\nImmigrants without HOP...</td>\n",
       "      <td>Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>It mounted as students went around the room te...</td>\n",
       "      <td>Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Georgia Tech.</td>\n",
       "      <td>Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>University of Georgia.</td>\n",
       "      <td>Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"All I could say was, 'I'm planning to see if ...</td>\n",
       "      <td>Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74463</th>\n",
       "      <td>Immigration1.0-9998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sue Brown, spokeswoman for the INS, said it's ...</td>\n",
       "      <td>Crime and Punishment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74464</th>\n",
       "      <td>Immigration1.0-9998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"They love it,\" she said.</td>\n",
       "      <td>Crime and Punishment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74465</th>\n",
       "      <td>Immigration1.0-9998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"They use these units to interview the people,...</td>\n",
       "      <td>Crime and Punishment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74466</th>\n",
       "      <td>Immigration1.0-9998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"We do about 15 interviews a day,\" Brown said.</td>\n",
       "      <td>Crime and Punishment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74467</th>\n",
       "      <td>Immigration1.0-9998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"We put a hold on about a third of them.\"</td>\n",
       "      <td>Crime and Punishment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74468 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 article_id  irrelevant  \\\n",
       "0      Immigration1.0-10005         0.0   \n",
       "1      Immigration1.0-10005         0.0   \n",
       "2      Immigration1.0-10005         0.0   \n",
       "3      Immigration1.0-10005         0.0   \n",
       "4      Immigration1.0-10005         0.0   \n",
       "...                     ...         ...   \n",
       "74463   Immigration1.0-9998         0.0   \n",
       "74464   Immigration1.0-9998         0.0   \n",
       "74465   Immigration1.0-9998         0.0   \n",
       "74466   Immigration1.0-9998         0.0   \n",
       "74467   Immigration1.0-9998         0.0   \n",
       "\n",
       "                                                    text        document_frame  \n",
       "0      IMM-10005\\n\\nPRIMARY\\n\\nImmigrants without HOP...       Quality of Life  \n",
       "1      It mounted as students went around the room te...       Quality of Life  \n",
       "2                                          Georgia Tech.       Quality of Life  \n",
       "3                                 University of Georgia.       Quality of Life  \n",
       "4      \"All I could say was, 'I'm planning to see if ...       Quality of Life  \n",
       "...                                                  ...                   ...  \n",
       "74463  Sue Brown, spokeswoman for the INS, said it's ...  Crime and Punishment  \n",
       "74464                          \"They love it,\" she said.  Crime and Punishment  \n",
       "74465  \"They use these units to interview the people,...  Crime and Punishment  \n",
       "74466     \"We do about 15 interviews a day,\" Brown said.  Crime and Punishment  \n",
       "74467          \"We put a hold on about a third of them.\"  Crime and Punishment  \n",
       "\n",
       "[74468 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1296
    },
    "executionInfo": {
     "elapsed": 3772,
     "status": "ok",
     "timestamp": 1696624002536,
     "user": {
      "displayName": "Elias Anderlohr",
      "userId": "15301978580987406749"
     },
     "user_tz": -120
    },
    "id": "DG_Xix7gdoGy",
    "outputId": "d6fad26e-e6f7-4c20-f4bb-c7b01d51eb33",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[df[\"irrelevant\"] == False][[\"article_id\", \"text\", \"document_frame\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>text</th>\n",
       "      <th>document_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>IMM-10005\\n\\nPRIMARY\\n\\nImmigrants without HOP...</td>\n",
       "      <td>Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>It mounted as students went around the room te...</td>\n",
       "      <td>Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>Georgia Tech.</td>\n",
       "      <td>Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>University of Georgia.</td>\n",
       "      <td>Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>\"All I could say was, 'I'm planning to see if ...</td>\n",
       "      <td>Quality of Life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             article_id                                               text  \\\n",
       "0  Immigration1.0-10005  IMM-10005\\n\\nPRIMARY\\n\\nImmigrants without HOP...   \n",
       "1  Immigration1.0-10005  It mounted as students went around the room te...   \n",
       "2  Immigration1.0-10005                                      Georgia Tech.   \n",
       "3  Immigration1.0-10005                             University of Georgia.   \n",
       "4  Immigration1.0-10005  \"All I could say was, 'I'm planning to see if ...   \n",
       "\n",
       "    document_frame  \n",
       "0  Quality of Life  \n",
       "1  Quality of Life  \n",
       "2  Quality of Life  \n",
       "3  Quality of Life  \n",
       "4  Quality of Life  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create for each code a col and fill with 1 if code is in code col\n",
    "df = pd.concat([df, pd.get_dummies(df['document_frame'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>text</th>\n",
       "      <th>document_frame</th>\n",
       "      <th>Capacity and Resources</th>\n",
       "      <th>Crime and Punishment</th>\n",
       "      <th>Cultural Identity</th>\n",
       "      <th>Economic</th>\n",
       "      <th>External Regulation and Reputation</th>\n",
       "      <th>Fairness and Equality</th>\n",
       "      <th>Health and Safety</th>\n",
       "      <th>Legality, Constitutionality, Jurisdiction</th>\n",
       "      <th>Morality</th>\n",
       "      <th>Other</th>\n",
       "      <th>Policy Prescription and Evaluation</th>\n",
       "      <th>Political</th>\n",
       "      <th>Public Sentiment</th>\n",
       "      <th>Quality of Life</th>\n",
       "      <th>Security and Defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>IMM-10005\\n\\nPRIMARY\\n\\nImmigrants without HOP...</td>\n",
       "      <td>Quality of Life</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>It mounted as students went around the room te...</td>\n",
       "      <td>Quality of Life</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>Georgia Tech.</td>\n",
       "      <td>Quality of Life</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>University of Georgia.</td>\n",
       "      <td>Quality of Life</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>\"All I could say was, 'I'm planning to see if ...</td>\n",
       "      <td>Quality of Life</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             article_id                                               text  \\\n",
       "0  Immigration1.0-10005  IMM-10005\\n\\nPRIMARY\\n\\nImmigrants without HOP...   \n",
       "1  Immigration1.0-10005  It mounted as students went around the room te...   \n",
       "2  Immigration1.0-10005                                      Georgia Tech.   \n",
       "3  Immigration1.0-10005                             University of Georgia.   \n",
       "4  Immigration1.0-10005  \"All I could say was, 'I'm planning to see if ...   \n",
       "\n",
       "    document_frame  Capacity and Resources  Crime and Punishment  \\\n",
       "0  Quality of Life                       0                     0   \n",
       "1  Quality of Life                       0                     0   \n",
       "2  Quality of Life                       0                     0   \n",
       "3  Quality of Life                       0                     0   \n",
       "4  Quality of Life                       0                     0   \n",
       "\n",
       "   Cultural Identity  Economic  External Regulation and Reputation  \\\n",
       "0                  0         0                                   0   \n",
       "1                  0         0                                   0   \n",
       "2                  0         0                                   0   \n",
       "3                  0         0                                   0   \n",
       "4                  0         0                                   0   \n",
       "\n",
       "   Fairness and Equality  Health and Safety  \\\n",
       "0                      0                  0   \n",
       "1                      0                  0   \n",
       "2                      0                  0   \n",
       "3                      0                  0   \n",
       "4                      0                  0   \n",
       "\n",
       "   Legality, Constitutionality, Jurisdiction  Morality  Other  \\\n",
       "0                                          0         0      0   \n",
       "1                                          0         0      0   \n",
       "2                                          0         0      0   \n",
       "3                                          0         0      0   \n",
       "4                                          0         0      0   \n",
       "\n",
       "   Policy Prescription and Evaluation  Political  Public Sentiment  \\\n",
       "0                                   0          0                 0   \n",
       "1                                   0          0                 0   \n",
       "2                                   0          0                 0   \n",
       "3                                   0          0                 0   \n",
       "4                                   0          0                 0   \n",
       "\n",
       "   Quality of Life  Security and Defense  \n",
       "0                1                     0  \n",
       "1                1                     0  \n",
       "2                1                     0  \n",
       "3                1                     0  \n",
       "4                1                     0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67480, 18)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='transformers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract SRL Embeddings from articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycuda\n",
      "  Downloading pycuda-2024.1.tar.gz (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting mako\n",
      "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting appdirs>=1.4.0\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting pytools>=2011.2\n",
      "  Downloading pytools-2023.1.1-py2.py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.9/dist-packages (from pytools>=2011.2->pycuda) (4.4.0)\n",
      "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from pytools>=2011.2->pycuda) (2.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from mako->pycuda) (2.1.2)\n",
      "Building wheels for collected packages: pycuda\n",
      "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycuda: filename=pycuda-2024.1-cp39-cp39-linux_x86_64.whl size=661892 sha256=3c0e3cef185937b2431e26fabeca331ebe896a076302685c05622601d236d90a\n",
      "  Stored in directory: /root/.cache/pip/wheels/06/f2/d5/eb166b853d02ecfcc750b3f6b7978c56410a5bbe587074cbeb\n",
      "Successfully built pycuda\n",
      "Installing collected packages: appdirs, pytools, mako, pycuda\n",
      "Successfully installed appdirs-1.4.4 mako-1.3.2 pycuda-2024.1 pytools-2023.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting allennlp\n",
      "  Downloading allennlp-2.10.1-py3-none-any.whl (730 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m730.2/730.2 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting allennlp-models\n",
      "  Downloading allennlp_models-2.10.1-py3-none-any.whl (464 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.5/464.5 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.9/dist-packages (from allennlp) (1.9.2)\n",
      "Requirement already satisfied: sentencepiece>=0.1.96 in /usr/local/lib/python3.9/dist-packages (from allennlp) (0.1.97)\n",
      "Collecting jsonnet>=0.10.0\n",
      "  Downloading jsonnet-0.20.0.tar.gz (594 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.2/594.2 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch<1.13.0,>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from allennlp) (1.12.1+cu116)\n",
      "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.9/dist-packages (from allennlp) (2.28.2)\n",
      "Requirement already satisfied: traitlets>5.1.1 in /usr/local/lib/python3.9/dist-packages (from allennlp) (5.8.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.16 in /usr/local/lib/python3.9/dist-packages (from allennlp) (0.12.0)\n",
      "Collecting spacy<3.4,>=2.1.0\n",
      "  Downloading spacy-3.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytest>=6.2.5 in /usr/local/lib/python3.9/dist-packages (from allennlp) (7.2.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from allennlp) (1.1.2)\n",
      "Requirement already satisfied: h5py>=3.6.0 in /usr/local/lib/python3.9/dist-packages (from allennlp) (3.8.0)\n",
      "Requirement already satisfied: tqdm>=4.62 in /usr/local/lib/python3.9/dist-packages (from allennlp) (4.64.1)\n",
      "Collecting termcolor==1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.9/dist-packages (from allennlp) (0.3.5.1)\n",
      "Requirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from allennlp) (0.4.2)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboardX>=1.2\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wandb<0.13.0,>=0.10.0\n",
      "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lmdb>=1.2.1\n",
      "  Downloading lmdb-1.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.5/298.5 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting more-itertools>=8.12.0\n",
      "  Downloading more_itertools-10.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock<3.8,>=3.3\n",
      "  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: torchvision<0.14.0,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from allennlp) (0.13.1+cu116)\n",
      "Collecting transformers<4.21,>=4.1\n",
      "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fairscale==0.4.6\n",
      "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.2/248.2 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.6.5 in /usr/local/lib/python3.9/dist-packages (from allennlp) (3.7)\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.12.0 in /usr/local/lib/python3.9/dist-packages (from allennlp) (3.19.6)\n",
      "Collecting cached-path<1.2.0,>=1.1.3\n",
      "  Downloading cached_path-1.1.6-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: numpy>=1.21.4 in /usr/local/lib/python3.9/dist-packages (from allennlp) (1.23.4)\n",
      "Collecting base58>=2.1.1\n",
      "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (from allennlp-models) (2.4.0)\n",
      "Collecting conllu==4.4.2\n",
      "  Downloading conllu-4.4.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting py-rouge==1.1\n",
      "  Downloading py_rouge-1.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ftfy\n",
      "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting word2number>=1.1\n",
      "  Downloading word2number-1.1.zip (9.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: boto3<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from cached-path<1.2.0,>=1.1.3->allennlp) (1.24.90)\n",
      "Collecting rich<13.0,>=12.1\n",
      "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.0.16\n",
      "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-storage<3.0,>=1.32.0\n",
      "  Downloading google_cloud_storage-2.14.0-py2.py3-none-any.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.0.16->allennlp) (4.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.0.16->allennlp) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.0.16->allennlp) (23.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk>=3.6.5->allennlp) (1.2.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk>=3.6.5->allennlp) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk>=3.6.5->allennlp) (2022.10.31)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.9/dist-packages (from pytest>=6.2.5->allennlp) (1.1.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from pytest>=6.2.5->allennlp) (2.0.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.9/dist-packages (from pytest>=6.2.5->allennlp) (1.0.0)\n",
      "Requirement already satisfied: iniconfig in /usr/local/lib/python3.9/dist-packages (from pytest>=6.2.5->allennlp) (2.0.0)\n",
      "Collecting attrs>=19.2.0\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.28->allennlp) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.28->allennlp) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.28->allennlp) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.28->allennlp) (2019.11.28)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.1->allennlp) (3.1.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.12)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp39-cp39-manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.10.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (66.1.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.7.9)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.1.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (6.3.0)\n",
      "Collecting thinc<8.1.0,>=8.0.14\n",
      "  Downloading thinc-8.0.17-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (668 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m668.8/668.8 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.4.5)\n",
      "Collecting protobuf<4.0.0,>=3.12.0\n",
      "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision<0.14.0,>=0.8.1->allennlp) (9.2.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers<4.21,>=4.1->allennlp) (0.12.1)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.14.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.3.2)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/lib/python3/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.14.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.3)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (0.4.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.0.11)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (3.1.30)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (5.9.4)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (0.1.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (3.8.3)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (0.18.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (0.70.13)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (2023.1.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (3.2.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (1.5.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (10.0.1)\n",
      "Collecting wcwidth<0.3.0,>=0.2.12\n",
      "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.90 in /usr/local/lib/python3.9/dist-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.27.90)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->allennlp-models) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->allennlp-models) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->allennlp-models) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->allennlp-models) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->allennlp-models) (1.3.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp) (4.0.10)\n",
      "Collecting google-auth<3.0dev,>=2.23.3\n",
      "  Downloading google_auth-2.27.0-py2.py3-none-any.whl (186 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.8/186.8 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Collecting google-resumable-media>=2.6.0\n",
      "  Downloading google_resumable_media-2.7.0-py2.py3-none-any.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-core<3.0dev,>=2.3.0\n",
      "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.16.2-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.2/135.2 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting commonmark<0.10.0,>=0.9.0\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp) (2.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.4,>=2.1.0->allennlp) (2.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->allennlp-models) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->allennlp-models) (2.8.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp) (5.0.0)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl (228 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.7/228.7 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (5.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.4.8)\n",
      "Building wheels for collected packages: fairscale, termcolor, jsonnet, word2number\n",
      "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307222 sha256=862dab20021c71bc24a5563dda627091cee8439c4e0a7d50f9e6a23793ce108d\n",
      "  Stored in directory: /root/.cache/pip/wheels/8d/7b/f9/6c7a350821ca240450550801e17996aee846b71caaccda7a32\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4833 sha256=4715c0ab03d8f63d0194d74b469e910d5fe64e0f6a8bae4d5c1a0f59acef8263\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/00/51/e04e70a050b271a6aac779726204a324ada2b39b99334175c3\n",
      "  Building wheel for jsonnet (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jsonnet: filename=jsonnet-0.20.0-cp39-cp39-linux_x86_64.whl size=6619656 sha256=dca1cf60233089c97d8b48e377e758938f9d3b3b64d0dc99c6fab7414e6be9a9\n",
      "  Stored in directory: /root/.cache/pip/wheels/77/1a/fe/4d7df1823604150f77a6877f88fc6236d7c56d92a4d15e8b8c\n",
      "  Building wheel for word2number (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5566 sha256=b15471cae939694e62d92373aa68830dd66e52f68e7f59b111004f1ef7308556\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/1d/b2/768b65901d249c6eb2a8d9c30392506555a4e94055ba4e0aa0\n",
      "Successfully built fairscale termcolor jsonnet word2number\n",
      "Installing collected packages: word2number, wcwidth, termcolor, py-rouge, lmdb, jsonnet, commonmark, sacremoses, rich, pydantic, protobuf, more-itertools, google-crc32c, ftfy, filelock, conllu, base58, attrs, thinc, tensorboardX, huggingface-hub, googleapis-common-protos, google-resumable-media, google-auth, fairscale, wandb, transformers, spacy, google-api-core, google-cloud-core, google-cloud-storage, cached-path, allennlp, allennlp-models\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.6\n",
      "    Uninstalling wcwidth-0.2.6:\n",
      "      Successfully uninstalled wcwidth-0.2.6\n",
      "  Attempting uninstall: termcolor\n",
      "    Found existing installation: termcolor 2.2.0\n",
      "    Uninstalling termcolor-2.2.0:\n",
      "      Successfully uninstalled termcolor-2.2.0\n",
      "  Attempting uninstall: rich\n",
      "    Found existing installation: rich 13.2.0\n",
      "    Uninstalling rich-13.2.0:\n",
      "      Successfully uninstalled rich-13.2.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.9.2\n",
      "    Uninstalling pydantic-1.9.2:\n",
      "      Successfully uninstalled pydantic-1.9.2\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.9.0\n",
      "    Uninstalling filelock-3.9.0:\n",
      "      Successfully uninstalled filelock-3.9.0\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 18.2.0\n",
      "    Uninstalling attrs-18.2.0:\n",
      "      Successfully uninstalled attrs-18.2.0\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.1.7\n",
      "    Uninstalling thinc-8.1.7:\n",
      "      Successfully uninstalled thinc-8.1.7\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.12.0\n",
      "    Uninstalling huggingface-hub-0.12.0:\n",
      "      Successfully uninstalled huggingface-hub-0.12.0\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.16.0\n",
      "    Uninstalling google-auth-2.16.0:\n",
      "      Successfully uninstalled google-auth-2.16.0\n",
      "  Attempting uninstall: wandb\n",
      "    Found existing installation: wandb 0.13.4\n",
      "    Uninstalling wandb-0.13.4:\n",
      "      Successfully uninstalled wandb-0.13.4\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.21.3\n",
      "    Uninstalling transformers-4.21.3:\n",
      "      Successfully uninstalled transformers-4.21.3\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.4.1\n",
      "    Uninstalling spacy-3.4.1:\n",
      "      Successfully uninstalled spacy-3.4.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "gradient 2.0.6 requires attrs<=19, but you have attrs 23.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed allennlp-2.10.1 allennlp-models-2.10.1 attrs-23.2.0 base58-2.1.1 cached-path-1.1.6 commonmark-0.9.1 conllu-4.4.2 fairscale-0.4.6 filelock-3.7.1 ftfy-6.1.3 google-api-core-2.16.2 google-auth-2.27.0 google-cloud-core-2.4.1 google-cloud-storage-2.14.0 google-crc32c-1.5.0 google-resumable-media-2.7.0 googleapis-common-protos-1.62.0 huggingface-hub-0.10.1 jsonnet-0.20.0 lmdb-1.4.1 more-itertools-10.2.0 protobuf-3.20.3 py-rouge-1.1 pydantic-1.8.2 rich-12.6.0 sacremoses-0.1.1 spacy-3.3.3 tensorboardX-2.6.2.2 termcolor-1.1.0 thinc-8.0.17 transformers-4.20.1 wandb-0.12.21 wcwidth-0.2.13 word2number-1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pycuda\n",
    "!pip install allennlp allennlp-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadro P5000\n"
     ]
    }
   ],
   "source": [
    "# get name / id of cuda device\n",
    "import pycuda.driver as cuda\n",
    "\n",
    "cuda.init()\n",
    "device = cuda.Device(0)\n",
    "print(device.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def batched_extract_srl_components(batched_sentences, predictor):\n",
    "    # Convert each sentence into the required format for the predictor\n",
    "    batched_sentences = [{'sentence': sentence} for sentence in batched_sentences]\n",
    "\n",
    "    # Prepare the batched input for the predictor\n",
    "    batched_srl = predictor.predict_batch_json(batched_sentences)\n",
    "\n",
    "    # Extract SRL components from the batched predictions\n",
    "    results = []\n",
    "    for index, srl in enumerate(batched_srl):\n",
    "        sentence_results = []\n",
    "        for verb_entry in srl['verbs']:\n",
    "            arg_components = {'ARG0': [], 'ARG1': []}\n",
    "            for i, tag in enumerate(verb_entry['tags']):\n",
    "                if 'ARG0' in tag:\n",
    "                    arg_components['ARG0'].append(srl['words'][i])\n",
    "                elif 'ARG1' in tag:\n",
    "                    arg_components['ARG1'].append(srl['words'][i])\n",
    "\n",
    "            if arg_components['ARG0'] or arg_components['ARG1']:\n",
    "                sentence_results.append({\n",
    "                    'predicate': verb_entry['verb'],\n",
    "                    'ARG0': ' '.join(arg_components['ARG0']),\n",
    "                    'ARG1': ' '.join(arg_components['ARG1'])\n",
    "                })\n",
    "\n",
    "        if sentence_results:\n",
    "            # add empty dict if predicate, arg0 or arg1 is empty\n",
    "            if not sentence_results[0]['predicate']:\n",
    "                results.append({'predicate': '', 'ARG0': '', 'ARG1': ''})\n",
    "            elif not sentence_results[0]['ARG0']:\n",
    "                results.append({'predicate': '', 'ARG0': '', 'ARG1': ''})\n",
    "            elif not sentence_results[0]['ARG1']:\n",
    "                results.append({'predicate': '', 'ARG0': '', 'ARG1': ''})\n",
    "            else:\n",
    "                results.append(sentence_results)    \n",
    "        else:\n",
    "            results.append([{'predicate': '', 'ARG0': '', 'ARG1': ''}])\n",
    "\n",
    "    return results\n",
    "\n",
    "def optimized_extract_srl(X, predictor, batch_size=32):\n",
    "    all_results = []\n",
    "\n",
    "    # Process sentences in batches\n",
    "    for i in tqdm(range(0, len(X), batch_size), desc=\"Processing Batches\"):\n",
    "        batched_sentences = X[i:i+batch_size]\n",
    "\n",
    "        batch_results = batched_extract_srl_components(batched_sentences, predictor)\n",
    "\n",
    "        all_results.extend(batch_results)\n",
    "\n",
    "    return pd.Series(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def get_X_srl(X, recalculate=False, pickle_path=\"../notebooks/classifier/X_srl_filtered.pkl\"):\n",
    "    \"\"\"\n",
    "    Returns the X_srl either by loading from a pickled file or recalculating.\n",
    "    \"\"\"\n",
    "    if recalculate or not os.path.exists(pickle_path):\n",
    "        print(\"Recalculate SRL\")\n",
    "        # Load predictor\n",
    "        predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\", cuda_device=0)\n",
    "\n",
    "        # make sentences max 480 chars long\n",
    "        X = X.apply(lambda x: x[:480])\n",
    "\n",
    "        X_srl = optimized_extract_srl(X, predictor, batch_size=32)\n",
    "        with open(pickle_path, 'wb') as f:\n",
    "            pickle.dump(X_srl, f)\n",
    "    else:\n",
    "        print(\"Load SRL from Pickle\")\n",
    "        with tqdm(total=os.path.getsize(pickle_path)) as pbar:\n",
    "            with open(pickle_path, 'rb') as f:\n",
    "                X_srl = pickle.load(f)\n",
    "                pbar.update(os.path.getsize(pickle_path))\n",
    "                \n",
    "    return X_srl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_X_srl(df[\"text\"], recalculate=False, pickle_path=\"../notebooks/FRISS_srl.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def free_gpu():\n",
    "    print(torch.cuda.mem_get_info())\n",
    "    print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/distributed/distributed_c10d.py:181: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "def list_gpu_tensors():\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            if torch.is_tensor(obj):\n",
    "                if obj.is_cuda:\n",
    "                    obj = obj.cpu()\n",
    "                    obj = obj.to(\"cpu\")\n",
    "                    print(type(obj), obj.size())\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "list_gpu_tensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "class ArticleDataset(Dataset):\n",
    "    def __init__(self, X, X_srl, tokenizer, labels=None, max_sentences_per_article=32, max_sentence_length=32, max_args_per_sentence=10, max_arg_length=16):\n",
    "        self.X = X  # DataFrame where each row has multiple sentences\n",
    "        self.X_srl = X_srl  # DataFrame where each row has multiple dictionaries for SRL\n",
    "        self.labels = labels  # DataFrame where each row has a list of lists of integers\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_sentences_per_article = max_sentences_per_article\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.max_args_per_sentence = max_args_per_sentence\n",
    "        self.max_arg_length = max_arg_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentences = self.X.iloc[idx]\n",
    "        srl_data = self.X_srl.iloc[idx]\n",
    "        labels = self.labels.iloc[idx]\n",
    "\n",
    "        # Tokenize sentences and get attention masks\n",
    "        sentence_ids, sentence_attention_masks = [], []\n",
    "        for sentence in sentences:\n",
    "            encoded = self.tokenizer(sentence, add_special_tokens=True, max_length=self.max_sentence_length, truncation=True, padding='max_length', return_attention_mask=True)\n",
    "            sentence_ids.append(encoded['input_ids'])\n",
    "            sentence_attention_masks.append(encoded['attention_mask'])\n",
    "\n",
    "        # Padding for sentences if necessary\n",
    "        while len(sentence_ids) < self.max_sentences_per_article:\n",
    "            sentence_ids.append([0] * self.max_sentence_length)\n",
    "            sentence_attention_masks.append([0] * self.max_sentence_length)\n",
    "\n",
    "        sentence_ids = sentence_ids[:self.max_sentences_per_article]\n",
    "        sentence_attention_masks = sentence_attention_masks[:self.max_sentences_per_article]\n",
    "\n",
    "        # Process SRL data\n",
    "        predicates, arg0s, arg1s = [], [], []\n",
    "        predicate_attention_masks, arg0_attention_masks, arg1_attention_masks = [], [], []\n",
    "        for srl_items in srl_data:\n",
    "            sentence_predicates, sentence_arg0s, sentence_arg1s = [], [], []\n",
    "            sentence_predicate_masks, sentence_arg0_masks, sentence_arg1_masks = [], [], []\n",
    "\n",
    "            if not isinstance(srl_items, list):\n",
    "                srl_items = [srl_items]\n",
    "\n",
    "            for item in srl_items:\n",
    "                encoded_predicate = self.tokenizer(item[\"predicate\"], add_special_tokens=True, max_length=self.max_arg_length, truncation=True, padding='max_length', return_attention_mask=True)\n",
    "                encoded_arg0 = self.tokenizer(item[\"ARG0\"], add_special_tokens=True, max_length=self.max_arg_length, truncation=True, padding='max_length', return_attention_mask=True)\n",
    "                encoded_arg1 = self.tokenizer(item[\"ARG1\"], add_special_tokens=True, max_length=self.max_arg_length, truncation=True, padding='max_length', return_attention_mask=True)\n",
    "\n",
    "                sentence_predicates.append(encoded_predicate['input_ids'])\n",
    "                sentence_arg0s.append(encoded_arg0['input_ids'])\n",
    "                sentence_arg1s.append(encoded_arg1['input_ids'])\n",
    "\n",
    "                sentence_predicate_masks.append(encoded_predicate['attention_mask'])\n",
    "                sentence_arg0_masks.append(encoded_arg0['attention_mask'])\n",
    "                sentence_arg1_masks.append(encoded_arg1['attention_mask'])\n",
    "\n",
    "            # Padding for SRL elements\n",
    "            for _ in range(self.max_args_per_sentence):\n",
    "                sentence_predicates.append([0] * self.max_arg_length)\n",
    "                sentence_arg0s.append([0] * self.max_arg_length)\n",
    "                sentence_arg1s.append([0] * self.max_arg_length)\n",
    "\n",
    "                sentence_predicate_masks.append([0] * self.max_arg_length)\n",
    "                sentence_arg0_masks.append([0] * self.max_arg_length)\n",
    "                sentence_arg1_masks.append([0] * self.max_arg_length)\n",
    "\n",
    "            sentence_predicates = sentence_predicates[:self.max_args_per_sentence]\n",
    "            sentence_arg0s = sentence_arg0s[:self.max_args_per_sentence]\n",
    "            sentence_arg1s = sentence_arg1s[:self.max_args_per_sentence]\n",
    "\n",
    "            sentence_predicate_masks = sentence_predicate_masks[:self.max_args_per_sentence]\n",
    "            sentence_arg0_masks = sentence_arg0_masks[:self.max_args_per_sentence]\n",
    "            sentence_arg1_masks = sentence_arg1_masks[:self.max_args_per_sentence]\n",
    "\n",
    "            predicates.append(sentence_predicates)\n",
    "            arg0s.append(sentence_arg0s)\n",
    "            arg1s.append(sentence_arg1s)\n",
    "\n",
    "            predicate_attention_masks.append(sentence_predicate_masks)\n",
    "            arg0_attention_masks.append(sentence_arg0_masks)\n",
    "            arg1_attention_masks.append(sentence_arg1_masks)\n",
    "\n",
    "        # Padding for SRL data\n",
    "        srl_padding = [[0] * self.max_arg_length] * self.max_args_per_sentence\n",
    "        mask_padding = [[0] * self.max_arg_length] * self.max_args_per_sentence\n",
    "\n",
    "        predicates = (predicates + [srl_padding] * self.max_sentences_per_article)[:self.max_sentences_per_article]\n",
    "        arg0s = (arg0s + [srl_padding] * self.max_sentences_per_article)[:self.max_sentences_per_article]\n",
    "        arg1s = (arg1s + [srl_padding] * self.max_sentences_per_article)[:self.max_sentences_per_article]\n",
    "\n",
    "        predicate_attention_masks = (predicate_attention_masks + [mask_padding] * self.max_sentences_per_article)[:self.max_sentences_per_article]\n",
    "        arg0_attention_masks = (arg0_attention_masks + [mask_padding] * self.max_sentences_per_article)[:self.max_sentences_per_article]\n",
    "        arg1_attention_masks = (arg1_attention_masks + [mask_padding] * self.max_sentences_per_article)[:self.max_sentences_per_article]\n",
    "\n",
    "        data = {\n",
    "            'sentence_ids': torch.tensor(sentence_ids, dtype=torch.long),\n",
    "            'sentence_attention_masks': torch.tensor(sentence_attention_masks, dtype=torch.long),\n",
    "            'predicate_ids': torch.tensor(predicates, dtype=torch.long),\n",
    "            'predicate_attention_masks': torch.tensor(predicate_attention_masks, dtype=torch.long),\n",
    "            'arg0_ids': torch.tensor(arg0s, dtype=torch.long),\n",
    "            'arg0_attention_masks': torch.tensor(arg0_attention_masks, dtype=torch.long),\n",
    "            'arg1_ids': torch.tensor(arg1s, dtype=torch.long),\n",
    "            'arg1_attention_masks': torch.tensor(arg1_attention_masks, dtype=torch.long),\n",
    "            'labels': torch.tensor(labels[0], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    # Extract individual lists from the batch\n",
    "    sentence_ids = [item['sentence_ids'] for item in batch]\n",
    "    sentence_attention_masks = [item['sentence_attention_masks'] for item in batch]\n",
    "    predicate_ids = [item['predicate_ids'] for item in batch]\n",
    "    predicate_attention_masks = [item['predicate_attention_masks'] for item in batch]\n",
    "    arg0_ids = [item['arg0_ids'] for item in batch]\n",
    "    arg0_attention_masks = [item['arg0_attention_masks'] for item in batch]\n",
    "    arg1_ids = [item['arg1_ids'] for item in batch]\n",
    "    arg1_attention_masks = [item['arg1_attention_masks'] for item in batch]\n",
    "    labels = [item['labels'] for item in batch]\n",
    "    \n",
    "    # Pad each list\n",
    "    sentence_ids = torch.nn.utils.rnn.pad_sequence(sentence_ids, batch_first=True, padding_value=0)\n",
    "    sentence_attention_masks = torch.nn.utils.rnn.pad_sequence(sentence_attention_masks, batch_first=True, padding_value=0)\n",
    "    predicate_ids = torch.nn.utils.rnn.pad_sequence(predicate_ids, batch_first=True, padding_value=0)\n",
    "    predicate_attention_masks = torch.nn.utils.rnn.pad_sequence(predicate_attention_masks, batch_first=True, padding_value=0)\n",
    "    arg0_ids = torch.nn.utils.rnn.pad_sequence(arg0_ids, batch_first=True, padding_value=0)\n",
    "    arg0_attention_masks = torch.nn.utils.rnn.pad_sequence(arg0_attention_masks, batch_first=True, padding_value=0)\n",
    "    arg1_ids = torch.nn.utils.rnn.pad_sequence(arg1_ids, batch_first=True, padding_value=0)\n",
    "    arg1_attention_masks = torch.nn.utils.rnn.pad_sequence(arg1_attention_masks, batch_first=True, padding_value=0)\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=0)\n",
    "\n",
    "    # Create the output dictionary\n",
    "    output_dict = {\n",
    "        'sentence_ids': sentence_ids,\n",
    "        'sentence_attention_masks': sentence_attention_masks,\n",
    "        'predicate_ids': predicate_ids,\n",
    "        'predicate_attention_masks': predicate_attention_masks,\n",
    "        'arg0_ids': arg0_ids,\n",
    "        'arg0_attention_masks': arg0_attention_masks,\n",
    "        'arg1_ids': arg1_ids,\n",
    "        'arg1_attention_masks': arg1_attention_masks,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "def preprocess_df(df, recalculate_srl=False, pickle_path=\"../notebooks/FRISS_srl.pkl\", ignore_y=False):\n",
    "    # reset index of df\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Get X_srl\n",
    "    X_srl = get_X_srl(df[\"text\"], recalculate=recalculate_srl, pickle_path=pickle_path)\n",
    "\n",
    "    # reset index of X_srl\n",
    "    X_srl = X_srl.reset_index(drop=True)\n",
    "\n",
    "    # Aggregating 'text' column in df into a list of strings for each article_id\n",
    "    X_subset = df.groupby('article_id')['text'].apply(list).reset_index(name='text')\n",
    "    X_subset = X_subset['text']\n",
    "\n",
    "    # Assuming X_srl follows the same index order as df\n",
    "    X_srl_subset = X_srl.groupby(df['article_id']).apply(lambda x: x.values.tolist()).reset_index(name='srl_values')\n",
    "    X_srl_subset = X_srl_subset['srl_values']\n",
    "\n",
    "    if not ignore_y:\n",
    "        # Columns to be one-hot encoded in y_subset\n",
    "        y_cols = ['Capacity and Resources', 'Crime and Punishment', 'Cultural Identity', \n",
    "                'Economic', 'External Regulation and Reputation', 'Fairness and Equality', \n",
    "                'Health and Safety', 'Legality, Constitutionality, Jurisdiction', \n",
    "                'Morality', 'Other', 'Policy Prescription and Evaluation', 'Political', \n",
    "                'Public Sentiment', 'Quality of Life', 'Security and Defense']\n",
    "\n",
    "        # Creating y_subset\n",
    "        y_subset = df.groupby('article_id')[y_cols].apply(lambda x: x.values.tolist()).reset_index(name='encoded_values')\n",
    "        y_subset = y_subset['encoded_values']\n",
    "\n",
    "    return X_subset, X_srl_subset, y_subset\n",
    "\n",
    "def get_datasets_dataloaders(df, tokenizer, recalculate_srl=False, pickle_path=\"../notebooks/FRISS_srl.pkl\", batch_size=16, max_sentences_per_article=32, max_sentence_length=32,  max_args_per_sentence=10,  max_arg_length=16, test_size=0.1):\n",
    "    \n",
    "    X_subset, X_srl_subset, y_subset = preprocess_df(df, recalculate_srl=recalculate_srl, pickle_path=pickle_path)\n",
    "\n",
    "    # Len\n",
    "    print(\"X:\", len(X_subset))\n",
    "    print(\"X_srl:\", len(X_srl_subset))\n",
    "    print(\"y:\", len(y_subset))\n",
    "\n",
    "    print(\"CREATING DATASETS\")\n",
    "    \n",
    "    # Assuming X, X_srl, and y are already defined and have the same number of samples\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_subset, y_subset, test_size=test_size, random_state=42)\n",
    "    \n",
    "    print(\"TRAIN TEST SPLIT DONE\")\n",
    "    \n",
    "    X_srl_train, X_srl_test, _, _ = train_test_split(X_srl_subset, y_subset, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Create the dataset\n",
    "    train_dataset = ArticleDataset(X_train, X_srl_train, tokenizer, y_train, max_sentences_per_article, max_sentence_length,  max_args_per_sentence, max_arg_length)\n",
    "    test_dataset = ArticleDataset(X_test, X_srl_test, tokenizer, y_test, max_sentences_per_article, max_sentence_length, max_args_per_sentence, max_arg_length)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn, drop_last=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn, drop_last=True)\n",
    "    \n",
    "    print(\"CREATION DONE\")\n",
    "    return train_dataset, test_dataset , train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79629f6c42584c16ba9d9c0521c603b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf88c67e7c414853a61fade8223efda8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6840e463be9240f4860c210ae84fc6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81f4756c6d54fe0965f6c71fff95b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load SRL from Pickle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650061a4a26547439da6993a42341e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10211714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 6097\n",
      "X_srl: 6097\n",
      "y: 6097\n",
      "CREATING DATASETS\n",
      "TRAIN TEST SPLIT DONE\n",
      "CREATION DONE\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "max_sentences_per_article = 24\n",
    "max_sentence_length = 32\n",
    "\n",
    "max_args_per_sentence = 10\n",
    "max_arg_length = 8\n",
    "\n",
    "test_size = 0.2\n",
    "\n",
    "train_dataset, test_dataset, train_dataloader, test_dataloader = get_datasets_dataloaders(df, tokenizer, recalculate_srl=False, batch_size=batch_size, max_sentences_per_article=max_sentences_per_article, max_sentence_length=max_sentence_length, max_arg_length=max_arg_length, pickle_path=\"data/srls/mfc/FRISS_srl.pkl\", test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Model\n",
    "The Model consist out of various Layers.\n",
    "\n",
    "1. SRL_Embedding\n",
    "2. Autoencoder\n",
    "3. FRISSLoss\n",
    "4. Unsupervised\n",
    "5. Supervised\n",
    "6. FRISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SRL_Embeddings\n",
    "\n",
    "The layer takes tensors of token IDs with the shape [batch_size, max_num_sentences, max_num_tokens] for the sentence, predicates, arg0 and arg1 and returns for each sentence an embedding with shape [batch_size, embedding_dim] for the sentence, predicate, arg0 and arg1. \n",
    "\n",
    "The single embedding for the sentence is extracted by taking the [CLS] token embedding. For the predicate, arg0 and arg1 by taking the mean over all word embeddings in this list of tokens. \n",
    "\n",
    "> Possible improvements: Better way of extracting the single embedding for predicate, arg0 and arg1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d6eec9f7364751ae2508b0e351de0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shapes:  torch.Size([2, 12, 8]) torch.Size([2, 12, 9, 8]) torch.Size([2, 12, 9, 8]) torch.Size([2, 12, 9, 8])\n",
      "Outputs shapes:  torch.Size([2, 12, 768]) torch.Size([2, 12, 9, 768]) torch.Size([2, 12, 9, 768]) torch.Size([2, 12, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class SRL_Embeddings(nn.Module):\n",
    "    def __init__(self, bert_model_name=\"bert-base-uncased\"):\n",
    "        super(SRL_Embeddings, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(bert_model_name)\n",
    "        self.embedding_dim = 768  # for bert-base-uncased\n",
    "\n",
    "    def forward(self, sentence_ids, sentence_attention_masks, predicate_ids, predicate_attention_masks, arg0_ids, arg0_attention_masks, arg1_ids, arg1_attention_masks):\n",
    "        with torch.no_grad():\n",
    "            # Sentence embeddings\n",
    "            sentence_embeddings = self.bert_model(input_ids=sentence_ids.view(-1, sentence_ids.size(-1)), \n",
    "                                                  attention_mask=sentence_attention_masks.view(-1, sentence_attention_masks.size(-1)))[0]\n",
    "            sentence_embeddings = sentence_embeddings.view(sentence_ids.size(0), sentence_ids.size(1), -1, self.embedding_dim)\n",
    "            sentence_embeddings = sentence_embeddings.mean(dim=2)\n",
    "\n",
    "            # Predicate embeddings\n",
    "            predicate_embeddings = self.bert_model(input_ids=predicate_ids.view(-1, predicate_ids.size(-1)), \n",
    "                                                   attention_mask=predicate_attention_masks.view(-1, predicate_attention_masks.size(-1)))[0]\n",
    "            predicate_embeddings = predicate_embeddings.view(predicate_ids.size(0), predicate_ids.size(1), predicate_ids.size(2), -1, self.embedding_dim)\n",
    "            predicate_embeddings = predicate_embeddings.mean(dim=3)\n",
    "\n",
    "            # ARG0 embeddings\n",
    "            arg0_embeddings = self.bert_model(input_ids=arg0_ids.view(-1, arg0_ids.size(-1)), \n",
    "                                              attention_mask=arg0_attention_masks.view(-1, arg0_attention_masks.size(-1)))[0]\n",
    "            arg0_embeddings = arg0_embeddings.view(arg0_ids.size(0), arg0_ids.size(1), arg0_ids.size(2), -1, self.embedding_dim)\n",
    "            arg0_embeddings = arg0_embeddings.mean(dim=3)\n",
    "\n",
    "            # ARG1 embeddings\n",
    "            arg1_embeddings = self.bert_model(input_ids=arg1_ids.view(-1, arg1_ids.size(-1)), \n",
    "                                              attention_mask=arg1_attention_masks.view(-1, arg1_attention_masks.size(-1)))[0]\n",
    "            arg1_embeddings = arg1_embeddings.view(arg1_ids.size(0), arg1_ids.size(1), arg1_ids.size(2), -1, self.embedding_dim)\n",
    "            arg1_embeddings = arg1_embeddings.mean(dim=3)\n",
    "\n",
    "        return sentence_embeddings, predicate_embeddings, arg0_embeddings, arg1_embeddings\n",
    "\n",
    "# Generate dummy data for the SRL_Embeddings\n",
    "batch_size = 2\n",
    "num_sentences = 12\n",
    "sentence_length = 8\n",
    "num_args = 9\n",
    "predicate_length = 8\n",
    "arg0_length = 8\n",
    "arg1_length = 8\n",
    "\n",
    "# Dummy data for sentences, predicates, arg0, and arg1\n",
    "sentence_ids = torch.randint(0, 10000, (batch_size, num_sentences, sentence_length))\n",
    "predicate_ids = torch.randint(0, 10000, (batch_size, num_sentences, num_args, predicate_length))\n",
    "arg0_ids = torch.randint(0, 10000, (batch_size, num_sentences, num_args, arg0_length))\n",
    "arg1_ids = torch.randint(0, 10000, (batch_size, num_sentences, num_args, arg1_length))\n",
    "\n",
    "# Mock attention masks\n",
    "sentence_attention_masks = torch.randint(0, 2, (batch_size, num_sentences, sentence_length))\n",
    "predicate_attention_masks = torch.randint(0, 2, (batch_size, num_sentences, num_args, predicate_length))\n",
    "arg0_attention_masks = torch.randint(0, 2, (batch_size, num_sentences, num_args, arg0_length))\n",
    "arg1_attention_masks = torch.randint(0, 2, (batch_size, num_sentences, num_args, arg1_length))\n",
    "\n",
    "srl_embeddings = SRL_Embeddings()\n",
    "\n",
    "sentence_embeddings, predicate_embeddings, arg0_embeddings, arg1_embeddings = srl_embeddings(\n",
    "    sentence_ids, sentence_attention_masks, \n",
    "    predicate_ids, predicate_attention_masks, \n",
    "    arg0_ids, arg0_attention_masks, \n",
    "    arg1_ids, arg1_attention_masks\n",
    ")\n",
    "\n",
    "print(\"Inputs shapes: \", sentence_ids.shape, predicate_ids.shape, arg0_ids.shape, arg1_ids.shape)\n",
    "print(\"Outputs shapes: \", sentence_embeddings.shape, predicate_embeddings.shape, arg0_embeddings.shape, arg1_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shapes:\n",
      "p -> vhat: torch.Size([2, 768]), d: torch.Size([2, 20]), g: torch.Size([2, 20]), F: torch.Size([20, 768])\n",
      "a0 -> vhat: torch.Size([2, 768]), d: torch.Size([2, 20]), g: torch.Size([2, 20]), F: torch.Size([20, 768])\n",
      "a1 -> vhat: torch.Size([2, 768]), d: torch.Size([2, 20]), g: torch.Size([2, 20]), F: torch.Size([20, 768])\n",
      "NaN values:\n",
      "p -> vhat: False, d: False, g: False, F: False\n",
      "g:  tensor([[0.0904, 0.0321, 0.0061, 0.0188, 0.0133, 0.0126, 0.0078, 0.0335, 0.3479,\n",
      "         0.0233, 0.0044, 0.0059, 0.0246, 0.0055, 0.0642, 0.0214, 0.1052, 0.1214,\n",
      "         0.0434, 0.0182],\n",
      "        [0.0385, 0.0125, 0.0035, 0.0155, 0.0060, 0.3611, 0.4571, 0.0204, 0.0068,\n",
      "         0.0024, 0.0055, 0.0109, 0.0066, 0.0031, 0.0104, 0.0020, 0.0026, 0.0171,\n",
      "         0.0032, 0.0147]], grad_fn=<SoftmaxBackward0>)\n",
      "a0 -> vhat: False, d: False, g: False, F: False\n",
      "g:  tensor([[0.1073, 0.0151, 0.0063, 0.1300, 0.0168, 0.1673, 0.0110, 0.0235, 0.0585,\n",
      "         0.0330, 0.0284, 0.0516, 0.0458, 0.0206, 0.0394, 0.0227, 0.1882, 0.0095,\n",
      "         0.0188, 0.0062],\n",
      "        [0.3932, 0.0330, 0.2121, 0.0063, 0.0168, 0.0222, 0.0687, 0.0096, 0.0235,\n",
      "         0.0026, 0.0241, 0.0047, 0.0344, 0.0217, 0.0025, 0.0069, 0.0832, 0.0247,\n",
      "         0.0015, 0.0085]], grad_fn=<SoftmaxBackward0>)\n",
      "a1 -> vhat: False, d: False, g: False, F: False\n",
      "g:  tensor([[0.0111, 0.0076, 0.0168, 0.1650, 0.0293, 0.0037, 0.0510, 0.0032, 0.0845,\n",
      "         0.3719, 0.0602, 0.0085, 0.0338, 0.0206, 0.0128, 0.0205, 0.0165, 0.0549,\n",
      "         0.0069, 0.0210],\n",
      "        [0.4078, 0.0968, 0.1626, 0.0018, 0.0019, 0.0333, 0.0166, 0.0331, 0.0080,\n",
      "         0.0146, 0.0026, 0.0154, 0.0827, 0.0677, 0.0099, 0.0096, 0.0015, 0.0099,\n",
      "         0.0150, 0.0091]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import log_softmax, softmax\n",
    "\n",
    "class CombinedAutoencoder(nn.Module):\n",
    "    def __init__(self, D_w, D_h, K, dropout_prob=0.3):\n",
    "        super(CombinedAutoencoder, self).__init__()\n",
    "        \n",
    "        self.D_h = D_h\n",
    "        self.K = K\n",
    "        \n",
    "        # Shared feed-forward layer for all views\n",
    "        self.feed_forward_shared = nn.Linear(2 * D_w, D_h)\n",
    "        \n",
    "        # Unique feed-forward layers for each view\n",
    "        self.feed_forward_unique = nn.ModuleDict({\n",
    "            'a0': nn.Linear(D_h, K),\n",
    "            'p': nn.Linear(D_h, K),\n",
    "            'a1': nn.Linear(D_h, K),\n",
    "        })\n",
    "\n",
    "        # Initializing F matrices for each view\n",
    "        self.F_matrices = nn.ParameterDict({\n",
    "            'a0': nn.Parameter(torch.Tensor(K, D_w)),\n",
    "            'p': nn.Parameter(torch.Tensor(K, D_w)),\n",
    "            'a1': nn.Parameter(torch.Tensor(K, D_w)),\n",
    "        })\n",
    "\n",
    "        # init F matrices with xavier_uniform and nn.init.calculate_gain('relu')\n",
    "        for _, value in self.F_matrices.items():\n",
    "            nn.init.xavier_uniform_(value.data, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "        # Additional layers and parameters\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "        self.batch_norm = nn.BatchNorm1d(D_h)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.activation2 = nn.Sigmoid()\n",
    "\n",
    "    def sample_gumbel(self, shape, eps=1e-20, device='cpu'):\n",
    "        \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "        U = torch.rand(shape, device=device)\n",
    "        return -torch.log(-torch.log(U + eps) + eps)\n",
    "\n",
    "\n",
    "    def gumbel_softmax_sample(self, logits, t):\n",
    "        \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "        y = logits + self.sample_gumbel(logits.size(), device=logits.device)\n",
    "        return softmax(y / t, dim=-1)\n",
    "\n",
    "\n",
    "    def gumbel_logsoftmax_sample(self, logits, t):\n",
    "        \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "        y = logits + self.sample_gumbel(logits.size(), device=logits.device)\n",
    "        return log_softmax(y / t, dim=-1)\n",
    "\n",
    "\n",
    "    def custom_gumbel_softmax(self, logits, tau, hard=False, log=False):\n",
    "        \"\"\"Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
    "        Args:\n",
    "        logits: [batch_size, n_class] unnormalized log-probs\n",
    "        tau: non-negative scalar\n",
    "        hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
    "        Returns:\n",
    "        [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
    "        If hard=True, then the returned sample will be one-hot, otherwise it will\n",
    "        be a probabilitiy distribution that sums to 1 across classes\n",
    "        \"\"\"\n",
    "        if log:\n",
    "            y = self.gumbel_logsoftmax_sample(logits, tau)\n",
    "        else:\n",
    "            y = self.gumbel_softmax_sample(logits, tau)\n",
    "        if hard:\n",
    "            shape = y.size()\n",
    "            _, ind = y.max(dim=-1)\n",
    "            y_hard = torch.zeros_like(y).view(-1, shape[-1])\n",
    "            y_hard.scatter_(1, ind.view(-1, 1), 1)\n",
    "            y_hard = y_hard.view(*shape)\n",
    "            # Set gradients w.r.t. y_hard gradients w.r.t. y\n",
    "            y_hard = (y_hard - y).detach() + y\n",
    "            return y_hard\n",
    "        return y\n",
    "\n",
    "    def forward(self, v_p, v_a0, v_a1, v_sentence, tau):\n",
    "        h_p = self.process_through_shared(v_p, v_sentence)\n",
    "        h_a0 = self.process_through_shared(v_a0, v_sentence)\n",
    "        h_a1 = self.process_through_shared(v_a1, v_sentence)\n",
    "\n",
    "        logits_p = self.feed_forward_unique['p'](h_p)\n",
    "        logits_a0 = self.feed_forward_unique['a0'](h_a0)\n",
    "        logits_a1 = self.feed_forward_unique['a1'](h_a1) \n",
    "\n",
    "        d_p = torch.softmax(logits_p, dim=1)\n",
    "        d_a0 = torch.softmax(logits_a0, dim=1)\n",
    "        d_a1 = torch.softmax(logits_a1, dim=1)\n",
    "        \n",
    "        # TODO - Paper said we pass the output of softmax into the Gumbel-Softmax but code passes the logits\n",
    "\n",
    "        g_p = self.custom_gumbel_softmax(d_p, tau=tau, hard=False, log=False)\n",
    "        g_a0 = self.custom_gumbel_softmax(d_a0, tau=tau, hard=False, log=False)\n",
    "        g_a1 = self.custom_gumbel_softmax(d_a1, tau=tau, hard=False, log=False)\n",
    "\n",
    "        #g_p = self.custom_gumbel_softmax(logits_p, tau=tau, hard=False, log=False)\n",
    "        #g_a0 = self.custom_gumbel_softmax(logits_a0, tau=tau, hard=False, log=False)\n",
    "        #g_a1 = self.custom_gumbel_softmax(logits_a1, tau=tau, hard=False, log=False)\n",
    "\n",
    "        vhat_p = torch.matmul(g_p, self.F_matrices['p'])\n",
    "        vhat_a0 = torch.matmul(g_a0, self.F_matrices['a0'])\n",
    "        vhat_a1 = torch.matmul(g_a1, self.F_matrices['a1'])\n",
    "\n",
    "        return {\n",
    "            \"p\": {\"vhat\": vhat_p, \"d\": d_p, \"g\": g_p, \"F\": self.F_matrices['p']},\n",
    "            \"a0\": {\"vhat\": vhat_a0, \"d\": d_a0, \"g\": g_a0, \"F\": self.F_matrices['a0']},\n",
    "            \"a1\": {\"vhat\": vhat_a1, \"d\": d_a1, \"g\": g_a1, \"F\": self.F_matrices['a1']}\n",
    "        }\n",
    "        \n",
    "    def process_through_shared(self, v_z, v_sentence):\n",
    "        # Concatenating v_z with the sentence embedding\n",
    "        concatenated = torch.cat((v_z, v_sentence), dim=-1)\n",
    "        \n",
    "        # Applying dropout\n",
    "        dropped = self.dropout1(concatenated)\n",
    "\n",
    "        # Passing through the shared linear layer\n",
    "        h_shared = self.feed_forward_shared(dropped)\n",
    "\n",
    "        # Applying batch normalization and ReLU activation\n",
    "        h_shared = self.batch_norm(h_shared)\n",
    "        h_shared = self.activation(h_shared)\n",
    "\n",
    "        # Applying dropout again\n",
    "        h_shared = self.dropout2(h_shared)\n",
    "\n",
    "        return h_shared\n",
    "\n",
    "# Mock Data Preparation\n",
    "D_h = 768\n",
    "batch_size = 2\n",
    "embedding_dim = 768\n",
    "K = 20\n",
    "tau = 0.9\n",
    "\n",
    "# Generating mock embeddings for article, predicate, ARG0, ARG1, and their corresponding sentence embeddings\n",
    "article_embedding = torch.randn(batch_size, embedding_dim)\n",
    "v_p = torch.randn(batch_size, embedding_dim)\n",
    "v_a0 = torch.randn(batch_size, embedding_dim)\n",
    "v_a1 = torch.randn(batch_size, embedding_dim)\n",
    "\n",
    "# Testing CombinedAutoencoder\n",
    "autoencoder = CombinedAutoencoder(embedding_dim, D_h, K)\n",
    "outputs = autoencoder(v_p, v_a0, v_a1, article_embedding, tau)\n",
    "\n",
    "# Check shapes of the outputs\n",
    "print(\"Output shapes:\")\n",
    "for key, value in outputs.items():\n",
    "    print(f\"{key} -> vhat: {value['vhat'].shape}, d: {value['d'].shape}, g: {value['g'].shape}, F: {value['F'].shape}\")\n",
    "\n",
    "# check if tensor have nan values\n",
    "def check_nan(tensor):\n",
    "    # if tensor has any nan values, return True\n",
    "    if torch.isnan(tensor).any():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Check if any of the outputs have NaN values\n",
    "print(\"NaN values:\")\n",
    "for key, value in outputs.items():\n",
    "    print(f\"{key} -> vhat: {check_nan(value['vhat'])}, d: {check_nan(value['d'])}, g: {check_nan(value['g'])}, F: {check_nan(value['F'])}\")\n",
    "    print(f\"g: \", value['g'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FRISSLoss\n",
    "\n",
    "The layer calculates the unsupervised loss for predicate, arg0 and arg1. \n",
    "\n",
    "The forward function takes as input 3 dicts with the parameters `v`, `v_hat`, `g` and `F`. Where `v` is the embedding of the predicate, arg0 or arg1. The `v_hat` (size: [batch_size, embedding_dim]) is the reconstructed embedding for the predicate, arg0 and arg1. The `g` is the gumbel softmax result (size: [batch_size, embedding_dim]). The `F` (size: [K, embedding_dim]) which is the descriptor dictionary.\n",
    "\n",
    "The layer returns the loss for each batch. So the output is [batch_size]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRiSSLoss output: tensor([783961.4375, 783958.6875])\n"
     ]
    }
   ],
   "source": [
    "class FRISSLoss(nn.Module):\n",
    "    def __init__(self, lambda_orthogonality, M, t):\n",
    "        super(FRISSLoss, self).__init__()\n",
    "        \n",
    "        self.lambda_orthogonality = lambda_orthogonality\n",
    "        self.M = M\n",
    "        self.t = t\n",
    "        self.triplet_loss = nn.TripletMarginLoss(margin=M)\n",
    "\n",
    "    def contrastive_loss(self, v, vhat, negatives):\n",
    "        batch_size = vhat.size(0)\n",
    "        N = negatives.size(0)\n",
    "        loss = torch.zeros(batch_size, device=v.device)\n",
    "\n",
    "        # Calculate true distance between reconstructed and real embeddings\n",
    "        true_distance = self.l2(vhat, v)\n",
    "\n",
    "        for i in range(N):  # loop over each element in \"negatives\"\n",
    "            \n",
    "            # Tranform negative from [embedding dim] to [batch size, embedding_dim] \n",
    "            negative = negatives[i, :].expand(v.size(0), -1)\n",
    "\n",
    "            # Calculate negative distance for current negative embedding\n",
    "            negative_distance = self.l2(vhat, negative)\n",
    "\n",
    "            # Compute loss based on the provided logic: l2(vhat, v) + 1 + l2(vhat, negative) and clamp to 0 if below 0\n",
    "            current_loss = 1 + true_distance - negative_distance\n",
    "            loss += torch.clamp(current_loss, min=0.0)\n",
    "\n",
    "        # Normalize the total loss by N\n",
    "        return loss / N\n",
    "\n",
    "    \n",
    "    def l2(self, u, v):\n",
    "        return torch.sqrt(torch.sum((u - v) ** 2, dim=1))\n",
    "    \n",
    "    def focal_triplet_loss_WRONG(self, v, vhat_z, g, F):\n",
    "        losses = []\n",
    "        for i in range(F.size(0)):  # Iterate over each negative example\n",
    "            # For each negative, compute the loss against the anchor and positive\n",
    "            loss = self.triplet_loss(vhat_z, v, F[i].unsqueeze(0).expand(v.size(0), -1))\n",
    "            losses.append(loss)\n",
    "\n",
    "        loss_tensor = torch.stack(losses) \n",
    "        loss = loss_tensor.mean(dim=0).mean()\n",
    "        return loss\n",
    "    \n",
    "    def focal_triplet_loss(self, v, vhat_z, g, F):\n",
    "        _, indices = torch.topk(g, self.t, largest=False, dim=1)\n",
    "\n",
    "        F_t = torch.stack([F[indices[i]] for i in range(g.size(0))])\n",
    "\n",
    "        g_tz = torch.stack([g[i, indices[i]] for i in range(g.size(0))])\n",
    "                    \n",
    "        g_t = g_tz / g_tz.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        # if division by zero set all nan values to 0\n",
    "        g_t[torch.isnan(g_t)] = 0\n",
    "        \n",
    "        m_t = self.M * ((1 - g_t)**2)\n",
    "\n",
    "        # Initializing loss\n",
    "        loss = torch.zeros_like(v[:, 0])\n",
    "        \n",
    "        # Iteratively adding to the loss for each negative embedding\n",
    "        for i in range(self.t):\n",
    "            current_v_t = F_t[:, i]\n",
    "            current_m_t = m_t[:, i]\n",
    "            \n",
    "            current_loss = current_m_t + self.l2(vhat_z, v) - self.l2(vhat_z, current_v_t)\n",
    "            \n",
    "            loss += torch.max(torch.zeros_like(current_loss), current_loss)\n",
    "             \n",
    "        # Normalizing\n",
    "        loss = loss / self.t\n",
    "        return loss\n",
    "\n",
    "    def orthogonality_term(self, F, reg=1e-4):\n",
    "        gram_matrix = torch.mm(F, F.T)  # Compute the Gram matrix F * F^T\n",
    "        identity_matrix = torch.eye(gram_matrix.size(0), device=gram_matrix.device)  # Create an identity matrix\n",
    "        ortho_loss = (gram_matrix - identity_matrix).abs().sum()\n",
    "        return ortho_loss\n",
    "\n",
    "\n",
    "    def forward(self, p, a0, a1, p_negatives, a0_negatives, a1_negatives):\n",
    "        # Extract components from dictionary for predicate p\n",
    "        v_p, vhat_p, d_p, g_p, F_p = p[\"v\"], p[\"vhat\"], p[\"d\"], p[\"g\"], p[\"F\"]\n",
    "        \n",
    "        # Extract components from dictionary for ARG0\n",
    "        v_a0, vhat_a0, d_a0, g_a0, F_a0 = a0[\"v\"], a0[\"vhat\"], a0[\"d\"], a0[\"g\"], a0[\"F\"]\n",
    "\n",
    "        # Extract components from dictionary for ARG1\n",
    "        v_a1, vhat_a1, d_a1, g_a1, F_a1 = a1[\"v\"], a1[\"vhat\"], a1[\"d\"], a1[\"g\"], a1[\"F\"]\n",
    "        \n",
    "         # Calculate losses for predicate\n",
    "        Ju_p = self.contrastive_loss(v_p, vhat_p, p_negatives)        \n",
    "        Jt_p = self.focal_triplet_loss(v_p, vhat_p, g_p, F_p)        \n",
    "        Jz_p = Ju_p + Jt_p + self.lambda_orthogonality * self.orthogonality_term(F_p) ** 2\n",
    "        \n",
    "        # Calculate losses for ARG0\n",
    "        Ju_a0 = self.contrastive_loss(v_a0, vhat_a0, a0_negatives)\n",
    "        Jt_a0 = self.focal_triplet_loss(v_a0, vhat_a0, g_a0, F_a0)\n",
    "        Jz_a0 = Ju_a0 + Jt_a0 + self.lambda_orthogonality * self.orthogonality_term(F_a0) ** 2\n",
    "        \n",
    "        # Calculate losses for ARG1\n",
    "        Ju_a1 = self.contrastive_loss(v_a1, vhat_a1, a1_negatives)\n",
    "        Jt_a1 = self.focal_triplet_loss(v_a1, vhat_a1, g_a1, F_a1)\n",
    "        Jz_a1 = Ju_a1 + Jt_a1 + self.lambda_orthogonality * self.orthogonality_term(F_a1) ** 2\n",
    "        \n",
    "        if torch.isnan(Jz_p).any():\n",
    "            print(\"Jz_p has nan\")\n",
    "            \n",
    "        if torch.isnan(Jz_a0).any():\n",
    "            print(\"Jz_a0 has nan\")\n",
    "            \n",
    "        if torch.isnan(Jz_a1).any():\n",
    "            print(\"Jz_a1 has nan\")\n",
    "        \n",
    "        # Aggregate the losses\n",
    "        loss = Jz_p + Jz_a0 + Jz_a1\n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "# Mock Data Preparation\n",
    "batch_size = 2\n",
    "embedding_dim = 768\n",
    "K = 15  # Number of frames/descriptors\n",
    "\n",
    "# Generating mock embeddings for article, predicate, ARG0, ARG1 and their reconstructions\n",
    "article_embedding = torch.randn(batch_size, embedding_dim)\n",
    "v_p = torch.randn(batch_size, embedding_dim)\n",
    "vhat_p = torch.randn(batch_size, embedding_dim)\n",
    "\n",
    "v_a0 = torch.randn(batch_size, embedding_dim)\n",
    "vhat_a0 = torch.randn(batch_size, embedding_dim)\n",
    "\n",
    "v_a1 = torch.randn(batch_size, embedding_dim)\n",
    "vhat_a1 = torch.randn(batch_size, embedding_dim)\n",
    "\n",
    "# Generating mock descriptor weights and descriptor matrices for predicate, ARG0, ARG1\n",
    "d_p = torch.randn(batch_size, K)\n",
    "d_a0 = torch.randn(batch_size, K)\n",
    "d_a1 = torch.randn(batch_size, K)\n",
    "\n",
    "F_p = torch.randn(K, embedding_dim)\n",
    "F_a0 = torch.randn(K, embedding_dim)\n",
    "F_a1 = torch.randn(K, embedding_dim)\n",
    "\n",
    "g_p = torch.randn(batch_size, K)\n",
    "g_a0 = torch.randn(batch_size, K)\n",
    "g_a1 = torch.randn(batch_size, K)\n",
    "\n",
    "# Generating some negative samples (let's assume 5 negative samples per batch entry)\n",
    "num_negatives = 8\n",
    "negatives_p = torch.randn(num_negatives, embedding_dim)\n",
    "negatives_a0 = torch.randn(num_negatives, embedding_dim)\n",
    "negatives_a1 = torch.randn(num_negatives, embedding_dim)\n",
    "\n",
    "# Initialize loss function\n",
    "lambda_orthogonality = 1e-3\n",
    "\n",
    "t = 8  # Number of descriptors with smallest weights for negative samples\n",
    "M = t\n",
    "\n",
    "loss_fn = FRISSLoss(lambda_orthogonality, M, t)\n",
    "\n",
    "# Organizing inputs into dictionaries\n",
    "p = {\"v\": v_p, \"vhat\": vhat_p, \"d\": d_p, \"g\": g_p, \"F\": F_p}\n",
    "a0 = {\"v\": v_a0, \"vhat\": vhat_a0, \"d\": d_a0, \"g\": g_a0, \"F\": F_a0}\n",
    "a1 = {\"v\": v_a1, \"vhat\": vhat_a1, \"d\": d_a1, \"g\": g_a1, \"F\": F_a1}\n",
    "\n",
    "loss_fn = FRISSLoss(lambda_orthogonality, M, t)\n",
    "loss = loss_fn(p, a0, a1, negatives_p, negatives_a0, negatives_a1)\n",
    "print(\"FRiSSLoss output:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. FRISSUnsupervised\n",
    "\n",
    "The `FRISSUnsupervised` layer integrates multiple autoencoders and the previously described `FRISSLoss` layer to achieve an unsupervised learning process over the predicates and their arguments.\n",
    "\n",
    "### Forward Method:\n",
    "\n",
    "**Inputs**:\n",
    "1. **v_p**: Embedding of the predicate with size: [batch_size, D_w].\n",
    "2. **v_a0**: Embedding of the ARG0 (first argument) with size: [batch_size, D_w].\n",
    "3. **v_a1**: Embedding of the ARG1 (second argument) with size: [batch_size, D_w].\n",
    "4. **v_article**: Embedding of the article with size: [batch_size, D_w].\n",
    "5. **negatives**: Tensor containing negative samples with size: [batch_size, num_negatives, D_w].\n",
    "6. **tau**: A scalar parameter for the Gumbel softmax in the autoencoder.\n",
    "\n",
    "**Outputs**:\n",
    "- A dictionary `results` containing:\n",
    "    - **loss**: A tensor representing the combined unsupervised loss over the batch with size: [batch_size].\n",
    "    - **p**: Dictionary containing components for the predicate, including reconstructed embedding (`vhat`), descriptor weights (`d`), Gumbel softmax result (`g`), and the descriptor matrix (`F`).\n",
    "    - **a0**: Same as `p` but for ARG0.\n",
    "    - **a1**: Same as `p` but for ARG1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results' Shapes:\n",
      "loss: tensor([3130.8589, 3137.2515], grad_fn=<AddBackward0>)\n",
      "p -> vhat: torch.Size([2, 768]), d: torch.Size([2, 20]), g: torch.Size([2, 20]), F: torch.Size([20, 768])\n",
      "a0 -> vhat: torch.Size([2, 768]), d: torch.Size([2, 20]), g: torch.Size([2, 20]), F: torch.Size([20, 768])\n",
      "a1 -> vhat: torch.Size([2, 768]), d: torch.Size([2, 20]), g: torch.Size([2, 20]), F: torch.Size([20, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming you have already defined CombinedAutoencoder and its methods as provided earlier.\n",
    "\n",
    "class FRISSUnsupervised(nn.Module):\n",
    "    def __init__(self, D_w, D_h, K, num_frames, lambda_orthogonality, M, t, dropout_prob=0.3):\n",
    "        super(FRISSUnsupervised, self).__init__()\n",
    "        \n",
    "        self.loss_fn = FRISSLoss(lambda_orthogonality, M, t)      \n",
    "        \n",
    "        # Using the CombinedAutoencoder instead of individual Autoencoders\n",
    "        self.combined_autoencoder = CombinedAutoencoder(D_w, D_h, K, dropout_prob=dropout_prob)\n",
    "\n",
    "    def forward(self, v_p, v_a0, v_a1, v_sentence, p_negatives, a0_negatives, a1_negatives, tau):\n",
    "        outputs = self.combined_autoencoder(v_p, v_a0, v_a1, v_sentence, tau)\n",
    "\n",
    "        outputs_p = outputs[\"p\"]\n",
    "        outputs_p[\"v\"] = v_p\n",
    "        \n",
    "        outputs_a0 = outputs[\"a0\"]\n",
    "        outputs_a0[\"v\"] = v_a0\n",
    "        \n",
    "        outputs_a1 = outputs[\"a1\"]\n",
    "        outputs_a1[\"v\"] = v_a1\n",
    "        \n",
    "        loss = self.loss_fn(\n",
    "            outputs_p,\n",
    "            outputs_a0, \n",
    "            outputs_a1, \n",
    "            p_negatives, a0_negatives, a1_negatives\n",
    "        )\n",
    "\n",
    "        results = {\n",
    "            \"loss\": loss,\n",
    "            \"p\": outputs[\"p\"],\n",
    "            \"a0\": outputs[\"a0\"],\n",
    "            \"a1\": outputs[\"a1\"]\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Mock Data Preparation\n",
    "D_h = 768\n",
    "batch_size = 2\n",
    "embedding_dim = 768\n",
    "K = 20\n",
    "num_frames = 15\n",
    "tau = 0.9\n",
    "lambda_orthogonality = 0.1  # Placeholder value, please replace with your actual value\n",
    "M = 7  # Placeholder value, please replace with your actual value\n",
    "t = 7  # Placeholder value, please replace with your actual value\n",
    "\n",
    "# Generating mock embeddings for article, predicate, ARG0, ARG1, and their corresponding sentence embeddings\n",
    "article_embedding = torch.randn(batch_size, embedding_dim)\n",
    "v_p = torch.randn(batch_size, embedding_dim)\n",
    "v_a0 = torch.randn(batch_size, embedding_dim)\n",
    "v_a1 = torch.randn(batch_size, embedding_dim)\n",
    "\n",
    "# Generating some negative samples (let's assume 5 negative samples per batch entry)\n",
    "num_negatives = 10\n",
    "negatives_p = torch.randn(num_negatives, embedding_dim)\n",
    "negatives_a0 = torch.randn(num_negatives, embedding_dim)\n",
    "negatives_a1 = torch.randn(num_negatives, embedding_dim)\n",
    "\n",
    "# Testing FRISSUnsupervised\n",
    "unsupervised_module = FRISSUnsupervised(embedding_dim, D_h, K, num_frames, lambda_orthogonality, M, t)\n",
    "results = unsupervised_module(v_p, v_a0, v_a1, article_embedding, negatives_p, negatives_a0, negatives_a1, tau)\n",
    "\n",
    "# Print the results' shapes for verification\n",
    "print(\"Results' Shapes:\")\n",
    "for key, value in results.items():\n",
    "    if key == \"loss\":\n",
    "        print(f\"{key}: {value}\")\n",
    "    else:\n",
    "        print(f\"{key} -> vhat: {value['vhat'].shape}, d: {value['d'].shape}, g: {value['g'].shape}, F: {value['F'].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. FRISSSupervised\n",
    "\n",
    "The layer takes the embeddings from the args and the sentence and predicts frames. \n",
    "\n",
    "The embeddings for the args are averaged for each arg individually and then averaged on args level. The final embedding is feed into a linear layer and passed through a sigmoid function. \n",
    "\n",
    "The sentence embedding is feed into a linear layer and then into a relu function. After again in a linear function and then averaged. The average embeddung is again feed into a linear layer and lastly in a signoid function. \n",
    "\n",
    "It returns a span and sentence based prediction of shape [batch_size, num_frames]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 15]), torch.Size([2, 15]), torch.Size([2, 15]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FRISSSupervised(nn.Module):\n",
    "    def __init__(self, D_w, K, num_frames, dropout_prob=0.3):\n",
    "        super(FRISSSupervised, self).__init__()\n",
    "\n",
    "        self.D_w = D_w\n",
    "                \n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.feed_forward_sentence1 = nn.Linear(D_w, D_w)\n",
    "        self.feed_forward_sentence2 = nn.Linear(D_w, num_frames)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Adding two dropout layers\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "    def forward(self, d_p, d_a0, d_a1, vs):\n",
    "        # Span-based Classification   \n",
    "\n",
    "        # Aggregate the SRL descriptors to have one descriptor per sentence\n",
    "        d_p = d_p.mean(dim=2)\n",
    "        d_a0 = d_a0.mean(dim=2)\n",
    "        d_a1 = d_a1.mean(dim=2)\n",
    "\n",
    "        # Take the mean over descriptors\n",
    "        w_u = (d_p + d_a0 + d_a1) / 3\n",
    "\n",
    "        w_u = w_u.sum(dim=1)\n",
    "\n",
    "        # Sentence-based Classification\n",
    "\n",
    "        # Apply the first dropout to vs\n",
    "        vs = self.dropout1(vs)\n",
    "\n",
    "        ws = self.relu(self.feed_forward_sentence1(vs))\n",
    "\n",
    "        # Mean over sentences and apply the second dropout\n",
    "        ws = self.dropout2(ws.mean(dim=1))\n",
    "\n",
    "        # Pass through the second feed forward network\n",
    "        ws = self.feed_forward_sentence2(ws)\n",
    "\n",
    "        # The softmax layer is commented out as it is not used with CrossEntropyLoss\n",
    "        # ys_hat = self.softmax(ws)\n",
    "\n",
    "        # combined pred = sum of span-based and sentence-based predictions\n",
    "        combined = w_u + ws\n",
    "\n",
    "        return w_u, ws, combined\n",
    "\n",
    "\n",
    "# Mock Data Preparation\n",
    "\n",
    "batch_size = 2\n",
    "embedding_dim = 768\n",
    "num_frames = 15  # Assuming the number of frames is equal to K for simplicity\n",
    "num_sentences = 32\n",
    "K = 15\n",
    "num_args = 9\n",
    "\n",
    "# Generating mock dsz representations for predicate, ARG0, ARG1\n",
    "d_p = torch.randn(batch_size, num_sentences, num_args, K)\n",
    "d_a0 = torch.randn(batch_size, num_sentences, num_args, K)\n",
    "d_a1 = torch.randn(batch_size, num_sentences, num_args, K) \n",
    "\n",
    "# Adjusting the num_heads parameter\n",
    "srl_heads = 4\n",
    "sentence_heads = 8\n",
    "\n",
    "# Adjust the mock sentence embeddings shape\n",
    "vs = torch.randn(batch_size, num_sentences, embedding_dim)\n",
    "\n",
    "# Initialize and test the supervised module\n",
    "supervised_module = FRISSSupervised(embedding_dim, K, num_frames)\n",
    "\n",
    "# Forward pass the mock data\n",
    "yu_hat, ys_hat, combined_pred = supervised_module(d_p, d_a0, d_a1, vs)\n",
    "yu_hat.shape, ys_hat.shape, combined_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. FRISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(9.0135, grad_fn=<DivBackward0>),\n",
       " torch.Size([2, 14]),\n",
       " torch.Size([2, 14]),\n",
       " torch.Size([2, 14]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FRISS(nn.Module):\n",
    "    def __init__(self, embedding_dim, D_h, lambda_orthogonality, M, t, num_sentences, K, num_frames, dropout_prob=0.3, bert_model_name=\"bert-base-uncased\"):\n",
    "        super(FRISS, self).__init__()\n",
    "        \n",
    "        # Aggregation layer replaced with SRL_Embeddings\n",
    "        self.aggregation = SRL_Embeddings(bert_model_name)\n",
    "        \n",
    "        # Unsupervised training module\n",
    "        self.unsupervised = FRISSUnsupervised(embedding_dim, D_h, K, num_frames, lambda_orthogonality, M, t, dropout_prob=dropout_prob)\n",
    "        \n",
    "        # Supervised training module\n",
    "        self.supervised = FRISSSupervised(embedding_dim, K, num_frames, dropout_prob=dropout_prob)\n",
    "        \n",
    "    def negative_sampling(self, embeddings, num_negatives=8):\n",
    "        batch_size, num_sentences, num_args, embedding_dim = embeddings.size()\n",
    "        all_negatives = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            for j in range(num_sentences):\n",
    "                # Flatten the arguments dimension to sample across all arguments in the sentence\n",
    "                flattened_embeddings = embeddings[i, j].view(-1, embedding_dim)\n",
    "                \n",
    "                # Get indices of non-padded embeddings (assuming padding is represented by all-zero vectors)\n",
    "                non_padded_indices = torch.where(torch.any(flattened_embeddings != 0, dim=1))[0]\n",
    "\n",
    "                # Randomly sample negative indices from non-padded embeddings\n",
    "                if len(non_padded_indices) > 0:\n",
    "                    negative_indices = non_padded_indices[torch.randint(0, len(non_padded_indices), (num_negatives,))]\n",
    "                else:\n",
    "                    # If no non-padded embeddings, use zeros\n",
    "                    negative_indices = torch.zeros(num_negatives, dtype=torch.long)\n",
    "\n",
    "                negative_samples = flattened_embeddings[negative_indices, :]\n",
    "                all_negatives.append(negative_samples)\n",
    "\n",
    "        # Concatenate all negative samples into a single tensor\n",
    "        all_negatives = torch.cat(all_negatives, dim=0)\n",
    "\n",
    "        # If more samples than required, randomly select 'num_negatives' samples\n",
    "        if all_negatives.size(0) > num_negatives:\n",
    "            indices = torch.randperm(all_negatives.size(0))[:num_negatives]\n",
    "            all_negatives = all_negatives[indices]\n",
    "\n",
    "        return all_negatives\n",
    "    \n",
    "    def forward(self, sentence_ids, sentence_attention_masks, predicate_ids, predicate_attention_masks, arg0_ids, arg0_attention_masks, arg1_ids, arg1_attention_masks, tau):\n",
    "        # Convert input IDs to embeddings\n",
    "        sentence_embeddings, predicate_embeddings, arg0_embeddings, arg1_embeddings = self.aggregation(sentence_ids, sentence_attention_masks, predicate_ids, predicate_attention_masks, arg0_ids, arg0_attention_masks, arg1_ids, arg1_attention_masks)\n",
    "        \n",
    "        # Handle multiple spans by averaging predictions\n",
    "        unsupervised_losses = torch.zeros((sentence_embeddings.size(0),), device=sentence_embeddings.device)\n",
    "        \n",
    "        # Creating storage for aggregated d tensors\n",
    "        d_p_list, d_a0_list, d_a1_list = [], [], []\n",
    "        \n",
    "        negatives_p = self.negative_sampling(predicate_embeddings)\n",
    "        negatives_a0 = self.negative_sampling(arg0_embeddings)\n",
    "        negatives_a1 = self.negative_sampling(arg1_embeddings)\n",
    "\n",
    "        # Process each sentence \n",
    "        for sentence_idx in range(sentence_embeddings.size(1)):\n",
    "            s_sentence_span = sentence_embeddings[:, sentence_idx, :]\n",
    "\n",
    "            d_p_sentence_list = []\n",
    "            d_a0_sentence_list = []\n",
    "            d_a1_sentence_list = []\n",
    "\n",
    "            # Process each span\n",
    "            for span_idx in range(predicate_embeddings.size(2)):                \n",
    "                v_p_span = predicate_embeddings[:, sentence_idx, span_idx, :]\n",
    "                v_a0_span = arg0_embeddings[:, sentence_idx, span_idx, :]\n",
    "                v_a1_span = arg1_embeddings[:, sentence_idx, span_idx, :]\n",
    "\n",
    "                # Feed the embeddings to the unsupervised module\n",
    "                unsupervised_results = self.unsupervised(v_p_span, v_a0_span, v_a1_span, s_sentence_span, negatives_p, negatives_a0, negatives_a1, tau)                \n",
    "                unsupervised_losses += unsupervised_results[\"loss\"]\n",
    "                \n",
    "                if torch.isnan(unsupervised_results[\"loss\"]).any():\n",
    "                    print(\"loss is nan\")\n",
    "                \n",
    "                # Use the vhat (reconstructed embeddings) for supervised predictions\n",
    "                d_p_sentence_list.append(unsupervised_results['p']['d'])\n",
    "                d_a0_sentence_list.append(unsupervised_results['a0']['d'])\n",
    "                d_a1_sentence_list.append(unsupervised_results['a1']['d'])        \n",
    "\n",
    "\n",
    "            # Aggregating across all spans\n",
    "            d_p_sentence = torch.stack(d_p_sentence_list, dim=1)\n",
    "            d_a0_sentence = torch.stack(d_a0_sentence_list, dim=1)\n",
    "            d_a1_sentence = torch.stack(d_a1_sentence_list, dim=1)\n",
    "\n",
    "            d_p_list.append(d_p_sentence)\n",
    "            d_a0_list.append(d_a0_sentence)\n",
    "            d_a1_list.append(d_a1_sentence)\n",
    "\n",
    "        # Aggregating across all spans\n",
    "        d_p_aggregated = torch.stack(d_p_list, dim=1)\n",
    "        d_a0_aggregated = torch.stack(d_a0_list, dim=1)\n",
    "        d_a1_aggregated = torch.stack(d_a1_list, dim=1)\n",
    "        \n",
    "        # Supervised predictions\n",
    "        span_pred, sentence_pred, combined_pred = self.supervised(d_p_aggregated, d_a0_aggregated, d_a1_aggregated, sentence_embeddings)\n",
    "    \n",
    "        # Identify valid (non-nan) losses\n",
    "        valid_losses = ~torch.isnan(unsupervised_losses)\n",
    "\n",
    "        # Take average by summing the valid losses and dividing by num sentences so that padded sentences are also taken in equation\n",
    "        unsupervised_loss = unsupervised_losses[valid_losses].sum() / (sentence_embeddings.shape[1] * sentence_embeddings.shape[2])\n",
    "        \n",
    "        return unsupervised_loss, span_pred, sentence_pred, combined_pred\n",
    "\n",
    "\n",
    "# Set the necessary parameters\n",
    "batch_size = 2\n",
    "embedding_dim = 768\n",
    "K = 14  # Number of frames/descriptors\n",
    "num_frames = 14  # Assuming the number of frames is equal to K for simplicity\n",
    "D_h = 512  # Dimension of the hidden representation\n",
    "lambda_orthogonality = 0.1\n",
    "M = 8\n",
    "t = 8\n",
    "tau = 1.0\n",
    "\n",
    "# Define some mock token IDs data parameters\n",
    "max_sentences_per_article = 8\n",
    "max_sentence_length = 10\n",
    "num_sentences = max_sentences_per_article\n",
    "max_args_per_sentence = 3\n",
    "\n",
    "# Generating mock token IDs for predicate, ARG0, ARG1, and their corresponding sentences\n",
    "# We assume a vocab size of 30522 (standard BERT vocab size) for simplicity.\n",
    "vocab_size = 30522\n",
    "\n",
    "sentence_ids = torch.randint(0, vocab_size, (batch_size, max_sentences_per_article, max_sentence_length))\n",
    "predicate_ids = torch.randint(0, vocab_size, (batch_size, max_sentences_per_article, max_args_per_sentence, max_sentence_length))\n",
    "arg0_ids = torch.randint(0, vocab_size, (batch_size, max_sentences_per_article, max_args_per_sentence, max_sentence_length))\n",
    "arg1_ids = torch.randint(0, vocab_size, (batch_size, max_sentences_per_article, max_args_per_sentence, max_sentence_length))\n",
    "\n",
    "sentence_embeddings = torch.randn(batch_size, max_sentences_per_article, embedding_dim)\n",
    "predicate_embeddings = torch.randn(batch_size, max_sentences_per_article, max_args_per_sentence, embedding_dim)\n",
    "arg0_embeddings = torch.randn(batch_size, max_sentences_per_article, max_args_per_sentence, embedding_dim)\n",
    "arg1_embeddings = torch.randn(batch_size, max_sentences_per_article, max_args_per_sentence, embedding_dim)\n",
    "\n",
    "# Mock attention masks\n",
    "sentence_attention_masks = torch.randint(0, 2, (batch_size, max_sentences_per_article, max_sentence_length))\n",
    "predicate_attention_masks = torch.randint(0, 2, (batch_size, max_sentences_per_article, max_args_per_sentence, max_sentence_length))\n",
    "arg0_attention_masks = torch.randint(0, 2, (batch_size, max_sentences_per_article, max_args_per_sentence, max_sentence_length))\n",
    "arg1_attention_masks = torch.randint(0, 2, (batch_size, max_sentences_per_article, max_args_per_sentence, max_sentence_length))\n",
    "\n",
    "# Initialize the FRISS model\n",
    "friss_model = FRISS(embedding_dim, D_h, lambda_orthogonality, M, t, num_sentences, K=K, num_frames=num_frames)\n",
    "\n",
    "# Forward pass the mock data\n",
    "unsupervised_loss, span_pred, sentence_pred, combined_pred = friss_model(sentence_ids, sentence_attention_masks, predicate_ids, predicate_attention_masks, arg0_ids, arg0_attention_masks, arg1_ids, arg1_attention_masks, 1)\n",
    "unsupervised_loss, span_pred.shape, sentence_pred.shape, combined_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import json\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "def train(model, train_dataloader, test_dataloader, optimizer, loss_function, alpha=0.5, num_epochs=10, tau_min=1, tau_decay=0.95, device='cuda', save_path='../notebooks/'):\n",
    "    # Create a unique directory for this training session\n",
    "    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    save_dir = os.path.join(save_path, f'training_session_{timestamp}')\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Create save directory: {save_dir}\")\n",
    "\n",
    "    # Save model settings\n",
    "    settings_path = os.path.join(save_dir, 'model_settings.json')\n",
    "    with open(settings_path, 'w') as f:\n",
    "        json.dump({\n",
    "            'alpha': alpha,\n",
    "            'num_epochs': num_epochs,\n",
    "            'tau_min': tau_min,\n",
    "            'tau_decay': tau_decay,\n",
    "        }, f, indent=4)\n",
    "    \n",
    "    tau = 1\n",
    "    scheduler = StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "    global_steps = 0\n",
    "\n",
    "    metrics = {\n",
    "        'epoch': [],\n",
    "        'accuracy_span': [],\n",
    "        'accuracy_sentence': [],\n",
    "        'accuracy_combined': [],\n",
    "        'f1_span_micro': [],\n",
    "        'f1_sentence_micro': [],\n",
    "        'f1_combined_micro': [],\n",
    "        'f1_span_macro': [],\n",
    "        'f1_sentence_macro': [],\n",
    "        'f1_combined_macro': [],\n",
    "        'tau': [],\n",
    "        'lr': []\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "        model.train()\n",
    "\n",
    "        # init loss\n",
    "        total_loss = 0\n",
    "        supervised_total_loss = 0\n",
    "        unsupervised_total_loss = 0\n",
    "\n",
    "        local_steps = 0\n",
    "        \n",
    "        batch_progress = tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=\"Batches\", leave=False)\n",
    "        for batch_idx, batch in batch_progress:   \n",
    "            global_steps += 1\n",
    "            if global_steps % 50 == 0:\n",
    "                tau = max(tau_min, math.exp(-tau_decay * global_steps))\n",
    "\n",
    "            local_steps += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            sentence_ids = batch['sentence_ids'].to(device)\n",
    "            sentence_attention_masks = batch['sentence_attention_masks'].to(device)\n",
    "\n",
    "            predicate_ids = batch['predicate_ids'].to(device)\n",
    "            predicate_attention_masks = batch['predicate_attention_masks'].to(device)\n",
    "            \n",
    "            arg0_ids = batch['arg0_ids'].to(device)\n",
    "            arg0_attention_masks = batch['arg0_attention_masks'].to(device)\n",
    "\n",
    "            arg1_ids = batch['arg1_ids'].to(device)\n",
    "            arg1_attention_masks = batch['arg1_attention_masks'].to(device)\t\n",
    "\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            unsupervised_loss, span_logits, sentence_logits, _ = model(sentence_ids, sentence_attention_masks, predicate_ids, predicate_attention_masks, arg0_ids, arg0_attention_masks, arg1_ids, arg1_attention_masks, tau)\n",
    "                    \n",
    "            span_loss = 0.0\n",
    "            sentence_loss = 0.0\n",
    "\n",
    "            span_loss = loss_function(span_logits, labels.float())       \n",
    "            sentence_loss = loss_function(sentence_logits, labels.float())\n",
    "            \n",
    "            supervised_loss = span_loss + sentence_loss\n",
    "            \n",
    "            combined_loss = alpha * supervised_loss + (1-alpha) * unsupervised_loss\n",
    "            \n",
    "            if torch.isnan(combined_loss):\n",
    "                print(f\"NaN loss detected at epoch {epoch+1}, batch {batch_idx+1}. Stopping...\")\n",
    "                return\n",
    "        \n",
    "            combined_loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            # After the backward pass\n",
    "            if any(p.grad is not None and torch.isnan(p.grad).any() for p in model.parameters()):\n",
    "                print(f\"NaN gradients detected at epoch {epoch+1}, batch {batch_idx+1}. Stopping...\")\n",
    "                return\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += combined_loss.item()\n",
    "            supervised_total_loss += supervised_loss.item()\n",
    "            unsupervised_total_loss += unsupervised_loss.item()\n",
    "\n",
    "            batch_progress.set_description(f\"Epoch {epoch+1} ({local_steps}) Total Loss: {combined_loss.item():.3f}, Span: {span_loss:.3f}, Sentence: {sentence_loss:.3f}, Supervised: {supervised_loss.item():.3f}, Unsupervised: {unsupervised_loss.item():.3f}\")\n",
    "                        \n",
    "            # Explicitly delete tensors to free up memory\n",
    "            del sentence_ids, predicate_ids, arg0_ids, arg1_ids, labels, unsupervised_loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Combined Loss: {total_loss/len(train_dataloader)}, Supervised Loss: {supervised_total_loss/len(train_dataloader)}, Unsupervised Loss: {unsupervised_total_loss/len(train_dataloader)}\")\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        span_preds = []\n",
    "        sentence_preds = []\n",
    "        combined_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in test_dataloader:\n",
    "                sentence_ids = batch['sentence_ids'].to(device)\n",
    "                sentence_attention_masks = batch['sentence_attention_masks'].to(device)\n",
    "\n",
    "                predicate_ids = batch['predicate_ids'].to(device)\n",
    "                predicate_attention_masks = batch['predicate_attention_masks'].to(device)\n",
    "                \n",
    "                arg0_ids = batch['arg0_ids'].to(device)\n",
    "                arg0_attention_masks = batch['arg0_attention_masks'].to(device)\n",
    "\n",
    "                arg1_ids = batch['arg1_ids'].to(device)\n",
    "                arg1_attention_masks = batch['arg1_attention_masks'].to(device)\t\n",
    "\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                _, span_logits, sentence_logits, combined_logits = model(sentence_ids, sentence_attention_masks, predicate_ids, predicate_attention_masks, arg0_ids, arg0_attention_masks, arg1_ids, arg1_attention_masks, tau)\n",
    "\n",
    "                span_pred = (torch.softmax(span_logits, dim=1) > 0.5).int()\n",
    "                sentence_pred = (torch.softmax(sentence_logits, dim=1) > 0.5).int()\n",
    "                combined_pred = (torch.softmax(combined_logits, dim=1) > 0.5).int()\n",
    "                \n",
    "                span_preds.append(span_pred.cpu().numpy())\n",
    "                sentence_preds.append(sentence_pred.cpu().numpy())\n",
    "                combined_preds.append(combined_pred.cpu().numpy())\n",
    "\n",
    "                all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "                # Explicitly delete tensors to free up memory\n",
    "                del sentence_ids, predicate_ids, arg0_ids, arg1_ids, labels, span_logits, sentence_logits, sentence_pred\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        all_span_preds = np.vstack(span_preds)\n",
    "        all_sentence_preds = np.vstack(sentence_preds)\n",
    "        all_combined_preds = np.vstack(combined_preds)\n",
    "        all_labels = np.vstack(all_labels)\n",
    "\n",
    "        # Compute metrics\n",
    "        f1_span_micro = f1_score(all_labels, all_span_preds, average='micro', zero_division=0)\n",
    "        f1_sentence_micro = f1_score(all_labels, all_sentence_preds, average='micro', zero_division=0)\n",
    "        f1_combined_micro = f1_score(all_labels, all_combined_preds, average='micro', zero_division=0)\n",
    "\n",
    "        f1_span_macro = f1_score(all_labels, all_span_preds, average='macro', zero_division=0)\n",
    "        f1_sentence_macro = f1_score(all_labels, all_sentence_preds, average='macro', zero_division=0)\n",
    "        f1_combined_macro = f1_score(all_labels, all_combined_preds, average='macro', zero_division=0)\n",
    "\n",
    "        accuracy_span = accuracy_score(all_labels, all_span_preds)\n",
    "        accuracy_sentence = accuracy_score(all_labels, all_sentence_preds)\n",
    "        accuracy_combined = accuracy_score(all_labels, all_combined_preds)\n",
    "\n",
    "        print(f\"Validation Metrics - micro F1 - Span: {f1_span_micro:.2f}, Sentence: {f1_sentence_micro:.2f}, Combined: {f1_combined_micro:.2f}, macro F1 - Span: {f1_span_macro:.2f}, Sentence: {f1_sentence_macro:.2f}, Combined: {f1_combined_macro:.2f}\")\n",
    "\n",
    "        # Update metrics dictionary\n",
    "        metrics['epoch'].append(epoch + 1)\n",
    "        metrics['f1_span_micro'].append(f1_span_micro)\n",
    "        metrics['f1_sentence_micro'].append(f1_sentence_micro)\n",
    "        metrics['f1_combined_micro'].append(f1_combined_micro)\n",
    "        metrics['f1_span_macro'].append(f1_span_macro)\n",
    "        metrics['f1_sentence_macro'].append(f1_sentence_macro)\n",
    "        metrics['f1_combined_macro'].append(f1_combined_macro)\n",
    "        metrics['accuracy_span'].append(accuracy_span)\n",
    "        metrics['accuracy_sentence'].append(accuracy_sentence)\n",
    "        metrics['accuracy_combined'].append(accuracy_combined)\n",
    "        metrics['tau'].append(tau)\n",
    "        metrics['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        # Save metrics after each validation run\n",
    "        metrics_save_path = os.path.join(save_dir, 'metrics.json')\n",
    "        with open(metrics_save_path, 'w') as f:\n",
    "            json.dump(metrics, f, indent=4)\n",
    "        \n",
    "        # Save the model every 2 epochs\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            model_checkpoint_path = os.path.join(save_dir, f'model_checkpoint_epoch_{epoch + 1}.pth')\n",
    "            torch.save(model.state_dict(), model_checkpoint_path)\n",
    "            print(f\"Model checkpoint saved to {model_checkpoint_path}\")\n",
    "\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load SRL from Pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10211714/10211714 [00:00<00:00, 66844215.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 6097\n",
      "X_srl: 6097\n",
      "y: 6097\n",
      "CREATING DATASETS\n",
      "TRAIN TEST SPLIT DONE\n",
      "CREATION DONE\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "batch_size = 48\n",
    "\n",
    "max_sentences_per_article = 32\n",
    "max_sentence_length = 64\n",
    "\n",
    "max_args_per_sentence = 10\n",
    "max_arg_length = 16\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "train_dataset, test_dataset, train_dataloader, test_dataloader = get_datasets_dataloaders(df, tokenizer, recalculate_srl=False, batch_size=batch_size, max_sentences_per_article=max_sentences_per_article, max_sentence_length=max_sentence_length, max_arg_length=max_arg_length, pickle_path=\"data/srls/mfc/FRISS_srl.pkl\", test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 5487)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset), len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_friss_model(embedding_dim, D_h, lambda_orthogonality, M, t, num_sentences, K, num_frames, dropout_prob, bert_model_name=\"bert-base-uncased\", load=True, path=\"\", device='cuda'):\n",
    "    # Model instantiation\n",
    "    model = FRISS(embedding_dim, D_h, lambda_orthogonality, M, t, num_sentences, K, num_frames, dropout_prob=dropout_prob, bert_model_name=bert_model_name)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    if load:\n",
    "        assert path != \"\"\n",
    "        model.load_state_dict(torch.load(path, map_location=device))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 768\n",
    "num_frames = 15\n",
    "\n",
    "D_h = 768\n",
    "lambda_orthogonality = 1e-3\n",
    "\n",
    "K = num_frames\n",
    "t = 8\n",
    "M = 8\n",
    "tau_min = 0.5\n",
    "tau_decay = 5e-4\n",
    "\n",
    "dropout_prob = 0.3\n",
    "\n",
    "friss_model_path = \"models/friss-new-v2/model_checkpoint_epoch_4.pth\"\n",
    "bert_model_path = \"bert-base-uncased\"\n",
    "\n",
    "# Model instantiation\n",
    "model = get_friss_model(embedding_dim, \n",
    "                        D_h, \n",
    "                        lambda_orthogonality, \n",
    "                        M, \n",
    "                        t, \n",
    "                        num_sentences, \n",
    "                        K, \n",
    "                        num_frames, \n",
    "                        dropout_prob=dropout_prob,\n",
    "                        bert_model_name=bert_model_path,\n",
    "                        load=True,\n",
    "                        path=friss_model_path)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# LOSS\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Train the model\n",
    "alpha_value = 0.5\n",
    "num_epochs_value = 10\n",
    "\n",
    "save_path = \"models/\"\n",
    "\n",
    "metrics = train(model, \n",
    "                train_dataloader, \n",
    "                test_dataloader, \n",
    "                optimizer, \n",
    "                loss_function, \n",
    "                tau_min=tau_min, \n",
    "                tau_decay=tau_decay, \n",
    "                alpha=alpha_value, \n",
    "                num_epochs=num_epochs_value,\n",
    "                device=device, \n",
    "                save_path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def validate(model, test_dataloader, device='cuda'):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    tau = 0.9\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_progress = tqdm(enumerate(test_dataloader), total=len(test_dataloader), desc=\"Batches\", leave=False)\n",
    "        for batch_idx, batch in batch_progress:\n",
    "            sentence_ids = batch['sentence_ids'].to(device)\n",
    "            sentence_attention_masks = batch['sentence_attention_masks'].to(device)\n",
    "\n",
    "            predicate_ids = batch['predicate_ids'].to(device)\n",
    "            predicate_attention_masks = batch['predicate_attention_masks'].to(device)\n",
    "\n",
    "            arg0_ids = batch['arg0_ids'].to(device)\n",
    "            arg0_attention_masks = batch['arg0_attention_masks'].to(device)\n",
    "\n",
    "            arg1_ids = batch['arg1_ids'].to(device)\n",
    "            arg1_attention_masks = batch['arg1_attention_masks'].to(device)\n",
    "\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            _, _, _, combined_logits = model(sentence_ids, sentence_attention_masks, predicate_ids, predicate_attention_masks, arg0_ids, arg0_attention_masks, arg1_ids, arg1_attention_masks, tau)\n",
    "\n",
    "            preds = torch.argmax(combined_logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Explicitly delete tensors to free up memory\n",
    "            del sentence_ids, predicate_ids, arg0_ids, arg1_ids, labels, combined_logits\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    return all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cafb78689034d06a79f2ac8dd703da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 768\n",
    "num_frames = 15\n",
    "\n",
    "D_h = 768\n",
    "lambda_orthogonality = 1e-3\n",
    "\n",
    "K = num_frames\n",
    "t = 8\n",
    "M = 8\n",
    "tau_min = 0.5\n",
    "tau_decay = 5e-4\n",
    "\n",
    "dropout_prob = 0.3\n",
    "\n",
    "friss_model_path = \"models/FRISS/model.pth\"\n",
    "bert_model_path = \"bert-base-uncased\"\n",
    "\n",
    "# Model instantiation\n",
    "model = get_friss_model(embedding_dim, \n",
    "                        D_h, \n",
    "                        lambda_orthogonality, \n",
    "                        M, \n",
    "                        t, \n",
    "                        num_sentences, \n",
    "                        K, \n",
    "                        num_frames, \n",
    "                        dropout_prob=dropout_prob,\n",
    "                        bert_model_name=bert_model_path,\n",
    "                        load=True,\n",
    "                        path=friss_model_path)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Validate the model\n",
    "all_labels, all_preds = validate(model, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "\n",
    "# Number of classes based on the labels\n",
    "num_classes = all_labels[0].shape[0]\n",
    "\n",
    "# Convert all_preds to one-hot encoding\n",
    "one_hot_preds = np.zeros((len(all_preds), num_classes))\n",
    "for i, pred in enumerate(all_preds):\n",
    "    one_hot_preds[i, pred] = 1\n",
    "\n",
    "# Convert all_labels to a single numpy array for easier comparison\n",
    "all_labels_array = np.stack(all_labels)\n",
    "all_preds_array = np.stack(one_hot_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.4097222222222222\n",
      "Macro F1 Score: 0.22420811931515844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Assuming all_labels_array and all_preds_array are your input arrays\n",
    "# Convert one-hot encoded predictions to class labels\n",
    "all_labels = np.argmax(all_labels_array, axis=1)\n",
    "all_preds = np.argmax(all_preds_array, axis=1)\n",
    "\n",
    "# Calculate overall accuracy and macro F1 score\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f\"Overall Accuracy: {accuracy}\")\n",
    "print(f\"Macro F1 Score: {macro_f1}\")\n",
    "\n",
    "# Calculate precision, recall, f1-score for each class\n",
    "precisions, recalls, f1_scores, _ = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "# For AUC, we need to binarize the labels because roc_auc_score expects binary labels\n",
    "n_classes = all_labels_array.shape[1]\n",
    "all_labels_binarized = label_binarize(all_labels, classes=range(n_classes))\n",
    "\n",
    "# For AUC calculation, we need to adjust predictions to a probability-like form\n",
    "# Here, we assume a simplistic conversion where the prediction gets a score of 1, and others 0\n",
    "all_preds_binarized = label_binarize(all_preds, classes=range(n_classes))\n",
    "\n",
    "auc_scores = []\n",
    "for i in range(n_classes):\n",
    "    # Try-except block to handle classes with no positive samples\n",
    "    try:\n",
    "        auc_score = roc_auc_score(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "        auc_scores.append(auc_score)\n",
    "    except ValueError:\n",
    "        auc_scores.append(float('nan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.642202</td>\n",
       "      <td>0.751447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.688593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.565770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.117949</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.200873</td>\n",
       "      <td>0.679564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.434066</td>\n",
       "      <td>0.877778</td>\n",
       "      <td>0.580882</td>\n",
       "      <td>0.832922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.544515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.700600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class  Precision    Recall  F1-Score       AUC\n",
       "0       0   0.000000  0.000000  0.000000  0.500000\n",
       "1       1   0.853659  0.514706  0.642202  0.751447\n",
       "2       2   0.625000  0.400000  0.487805  0.688593\n",
       "3       3   0.700000  0.137255  0.229508  0.565770\n",
       "4       4   0.000000  0.000000  0.000000  0.500000\n",
       "5       5   0.000000  0.000000  0.000000  0.500000\n",
       "6       6   0.000000  0.000000  0.000000  0.500000\n",
       "7       7   0.666667  0.583333  0.622222  0.762500\n",
       "8       8   0.000000  0.000000  0.000000  0.500000\n",
       "9       9   0.000000  0.000000  0.000000  0.500000\n",
       "10     10   0.117949  0.676471  0.200873  0.679564\n",
       "11     11   0.434066  0.877778  0.580882  0.832922\n",
       "12     12   0.000000  0.000000  0.000000  0.500000\n",
       "13     13   0.800000  0.090909  0.163265  0.544515\n",
       "14     14   0.444444  0.428571  0.436364  0.700600"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wrap into a pandas dataframe for better visualization\n",
    "import pandas as pd\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Class': range(n_classes),\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1-Score': f1_scores,\n",
    "    'AUC': auc_scores\n",
    "})\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the full metrics and the class-wise metrics into a single dataframe and save as json file\n",
    "full_metrics = {\n",
    "    \"Overall Accuracy\": accuracy,\n",
    "    \"Macro F1 Score\": macro_f1\n",
    "}\n",
    "\n",
    "full_metrics.update(metrics_df.to_dict())\n",
    "\n",
    "# Save the full metrics as a json file\n",
    "full_metrics_path = \"full_metrics.json\"\n",
    "\n",
    "with open(full_metrics_path, 'w') as f:\n",
    "    json.dump(full_metrics, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import torch.optim as optim\n",
    "import csv\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 768\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def grid_search(train_dataloader, test_dataloader, search_space, num_epochs=10):\n",
    "    # Store the results for each hyperparameter combination\n",
    "    results = {}\n",
    "\n",
    "    # Fixed values for K and num_frames\n",
    "    K = 14\n",
    "    num_frames = 14\n",
    "\n",
    "    # Fixed values for dropout_prob and bert_model_name (adjust if necessary)\n",
    "    bert_model_name = \"../notebooks/models/fine-tuned-model/\"\n",
    "\n",
    "    # Initialize the file to write metrics\n",
    "    with open(\"../notebooks/grid_search_metrics.csv\", \"w\", newline='') as csvfile:\n",
    "        fieldnames = ['combination', 'alpha', 'lr', 'D_h', 'lambda_orthogonality', 'M', 't', 'tau_min', 'tau_decay', 'dropout_prob', 'epoch', 'f1_span_micro', 'f1_span_macro', 'f1_sentence_micro', 'f1_sentence_macro', 'f1_combined_micro', 'f1_combined_macro']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Calculate the total number of combinations\n",
    "        total_combinations = 1\n",
    "        for key, values in search_space.items():\n",
    "            total_combinations *= len(values)\n",
    "\n",
    "        # Loop through all combinations\n",
    "        for idx, combination in enumerate(product(*search_space.values())):\n",
    "            print(f\"Training combination {idx + 1}/{total_combinations}: {combination}\")\n",
    "\n",
    "            # Extract hyperparameters from the current combination\n",
    "            alpha, lr, tau_min, tau_decay, t, D_h, lambda_orthogonality, M, dropout_prob = combination\n",
    "\n",
    "            # Initialize the model with current hyperparameters\n",
    "            model = FRISS(embedding_dim, D_h, lambda_orthogonality, M, t, num_sentences, K, num_frames, dropout_prob, bert_model_name)\n",
    "            model.to(device)\n",
    "        \n",
    "                \n",
    "            # Compute the `weight` parameter for each label\n",
    "            label_frequencies = y.mean()\n",
    "            weights = 1 / (label_frequencies + 1e-10)  # Adding a small value to avoid division by zero\n",
    "\n",
    "            # Compute the `pos_weight` parameter\n",
    "            pos_weights = (1 - label_frequencies) / (label_frequencies + 1e-10)\n",
    "\n",
    "            # Convert the computed weights and pos_weights to PyTorch tensors\n",
    "            weights_tensor = torch.tensor(weights.values, dtype=torch.float32).to(device)\n",
    "            pos_weights_tensor = torch.tensor(pos_weights.values, dtype=torch.float32).to(device)\n",
    "\n",
    "            loss_function = nn.BCEWithLogitsLoss(weight=weights_tensor, pos_weight=pos_weights_tensor, reduction=\"mean\")\n",
    "        \n",
    "            # Define the optimizer\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "            # Define loss_function if needed (add this if your train function requires it)\n",
    "\n",
    "            # Train the model with the current hyperparameters\n",
    "            epoch_metrics = train(model, train_dataloader, test_dataloader, optimizer, loss_function, alpha=alpha, num_epochs=num_epochs, tau_min=tau_min, tau_decay=tau_decay, device=device, save=False)\n",
    "\n",
    "            # Write the metrics to the CSV file\n",
    "            for epoch in range(num_epochs):\n",
    "                f1_span_micro = epoch_metrics['f1_span_micro'][epoch]\n",
    "                f1_span_macro = epoch_metrics['f1_span_macro'][epoch]\n",
    "                f1_sentence_micro = epoch_metrics['f1_sentence_micro'][epoch]\n",
    "                f1_sentence_macro = epoch_metrics['f1_sentence_macro'][epoch]\n",
    "                f1_combined_micro = epoch_metrics['f1_combined_micro'][epoch]\n",
    "                f1_combined_macro = epoch_metrics['f1_combined_macro'][epoch]\n",
    "                row = {\n",
    "                    'combination': idx,\n",
    "                    'alpha': alpha,\n",
    "                    'lr': lr,\n",
    "                    'D_h': D_h,\n",
    "                    'lambda_orthogonality': lambda_orthogonality,\n",
    "                    'M': M,\n",
    "                    't': t,\n",
    "                    'tau_min': tau_min,\n",
    "                    'tau_decay': tau_decay,\n",
    "                    'dropout_prob': dropout_prob,\n",
    "                    'epoch': epoch + 1,\n",
    "                    'f1_span_micro': f1_span_micro,\n",
    "                    'f1_span_macro': f1_span_macro,\n",
    "                    'f1_sentence_micro': f1_sentence_micro,\n",
    "                    'f1_sentence_macro': f1_sentence_macro,\n",
    "                    'f1_combined_micro': f1_combined_micro,\n",
    "                    'f1_combined_macro': f1_combined_macro\n",
    "                }\n",
    "                writer.writerow(row)\n",
    "                csvfile.flush()\n",
    "\n",
    "    return results\n",
    "\n",
    "search_space = {\n",
    "    'alpha': [0.5, 0.2, 0.8],\n",
    "    'lr': [1e-5, 2e-5, 5e-4, 1e-3],\n",
    "    'tau_min': [0.5],\n",
    "    'tau_decay': [5e-4],\n",
    "    't': [5, 8, 10, 20],\n",
    "    'D_h': [768, 768 * 2, 768 // 2, 768 * 3],\n",
    "    'lambda_orthogonality': [1e-6, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2],\n",
    "    'M': [5, 8, 10, 20],\n",
    "    'dropout_rate': [0.1, 0.2, 0.3, 0.5]\n",
    "}\n",
    "\n",
    "# Call the grid search function\n",
    "results = grid_search(train_dataloader, test_dataloader, search_space, 10)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_path(path, embedding_dim, D_h, lambda_orthogonality, M, t, num_sentences, K, num_frames, dropout_prob, bert_model_name, device='cuda'):\n",
    "    \"\"\"\n",
    "    Loads the weights into an instance of the model class from the given path.\n",
    "    \n",
    "    Args:\n",
    "    - model_class (torch.nn.Module): The class of the model (uninitialized).\n",
    "    - path (str): Path to the saved weights.\n",
    "    - device (str): Device to load the model on ('cpu' or 'cuda').\n",
    "    \n",
    "    Returns:\n",
    "    - model (torch.nn.Module): Model with weights loaded.\n",
    "    \"\"\"\n",
    "\n",
    "    # Model instantiation\n",
    "    model = FRISS(embedding_dim, D_h, lambda_orthogonality, M, t, num_sentences, K, num_frames, dropout_prob=dropout_prob, bert_model_name=bert_model_name)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    \n",
    "    #model.eval()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embedding_dim = 768\n",
    "num_frames = 15\n",
    "\n",
    "D_h = 768\n",
    "lambda_orthogonality = 1e-3\n",
    "\n",
    "K = num_frames\n",
    "t = 8\n",
    "M = 8\n",
    "tau_min = 0.5\n",
    "tau_decay = 5e-4\n",
    "\n",
    "dropout_prob = 0.3\n",
    "\n",
    "friss_model_path = \"bert-base-uncased\"\n",
    "bert_model_path = \"bert-base-uncased\"\n",
    "\n",
    "\n",
    "model = load_model_from_path('models/friss_best_v2/model_checkpoint_epoch_2.pth', embedding_dim, D_h, lambda_orthogonality, M, t, num_sentences, K, num_frames, dropout_prob, bert_model_path, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader, y_columns, device='cuda'):\n",
    "    \"\"\"\n",
    "    Make predictions with the given model and dataloader.\n",
    "    \n",
    "    Args:\n",
    "    - model (torch.nn.Module): The model to make predictions with.\n",
    "    - dataloader (DataLoader): DataLoader for the dataset to predict on.\n",
    "    - y_columns (pandas.Index): Column names from the y dataframe which correspond to labels.\n",
    "    - device (str): Device to make predictions on ('cpu' or 'cuda').\n",
    "    \n",
    "    Returns:\n",
    "    - predicted_labels (list of lists): List containing the predicted labels for each instance.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds_span = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Move data to device\n",
    "            sentence_ids = batch['sentence_ids'].to(device)\n",
    "            predicate_ids = batch['predicate_ids'].to(device)\n",
    "            arg0_ids = batch['arg0_ids'].to(device)\n",
    "            arg1_ids = batch['arg1_ids'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            _, span_logits, sentence_logits, combined_logits = model(sentence_ids, predicate_ids, arg0_ids, arg1_ids, 0.8)\n",
    "            combined_pred = (torch.softmax(combined_logits, dim=1) > 0.5).float()\n",
    "\n",
    "            all_preds_span.append(combined_pred.cpu().numpy())\n",
    "                \n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    predictions = np.vstack(all_preds_span)\n",
    "    \n",
    "    # Convert boolean predictions to labels\n",
    "    predicted_labels = []\n",
    "    for pred in predictions:\n",
    "        labels = list(y_columns[pred.astype(bool)])\n",
    "        predicted_labels.append(labels)\n",
    "    \n",
    "    return predicted_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# article813452859\n",
    "article = \"\"\"Sadiq Khan Slammed for Pro-EU 'Message of Support' During Firework Display\n",
    "\n",
    "The spectacular fireworks that lit up the London sky on Monday night caused a stir on social media over the display's pro-EU message, at a time when the nation is divided over its looming withdrawal from the bloc.\n",
    "London Mayor Sadiq Khan faced mounting criticism after the capital's New Year's Eve fireworks display, which celebrated ties with the European Union, left a bad taste in the mouths of some Brits.\n",
    "The 135-metre-high London Eye was lit up in blue while its tubs turned yellow, with the giant Ferris wheel resembling the star-studded flag of the European Union.Sadiq Khan called his fireworks display a \"message of support\" to EU citizens living in London.\n",
    "\"Our one million EU citizens are Londoners, they make a huge contribution, and no matter the outcome of Brexit — they will always be welcome\", he said.\n",
    "To the one million EU citizens who have made our city your home: you are Londoners, you make a huge contribution and you are welcome here.\n",
    "I'm proud that tonight we will welcome in the new year with a message of support to you.\n",
    "#LondonNYE #LondonIsOpen https://t.co/XctrgfXXaM — Sadiq Khan (@SadiqKhan) 31 декабря 2018 г.\n",
    "However, a host of Londoners rushed to Twitter to accuse their mayor of \"politicising\" the celebrations — with some are even calling for his resignation.\n",
    "I cannot believe this event has been politicised.\n",
    "This man has no shame.\n",
    "Just resign.\n",
    "— wayne campbell (@campbs177) 31 декабря 2018 г.\n",
    "Thanks a lot Sadiq Khan you ruined the fireworks display by talking about Europe, need I remind you about Brexit.\n",
    "You have started of the new year by talking about relationships with the European Union.\n",
    "Well done.\n",
    "We need Boris Johnson back.\n",
    "— Mitchell T Cannon (@MitchellTCanno1) 1 января 2019 г.\n",
    "Another shameless attempt at using party politics on what is supposed to be a happy occasion — droneguy (@shelbyguitars) 1 января 2019 г.\n",
    "Politicising another innocent event that should be no different to anyone no matter who they are or where they are from!\n",
    "Shameful!\n",
    "!\n",
    "— Mike Dyer (@Miked2372Mike) 31 декабря 2018 г.\n",
    "Someone was stabbed down the road from me last night.\n",
    "How about sorting that stuff out instead of politicizing something that should be fun for everyone?How many times does it have to be said.\n",
    "Commenting on Brexit isn't your job.\n",
    "— Peter Rockett (@rockettp) 31 декабря 2018 г.\n",
    "The UK voted to leave the EU in June 2016 via a nationwide referendum, with 51.9 per cent voting in favour of pulling out of the bloc, while 48.1 per cent wanted to remain.\n",
    "The withdrawal is scheduled for the end of March; the Article 50 deadline.\n",
    "The Remain sentiment dominated London, with nearly 60 percent of voters wanting Britain to stay in the European Union.\n",
    "Sadiq Khan, an outspoken Remainer himself, earlier called for a second referendum on Brexit.\n",
    "\"The government's abject failure — and the huge risk we face of a bad deal or a 'no deal' Brexit — means that giving people a fresh say is now the right — and only — approach left for our country,\" he said in September.\n",
    "\"\"\"\n",
    "\n",
    "test_article = get_article_dataloader(article, tokenizer)\n",
    "predict(model, test_article, y.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def inspect(model, dataloader, device='cuda'):\n",
    "    \"\"\"\n",
    "    Make predictions with the given model and dataloader.\n",
    "    \n",
    "    Args:\n",
    "    - model (torch.nn.Module): The model to make predictions with.\n",
    "    - dataloader (DataLoader): DataLoader for the dataset to predict on.\n",
    "    - y_columns (pandas.Index): Column names from the y dataframe which correspond to labels.\n",
    "    - device (str): Device to make predictions on ('cpu' or 'cuda').\n",
    "    \n",
    "    Returns:\n",
    "    - predicted_labels (list of lists): List containing the predicted labels for each instance.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds_span = []\n",
    "    \n",
    "    # Initialize usage lists for each label\n",
    "    num_labels = len(y_columns)\n",
    "    all_used_labels_p = []\n",
    "    all_used_labels_a0 = []\n",
    "    all_used_labels_a1 = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Wrap the dataloader with tqdm for batch progress\n",
    "        for batch in tqdm(dataloader, desc=\"Processing Batches\"):\n",
    "            used_labels_p = []\n",
    "            used_labels_a0 = []\n",
    "            used_labels_a1 = []\n",
    "    \n",
    "            sentence_ids = batch['sentence_ids'].to(device)\n",
    "            sentence_attention_masks = batch['sentence_attention_masks'].to(device)\n",
    "\n",
    "            predicate_ids = batch['predicate_ids'].to(device)\n",
    "            predicate_attention_masks = batch['predicate_attention_masks'].to(device)\n",
    "            \n",
    "            arg0_ids = batch['arg0_ids'].to(device)\n",
    "            arg0_attention_masks = batch['arg0_attention_masks'].to(device)\n",
    "\n",
    "            arg1_ids = batch['arg1_ids'].to(device)\n",
    "            arg1_attention_masks = batch['arg1_attention_masks'].to(device)\t\n",
    "\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            sentence_embeddings, predicate_embeddings, arg0_embeddings, arg1_embeddings = model.aggregation(sentence_ids, sentence_attention_masks, predicate_ids, predicate_attention_masks, arg0_ids, arg0_attention_masks, arg1_ids, arg1_attention_masks)\n",
    "            \n",
    "            # Process each span\n",
    "            for sentence_idx in range(sentence_embeddings.size(1)):\n",
    "                for span_idx in range(predicate_embeddings.size(2)):\n",
    "                    s_sentence_span = sentence_embeddings[:, sentence_idx, :]\n",
    "                    v_p_span = predicate_embeddings[:, sentence_idx, span_idx, :]\n",
    "                    v_a0_span = arg0_embeddings[:, sentence_idx, span_idx, :]\n",
    "                    v_a1_span = arg1_embeddings[:, sentence_idx, span_idx, :]\n",
    "\n",
    "                    #unsupervised.combined_autoencoder v_p, v_a0, v_a1, v_sentence, tau\n",
    "                    output = model.unsupervised.combined_autoencoder(v_p_span, v_a0_span, v_a1_span, s_sentence_span, 0.6)\n",
    "                    \n",
    "                    #print(output[\"p\"][\"g\"].cpu().numpy())\n",
    "                    used_labels_p.append(output[\"p\"][\"g\"].cpu().numpy())\n",
    "                    used_labels_a0.append(output[\"a0\"][\"g\"].cpu().numpy())\n",
    "                    used_labels_a1.append(output[\"a1\"][\"g\"].cpu().numpy())\n",
    "\n",
    "            \n",
    "            # Forward pass\n",
    "            _, span_logits, sentence_logits, combined_logits = model(sentence_ids, sentence_attention_masks, predicate_ids, predicate_attention_masks, arg0_ids, arg0_attention_masks, arg1_ids, arg1_attention_masks, 0.5)\n",
    "            combined_pred = (torch.sigmoid(combined_logits) > 0.5).float()\n",
    "\n",
    "            all_preds_span.append(combined_pred.cpu().numpy())\n",
    "                \n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            all_used_labels_p.append(used_labels_p)\n",
    "            all_used_labels_a0.append(used_labels_a0)\n",
    "            all_used_labels_a1.append(used_labels_a1)\n",
    "\n",
    "    predictions = np.vstack(all_preds_span)\n",
    "    \n",
    "    return predictions, all_used_labels_p, all_used_labels_a0, all_used_labels_a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_columns = ['Capacity and Resources',\n",
    "       'Crime and Punishment', 'Cultural Identity', 'Economic',\n",
    "       'External Regulation and Reputation', 'Fairness and Equality',\n",
    "       'Health and Safety', 'Legality, Constitutionality, Jurisdiction',\n",
    "       'Morality', 'Other', 'Policy Prescription and Evaluation', 'Political',\n",
    "       'Public Sentiment', 'Quality of Life', 'Security and Defense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted_labels, used_labels_p, used_labels_a0, used_labels_a1 = inspect(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(used_labels_p[75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = y_columns\n",
    "\n",
    "category_lists_p = {category: [] for category in categories}\n",
    "category_lists_a1 = {category: [] for category in categories}\n",
    "category_lists_a0 = {category: [] for category in categories}\n",
    "\n",
    "loader = test_dataloader\n",
    "\n",
    "batch_size = len(loader)\n",
    "\n",
    "for batch_idx in range(batch_size):\n",
    "    # Iterate over each sentence\n",
    "    ds = loader.dataset[batch_idx]\n",
    "\n",
    "    for idx in range(len(used_labels_p[batch_idx])):\n",
    "\n",
    "        # Update the lists for each category\n",
    "        for cat_idx, category in enumerate(categories):\n",
    "        \n",
    "            if used_labels_p[batch_idx][cat_idx][0][cat_idx] > 0.8:\n",
    "                category_lists_p[category].append(ds[\"predicate_ids\"][sentence_idx].numpy())\n",
    "            \n",
    "            if used_labels_a0[batch_idx][cat_idx][0][cat_idx] > 0.8:\n",
    "                category_lists_a0[category].append(ds[\"arg0_ids\"][sentence_idx].numpy())\n",
    "                \n",
    "            if used_labels_a1[batch_idx][cat_idx][0][cat_idx] > 0.8:\n",
    "                category_lists_a1[category].append(ds[\"arg1_ids\"][sentence_idx].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def decode_tokens(token_dict, stop_words):\n",
    "    decoded_data = {}\n",
    "    for category, token_lists in token_dict.items():\n",
    "        decoded_data[category] = []\n",
    "        for tokens in token_lists:\n",
    "            if np.any(tokens > 0):\n",
    "                # Decode the tokens\n",
    "                decoded_text = tokenizer.decode(tokens, skip_special_tokens=True).strip()\n",
    "                # Tokenize and remove stop words\n",
    "                words = word_tokenize(decoded_text)\n",
    "                filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "                # Join the words back into a string\n",
    "                decoded_data[category].append(' '.join(filtered_words))\n",
    "    return decoded_data\n",
    "\n",
    "stop_words = set(stopwords.words('english'))  # Assuming your text is in English\n",
    "\n",
    "# Decode the token IDs for each ARG\n",
    "decoded_predicate = decode_tokens(category_lists_p, stop_words)\n",
    "decoded_arg0 = decode_tokens(category_lists_a0, stop_words)\n",
    "decoded_arg1 = decode_tokens(category_lists_a1, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to collect DataFrame rows\n",
    "rows = []\n",
    "\n",
    "# Populate the list with rows\n",
    "for frame in set(decoded_predicate) | set(decoded_arg0) | set(decoded_arg1):\n",
    "    # Get the lists, joining multiple words with a comma\n",
    "    pred_words = ', '.join([ s.strip() for s in list(set(decoded_predicate.get(frame, []))) if s is not None or l != \"\"])\n",
    "    arg0_words = ', '.join(list(set(decoded_arg0.get(frame, []))))\n",
    "    arg1_words = ', '.join(list(set(decoded_arg1.get(frame, []))))\n",
    "\n",
    "    # Create a dictionary for the row\n",
    "    row = {\n",
    "        \"Frame\": frame,\n",
    "        \"Predicate\": pred_words,\n",
    "        \"ARG0\": arg0_words,\n",
    "        \"ARG1\": arg1_words\n",
    "    }\n",
    "    \n",
    "    # Append the row dictionary to the rows list\n",
    "    rows.append(row)\n",
    "\n",
    "# Convert the list of rows to a DataFrame\n",
    "df_full_table = pd.DataFrame(rows)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_full_table.style.hide_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05c4f9fa65704ea5ba7f80e879e08510": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f54181f857a4110bf9976a56c97de97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fbfe002ccd541f9b6ab62ed4eebef35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1048f064e69b46d497b65cb9b88d0142": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc871ed94e764fe884ffdafca1445bfe",
       "IPY_MODEL_b4e7e77911e5408b84d89ccaff134708",
       "IPY_MODEL_c322e99ad9504207b7cfb9ae2ca9d6b1"
      ],
      "layout": "IPY_MODEL_dd92db5892be4357a6446146d9e9a0dd"
     }
    },
    "145c8616bab245358c8052beac5bd2bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20d6b378a69744e4a327d929c391b475": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "364a4257f8a641e18b7bde39e63a618d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "409a73804fc34a63a619a42b9468be46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "475020323c07410e87d366a6f553aafb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_145c8616bab245358c8052beac5bd2bc",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ca901348dcd1428ebecc55d659fa40d1",
      "value": 28
     }
    },
    "4ddbb3fa3b924a9e9650f51204580f8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a5458551f974a94b61ff658ae59fa70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b48b8b79d6a4ff1b0655a6bfcf7a422": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c06d626b5ee4fe8bdb9be7fb879aae0",
      "placeholder": "​",
      "style": "IPY_MODEL_779202125255413cb719a43fe5d14ce7",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "5d40c6e034fd4b278969dd928cc07dff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f4b55ead6884f3790a3acfa43232fc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87907508c4eb43f3a27858f1d397ca99",
      "placeholder": "​",
      "style": "IPY_MODEL_d21ed2e527464a0ca0cb2b3b4fad928a",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "650f8e0f82e849f58a47507291b15500": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbb672669b9f4c36873048cfa1d2daf6",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cf42b39e3be94c90b3a63d05783481a3",
      "value": 231508
     }
    },
    "67ea6145091b440da6b4c5d5f8695aa9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ac495a816994aaeb8926c6c97d103ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ddbb3fa3b924a9e9650f51204580f8d",
      "placeholder": "​",
      "style": "IPY_MODEL_a115ed03534a4c64a17fa55d93a0f93a",
      "value": " 570/570 [00:00&lt;00:00, 47.0kB/s]"
     }
    },
    "71add6bf108545af8db6aeb392793759": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5f4b55ead6884f3790a3acfa43232fc9",
       "IPY_MODEL_475020323c07410e87d366a6f553aafb",
       "IPY_MODEL_e2454ec2f5904e0bacde56ae7d4089a9"
      ],
      "layout": "IPY_MODEL_0f54181f857a4110bf9976a56c97de97"
     }
    },
    "779202125255413cb719a43fe5d14ce7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "87907508c4eb43f3a27858f1d397ca99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c06d626b5ee4fe8bdb9be7fb879aae0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e13dccd922946ab873cc287fcca5baf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93fa55d130db463c8ddffc947f2e99cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a6d16261d5b4693b09acf83dcb38920": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0265a21ae504485ab59207228c1f6d6",
      "placeholder": "​",
      "style": "IPY_MODEL_8e13dccd922946ab873cc287fcca5baf",
      "value": " 232k/232k [00:00&lt;00:00, 9.51MB/s]"
     }
    },
    "a0265a21ae504485ab59207228c1f6d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a115ed03534a4c64a17fa55d93a0f93a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a74bacc051494d1ea0f4cbd656505cfe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4e7e77911e5408b84d89ccaff134708": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67ea6145091b440da6b4c5d5f8695aa9",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bef37b47c8ee49778464c05adcffa30d",
      "value": 466062
     }
    },
    "b83493088cd24629a04ec612aa522ed4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c222d2a5e4664f9b9aefed7f093d4a4e",
       "IPY_MODEL_fa94f90b735f418fb2b502f7877b5306",
       "IPY_MODEL_6ac495a816994aaeb8926c6c97d103ae"
      ],
      "layout": "IPY_MODEL_409a73804fc34a63a619a42b9468be46"
     }
    },
    "bef37b47c8ee49778464c05adcffa30d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c222d2a5e4664f9b9aefed7f093d4a4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_364a4257f8a641e18b7bde39e63a618d",
      "placeholder": "​",
      "style": "IPY_MODEL_93fa55d130db463c8ddffc947f2e99cd",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "c322e99ad9504207b7cfb9ae2ca9d6b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d40c6e034fd4b278969dd928cc07dff",
      "placeholder": "​",
      "style": "IPY_MODEL_f6b3c67d61114db5810bd78339a218d9",
      "value": " 466k/466k [00:00&lt;00:00, 1.88MB/s]"
     }
    },
    "ca901348dcd1428ebecc55d659fa40d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cf42b39e3be94c90b3a63d05783481a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d21ed2e527464a0ca0cb2b3b4fad928a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d568d9b894694b6fb432456031cee230": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbb672669b9f4c36873048cfa1d2daf6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd92db5892be4357a6446146d9e9a0dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2454ec2f5904e0bacde56ae7d4089a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20d6b378a69744e4a327d929c391b475",
      "placeholder": "​",
      "style": "IPY_MODEL_05c4f9fa65704ea5ba7f80e879e08510",
      "value": " 28.0/28.0 [00:00&lt;00:00, 1.97kB/s]"
     }
    },
    "e9ee9acc5e414c65ad10b8864cc07b07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f19c187b1e8c4bbe9fda366f24f2b79e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b48b8b79d6a4ff1b0655a6bfcf7a422",
       "IPY_MODEL_650f8e0f82e849f58a47507291b15500",
       "IPY_MODEL_9a6d16261d5b4693b09acf83dcb38920"
      ],
      "layout": "IPY_MODEL_d568d9b894694b6fb432456031cee230"
     }
    },
    "f6b3c67d61114db5810bd78339a218d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa94f90b735f418fb2b502f7877b5306": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a74bacc051494d1ea0f4cbd656505cfe",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0fbfe002ccd541f9b6ab62ed4eebef35",
      "value": 570
     }
    },
    "fc871ed94e764fe884ffdafca1445bfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a5458551f974a94b61ff658ae59fa70",
      "placeholder": "​",
      "style": "IPY_MODEL_e9ee9acc5e414c65ad10b8864cc07b07",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
