{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Waumhn_ldoGu"
   },
   "source": [
    "## FRISS with MFC\n",
    "\n",
    "Implementation of the FRISS using the Media Frames Corpus (MFC) from Card et al. (2015). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.7)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
      "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FRISS_srl.pkl',\n",
       " 'README.md',\n",
       " 'used_labels_a1.npy',\n",
       " 'notebooks',\n",
       " 'FRISS_SRL_unlabeled.pkl',\n",
       " 'chunks.pkl',\n",
       " 'grid_search_metrics.csv',\n",
       " 'predicted_labels.npy',\n",
       " '.git',\n",
       " 'used_labels_p.npy',\n",
       " 'assets',\n",
       " 'friss',\n",
       " 'models',\n",
       " 'used_labels_a0.npy',\n",
       " '.ipynb_checkpoints',\n",
       " 'data',\n",
       " '.gitignore',\n",
       " 'frameaxis']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_path = \"data/mfc/immigration_labeled.json\"\n",
    "unlabeld_path = \"data/mfc/immigration_unlabeled.json\"\n",
    "codes_path = \"data/mfc/codes.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from path \n",
    "import json\n",
    "\n",
    "with open(labeled_path) as f:\n",
    "    labeled = json.load(f)\n",
    "\n",
    "with open(unlabeld_path) as f:\n",
    "    unlabeld = json.load(f)\n",
    "\n",
    "with open(codes_path) as f:\n",
    "    codes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labeled_data(labeled, codes):\n",
    "    # articles list\n",
    "    articles_list = []\n",
    "\n",
    "    # Iterate through the data to fill the DataFrame\n",
    "    for article_id, article_data in labeled.items():\n",
    "        annotations_data = article_data['annotations']\n",
    "\n",
    "        irrelevant_dict = annotations_data['irrelevant']\n",
    "\n",
    "        text = article_data['text']\n",
    "        irrelevant = article_data['irrelevant']\n",
    "\n",
    "        # if primary_frame is none set to 15.0\n",
    "        if article_data['primary_frame'] is not None:\n",
    "            primary_frame = str(article_data['primary_frame']).split(\".\")[0] + \".0\"\n",
    "        else:\n",
    "            primary_frame = \"15.0\"\n",
    "\n",
    "        # get primary frame from code\n",
    "        primary_frame = str(codes[primary_frame])\n",
    "\n",
    "        # split text into sentences using nltk library\n",
    "        sentences = sent_tokenize(text)\n",
    "\n",
    "        # iterate through sentences\n",
    "        for sentence in sentences:\n",
    "            article = {\n",
    "                'article_id': article_id,\n",
    "                'irrelevant': irrelevant,\n",
    "                'text': sentence,\n",
    "                'document_frame': primary_frame\n",
    "            }\n",
    "\n",
    "            articles_list.append(article)\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    df = pd.DataFrame(articles_list, columns=['article_id', 'irrelevant', 'text', 'document_frame'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unlabeled_data(unlabeled):\n",
    "    # articles list\n",
    "    articles_list = []\n",
    "\n",
    "    for idx, article in enumerate(unlabeled):\n",
    "        article_id = f\"unlabeled_{idx}\" \n",
    "        text = article['text']\n",
    "\n",
    "        # split text into sentences using nltk library\n",
    "        sentences = sent_tokenize(text)\n",
    "\n",
    "        # iterate through sentences\n",
    "        for sentence in sentences:\n",
    "            article = {\n",
    "                'article_id': article_id,\n",
    "                'text': sentence\n",
    "            }\n",
    "\n",
    "            articles_list.append(article)\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    df = pd.DataFrame(articles_list, columns=['article_id', 'text'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get labeled and unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled Count:  74468\n",
      "Unlabeled Count:  460535\n"
     ]
    }
   ],
   "source": [
    "df_labeled = get_labeled_data(labeled, codes)\n",
    "df_unlabeled = get_unlabeled_data(unlabeld)\n",
    "\n",
    "print(\"Labeled Count: \", len(df_labeled))\n",
    "print(\"Unlabeled Count: \", len(df_unlabeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_labeled_df(df):\n",
    "    df = df[df[\"irrelevant\"] == False][[\"article_id\", \"text\", \"document_frame\"]]\n",
    "\n",
    "    # create for each code a col and fill with 1 if code is in code col\n",
    "    df = pd.concat([df, pd.get_dummies(df['document_frame'])], axis=1)  \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1296
    },
    "executionInfo": {
     "elapsed": 3772,
     "status": "ok",
     "timestamp": 1696624002536,
     "user": {
      "displayName": "Elias Anderlohr",
      "userId": "15301978580987406749"
     },
     "user_tz": -120
    },
    "id": "DG_Xix7gdoGy",
    "outputId": "d6fad26e-e6f7-4c20-f4bb-c7b01d51eb33",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_labeled = preprocess_labeled_df(df_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>text</th>\n",
       "      <th>document_frame</th>\n",
       "      <th>Capacity and Resources</th>\n",
       "      <th>Crime and Punishment</th>\n",
       "      <th>Cultural Identity</th>\n",
       "      <th>Economic</th>\n",
       "      <th>External Regulation and Reputation</th>\n",
       "      <th>Fairness and Equality</th>\n",
       "      <th>Health and Safety</th>\n",
       "      <th>Legality, Constitutionality, Jurisdiction</th>\n",
       "      <th>Morality</th>\n",
       "      <th>Other</th>\n",
       "      <th>Policy Prescription and Evaluation</th>\n",
       "      <th>Political</th>\n",
       "      <th>Public Sentiment</th>\n",
       "      <th>Quality of Life</th>\n",
       "      <th>Security and Defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>IMM-10005\\n\\nPRIMARY\\n\\nImmigrants without HOP...</td>\n",
       "      <td>Quality of Life</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>It mounted as students went around the room te...</td>\n",
       "      <td>Quality of Life</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>Georgia Tech.</td>\n",
       "      <td>Quality of Life</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>University of Georgia.</td>\n",
       "      <td>Quality of Life</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Immigration1.0-10005</td>\n",
       "      <td>\"All I could say was, 'I'm planning to see if ...</td>\n",
       "      <td>Quality of Life</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             article_id                                               text  \\\n",
       "0  Immigration1.0-10005  IMM-10005\\n\\nPRIMARY\\n\\nImmigrants without HOP...   \n",
       "1  Immigration1.0-10005  It mounted as students went around the room te...   \n",
       "2  Immigration1.0-10005                                      Georgia Tech.   \n",
       "3  Immigration1.0-10005                             University of Georgia.   \n",
       "4  Immigration1.0-10005  \"All I could say was, 'I'm planning to see if ...   \n",
       "\n",
       "    document_frame  Capacity and Resources  Crime and Punishment  \\\n",
       "0  Quality of Life                       0                     0   \n",
       "1  Quality of Life                       0                     0   \n",
       "2  Quality of Life                       0                     0   \n",
       "3  Quality of Life                       0                     0   \n",
       "4  Quality of Life                       0                     0   \n",
       "\n",
       "   Cultural Identity  Economic  External Regulation and Reputation  \\\n",
       "0                  0         0                                   0   \n",
       "1                  0         0                                   0   \n",
       "2                  0         0                                   0   \n",
       "3                  0         0                                   0   \n",
       "4                  0         0                                   0   \n",
       "\n",
       "   Fairness and Equality  Health and Safety  \\\n",
       "0                      0                  0   \n",
       "1                      0                  0   \n",
       "2                      0                  0   \n",
       "3                      0                  0   \n",
       "4                      0                  0   \n",
       "\n",
       "   Legality, Constitutionality, Jurisdiction  Morality  Other  \\\n",
       "0                                          0         0      0   \n",
       "1                                          0         0      0   \n",
       "2                                          0         0      0   \n",
       "3                                          0         0      0   \n",
       "4                                          0         0      0   \n",
       "\n",
       "   Policy Prescription and Evaluation  Political  Public Sentiment  \\\n",
       "0                                   0          0                 0   \n",
       "1                                   0          0                 0   \n",
       "2                                   0          0                 0   \n",
       "3                                   0          0                 0   \n",
       "4                                   0          0                 0   \n",
       "\n",
       "   Quality of Life  Security and Defense  \n",
       "0                1                     0  \n",
       "1                1                     0  \n",
       "2                1                     0  \n",
       "3                1                     0  \n",
       "4                1                     0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unlabeled_0</td>\n",
       "      <td>IMM-10000\\n\\nPRIMARY\\n\\nMetro Briefing New Yor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unlabeled_0</td>\n",
       "      <td>As part of the scheme, Ms. Holzer convinced Sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unlabeled_0</td>\n",
       "      <td>Katherine E. Finkelstein (NYT)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unlabeled_1</td>\n",
       "      <td>IMM-10003\\n\\nPRIMARY\\n\\nAmnesty Works for Amer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unlabeled_1</td>\n",
       "      <td>All working families would benefit from immigr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id                                               text\n",
       "0  unlabeled_0  IMM-10000\\n\\nPRIMARY\\n\\nMetro Briefing New Yor...\n",
       "1  unlabeled_0  As part of the scheme, Ms. Holzer convinced Sp...\n",
       "2  unlabeled_0                     Katherine E. Finkelstein (NYT)\n",
       "3  unlabeled_1  IMM-10003\\n\\nPRIMARY\\n\\nAmnesty Works for Amer...\n",
       "4  unlabeled_1  All working families would benefit from immigr..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unlabeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67480, 18), (460535, 2))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled.shape, df_unlabeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,\n",
       " Index(['Capacity and Resources', 'Crime and Punishment', 'Cultural Identity',\n",
       "        'Economic', 'External Regulation and Reputation',\n",
       "        'Fairness and Equality', 'Health and Safety',\n",
       "        'Legality, Constitutionality, Jurisdiction', 'Morality', 'Other',\n",
       "        'Policy Prescription and Evaluation', 'Political', 'Public Sentiment',\n",
       "        'Quality of Life', 'Security and Defense'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_columns = df_labeled.columns[3:]\n",
    "len(y_columns), y_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract SRL Embeddings from articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycuda\n",
      "  Downloading pycuda-2023.1.tar.gz (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting mako\n",
      "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytools>=2011.2\n",
      "  Downloading pytools-2023.1.1-py2.py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting appdirs>=1.4.0\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.9/dist-packages (from pytools>=2011.2->pycuda) (4.4.0)\n",
      "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from pytools>=2011.2->pycuda) (2.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from mako->pycuda) (2.1.2)\n",
      "Building wheels for collected packages: pycuda\n",
      "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycuda: filename=pycuda-2023.1-cp39-cp39-linux_x86_64.whl size=661891 sha256=7ba63f1c336cc2f5f67dd9ca9c38780502d88ce08925e21fb831562db935ae41\n",
      "  Stored in directory: /root/.cache/pip/wheels/58/65/0d/8abe9d4a5fad9c5ba54c7e6b57bbc927a99517f3383a428f9d\n",
      "Successfully built pycuda\n",
      "Installing collected packages: appdirs, pytools, mako, pycuda\n",
      "Successfully installed appdirs-1.4.4 mako-1.3.0 pycuda-2023.1 pytools-2023.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting allennlp\n",
      "  Downloading allennlp-2.10.1-py3-none-any.whl (730 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m730.2/730.2 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting allennlp-models\n",
      "  Downloading allennlp_models-2.10.1-py3-none-any.whl (464 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.5/464.5 kB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py>=3.6.0 in /usr/local/lib/python3.9/dist-packages (from allennlp) (3.8.0)\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.12.0 in /usr/local/lib/python3.9/dist-packages (from allennlp) (3.19.6)\n",
      "Collecting fairscale==0.4.6\n",
      "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.2/248.2 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cached-path<1.2.0,>=1.1.3\n",
      "  Downloading cached_path-1.1.6-py3-none-any.whl (26 kB)\n",
      "Collecting spacy<3.4,>=2.1.0\n",
      "  Downloading spacy-3.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.62 in /usr/local/lib/python3.9/dist-packages (from allennlp) (4.64.1)\n",
      "Collecting more-itertools>=8.12.0\n",
      "  Downloading more_itertools-10.1.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.6.5 in /usr/local/lib/python3.9/dist-packages (from allennlp) (3.7)\n",
      "Requirement already satisfied: torchvision<0.14.0,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from allennlp) (0.13.1+cu116)\n",
      "Collecting lmdb>=1.2.1\n",
      "  Downloading lmdb-1.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.5/298.5 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting termcolor==1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting base58>=2.1.1\n",
      "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
      "Collecting transformers<4.21,>=4.1\n",
      "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboardX>=1.2\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece>=0.1.96 in /usr/local/lib/python3.9/dist-packages (from allennlp) (0.1.97)\n",
      "Collecting wandb<0.13.0,>=0.10.0\n",
      "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.28 in /usr/local/lib/python3.9/dist-packages (from allennlp) (2.28.2)\n",
      "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.9/dist-packages (from allennlp) (1.9.2)\n",
      "Collecting filelock<3.8,>=3.3\n",
      "  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: numpy>=1.21.4 in /usr/local/lib/python3.9/dist-packages (from allennlp) (1.23.4)\n",
      "Requirement already satisfied: traitlets>5.1.1 in /usr/local/lib/python3.9/dist-packages (from allennlp) (5.8.1)\n",
      "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.9/dist-packages (from allennlp) (0.3.5.1)\n",
      "Requirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from allennlp) (0.4.2)\n",
      "Requirement already satisfied: pytest>=6.2.5 in /usr/local/lib/python3.9/dist-packages (from allennlp) (7.2.1)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch<1.13.0,>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from allennlp) (1.12.1+cu116)\n",
      "Collecting jsonnet>=0.10.0\n",
      "  Downloading jsonnet-0.20.0.tar.gz (594 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.2/594.2 kB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.0.16 in /usr/local/lib/python3.9/dist-packages (from allennlp) (0.12.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from allennlp) (1.1.2)\n",
      "Collecting word2number>=1.1\n",
      "  Downloading word2number-1.1.zip (9.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py-rouge==1.1\n",
      "  Downloading py_rouge-1.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (from allennlp-models) (2.4.0)\n",
      "Collecting conllu==4.4.2\n",
      "  Downloading conllu-4.4.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.0.16\n",
      "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rich<13.0,>=12.1\n",
      "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: boto3<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from cached-path<1.2.0,>=1.1.3->allennlp) (1.24.90)\n",
      "Collecting google-cloud-storage<3.0,>=1.32.0\n",
      "  Downloading google_cloud_storage-2.13.0-py2.py3-none-any.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.0.16->allennlp) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.0.16->allennlp) (4.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.0.16->allennlp) (5.4.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk>=3.6.5->allennlp) (2022.10.31)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk>=3.6.5->allennlp) (8.1.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk>=3.6.5->allennlp) (1.2.0)\n",
      "Collecting attrs>=19.2.0\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: iniconfig in /usr/local/lib/python3.9/dist-packages (from pytest>=6.2.5->allennlp) (2.0.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from pytest>=6.2.5->allennlp) (2.0.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.9/dist-packages (from pytest>=6.2.5->allennlp) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.9/dist-packages (from pytest>=6.2.5->allennlp) (1.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.28->allennlp) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.28->allennlp) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.28->allennlp) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.28->allennlp) (2.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.1->allennlp) (3.1.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.7.9)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.9)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.10.1)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp39-cp39-manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (66.1.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (6.3.0)\n",
      "Collecting thinc<8.1.0,>=8.0.14\n",
      "  Downloading thinc-8.0.17-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (668 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m668.8/668.8 kB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.4.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.8)\n",
      "Collecting protobuf<4.0.0,>=3.12.0\n",
      "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision<0.14.0,>=0.8.1->allennlp) (9.2.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers<4.21,>=4.1->allennlp) (0.12.1)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/lib/python3/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.14.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.0.11)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.14.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (5.9.4)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (0.1.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (3.1.30)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.3.2)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.3)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (0.4.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (3.8.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (2023.1.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (1.5.0)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (10.0.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets->allennlp-models) (0.70.13)\n",
      "Collecting wcwidth<0.3.0,>=0.2.12\n",
      "  Downloading wcwidth-0.2.12-py2.py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.90 in /usr/local/lib/python3.9/dist-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.27.90)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->allennlp-models) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->allennlp-models) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->allennlp-models) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->allennlp-models) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->allennlp-models) (4.0.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp) (4.0.10)\n",
      "Collecting google-auth<3.0dev,>=2.23.3\n",
      "  Downloading google_auth-2.25.2-py2.py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.2/184.2 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Collecting google-resumable-media>=2.6.0\n",
      "  Downloading google_resumable_media-2.6.0-py2.py3-none-any.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.15.0-py3-none-any.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.0/122.0 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-core<3.0dev,>=2.3.0\n",
      "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp) (2.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.4,>=2.1.0->allennlp) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->allennlp-models) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->allennlp-models) (2022.7.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp) (5.0.0)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl (228 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.7/228.7 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (4.7.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.4.8)\n",
      "Building wheels for collected packages: fairscale, termcolor, jsonnet, word2number\n",
      "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307222 sha256=2b422a20ff3c1f58683079b0ecb158416222ac70cff5934681edbeb610402b4d\n",
      "  Stored in directory: /root/.cache/pip/wheels/8d/7b/f9/6c7a350821ca240450550801e17996aee846b71caaccda7a32\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4833 sha256=bfb3d21e5d7eda09080c284cd3b85681359a26db59e7a7cbda0896c462f0752e\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/00/51/e04e70a050b271a6aac779726204a324ada2b39b99334175c3\n",
      "  Building wheel for jsonnet (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jsonnet: filename=jsonnet-0.20.0-cp39-cp39-linux_x86_64.whl size=6619701 sha256=a5f3f91328e8522e951e6997bb00d56d93a9a628f1e20a7fa2272e8a1d044349\n",
      "  Stored in directory: /root/.cache/pip/wheels/77/1a/fe/4d7df1823604150f77a6877f88fc6236d7c56d92a4d15e8b8c\n",
      "  Building wheel for word2number (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5566 sha256=7e221d1f41168c78ab11a0edf106296c2d74f7a68cd7857b5d0de7af586c6059\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/1d/b2/768b65901d249c6eb2a8d9c30392506555a4e94055ba4e0aa0\n",
      "Successfully built fairscale termcolor jsonnet word2number\n",
      "Installing collected packages: word2number, wcwidth, termcolor, py-rouge, lmdb, jsonnet, commonmark, sacremoses, rich, pydantic, protobuf, more-itertools, google-crc32c, ftfy, filelock, conllu, base58, attrs, thinc, tensorboardX, huggingface-hub, googleapis-common-protos, google-resumable-media, google-auth, fairscale, wandb, transformers, spacy, google-api-core, google-cloud-core, google-cloud-storage, cached-path, allennlp, allennlp-models\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.6\n",
      "    Uninstalling wcwidth-0.2.6:\n",
      "      Successfully uninstalled wcwidth-0.2.6\n",
      "  Attempting uninstall: termcolor\n",
      "    Found existing installation: termcolor 2.2.0\n",
      "    Uninstalling termcolor-2.2.0:\n",
      "      Successfully uninstalled termcolor-2.2.0\n",
      "  Attempting uninstall: rich\n",
      "    Found existing installation: rich 13.2.0\n",
      "    Uninstalling rich-13.2.0:\n",
      "      Successfully uninstalled rich-13.2.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.9.2\n",
      "    Uninstalling pydantic-1.9.2:\n",
      "      Successfully uninstalled pydantic-1.9.2\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.9.0\n",
      "    Uninstalling filelock-3.9.0:\n",
      "      Successfully uninstalled filelock-3.9.0\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 18.2.0\n",
      "    Uninstalling attrs-18.2.0:\n",
      "      Successfully uninstalled attrs-18.2.0\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.1.7\n",
      "    Uninstalling thinc-8.1.7:\n",
      "      Successfully uninstalled thinc-8.1.7\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.12.0\n",
      "    Uninstalling huggingface-hub-0.12.0:\n",
      "      Successfully uninstalled huggingface-hub-0.12.0\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.16.0\n",
      "    Uninstalling google-auth-2.16.0:\n",
      "      Successfully uninstalled google-auth-2.16.0\n",
      "  Attempting uninstall: wandb\n",
      "    Found existing installation: wandb 0.13.4\n",
      "    Uninstalling wandb-0.13.4:\n",
      "      Successfully uninstalled wandb-0.13.4\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.21.3\n",
      "    Uninstalling transformers-4.21.3:\n",
      "      Successfully uninstalled transformers-4.21.3\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.4.1\n",
      "    Uninstalling spacy-3.4.1:\n",
      "      Successfully uninstalled spacy-3.4.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "gradient 2.0.6 requires attrs<=19, but you have attrs 23.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed allennlp-2.10.1 allennlp-models-2.10.1 attrs-23.1.0 base58-2.1.1 cached-path-1.1.6 commonmark-0.9.1 conllu-4.4.2 fairscale-0.4.6 filelock-3.7.1 ftfy-6.1.3 google-api-core-2.15.0 google-auth-2.25.2 google-cloud-core-2.4.1 google-cloud-storage-2.13.0 google-crc32c-1.5.0 google-resumable-media-2.6.0 googleapis-common-protos-1.62.0 huggingface-hub-0.10.1 jsonnet-0.20.0 lmdb-1.4.1 more-itertools-10.1.0 protobuf-3.20.3 py-rouge-1.1 pydantic-1.8.2 rich-12.6.0 sacremoses-0.1.1 spacy-3.3.3 tensorboardX-2.6.2.2 termcolor-1.1.0 thinc-8.0.17 transformers-4.20.1 wandb-0.12.21 wcwidth-0.2.12 word2number-1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pycuda\n",
    "!pip install allennlp allennlp-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadro RTX 5000\n"
     ]
    }
   ],
   "source": [
    "# get name / id of cuda device\n",
    "import pycuda.driver as cuda\n",
    "\n",
    "cuda.init()\n",
    "device = cuda.Device(0)\n",
    "print(device.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def batched_extract_srl_components(batched_sentences, predictor):\n",
    "    # Convert each sentence into the required format for the predictor\n",
    "    batched_sentences = [{'sentence': sentence} for sentence in batched_sentences]\n",
    "\n",
    "    # Prepare the batched input for the predictor\n",
    "    batched_srl = predictor.predict_batch_json(batched_sentences)\n",
    "\n",
    "    # Extract SRL components from the batched predictions\n",
    "    results = []\n",
    "    for index, srl in enumerate(batched_srl):\n",
    "        sentence_results = []\n",
    "        for verb_entry in srl['verbs']:\n",
    "            arg_components = {'ARG0': [], 'ARG1': []}\n",
    "            for i, tag in enumerate(verb_entry['tags']):\n",
    "                if 'ARG0' in tag:\n",
    "                    arg_components['ARG0'].append(srl['words'][i])\n",
    "                elif 'ARG1' in tag:\n",
    "                    arg_components['ARG1'].append(srl['words'][i])\n",
    "\n",
    "            if arg_components['ARG0'] or arg_components['ARG1']:\n",
    "                sentence_results.append({\n",
    "                    'predicate': verb_entry['verb'],\n",
    "                    'ARG0': ' '.join(arg_components['ARG0']),\n",
    "                    'ARG1': ' '.join(arg_components['ARG1'])\n",
    "                })\n",
    "\n",
    "        if sentence_results:\n",
    "            # add empty dict if predicate, arg0 or arg1 is empty\n",
    "            if not sentence_results[0]['predicate']:\n",
    "                results.append({'predicate': '', 'ARG0': '', 'ARG1': ''})\n",
    "            elif not sentence_results[0]['ARG0']:\n",
    "                results.append({'predicate': '', 'ARG0': '', 'ARG1': ''})\n",
    "            elif not sentence_results[0]['ARG1']:\n",
    "                results.append({'predicate': '', 'ARG0': '', 'ARG1': ''})\n",
    "            else:\n",
    "                results.append(sentence_results)    \n",
    "        else:\n",
    "            results.append([{'predicate': '', 'ARG0': '', 'ARG1': ''}])\n",
    "\n",
    "    return results\n",
    "\n",
    "def optimized_extract_srl(X, predictor, batch_size=32):\n",
    "    all_results = []\n",
    "\n",
    "    # Process sentences in batches\n",
    "    for i in tqdm(range(0, len(X), batch_size), desc=\"Processing Batches\"):\n",
    "        batched_sentences = X[i:i+batch_size]\n",
    "\n",
    "        batch_results = batched_extract_srl_components(batched_sentences, predictor)\n",
    "\n",
    "        all_results.extend(batch_results)\n",
    "\n",
    "    return pd.Series(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def get_X_srl(X, recalculate=False, pickle_path=\"../notebooks/classifier/X_srl_filtered.pkl\", _save = True):\n",
    "    \"\"\"\n",
    "    Returns the X_srl either by loading from a pickled file or recalculating.\n",
    "    \"\"\"\n",
    "    if recalculate or not os.path.exists(pickle_path):\n",
    "        print(\"Recalculate SRL\")\n",
    "        # Load predictor\n",
    "        predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\", cuda_device=0)\n",
    "\n",
    "        # make sentences max 480 chars long\n",
    "        X = X.apply(lambda x: x[:480])\n",
    "\n",
    "        X_srl = optimized_extract_srl(X, predictor, batch_size=32)\n",
    "\n",
    "        if _save:\n",
    "            print(\"Save SRL to Pickle\")\n",
    "            with open(pickle_path, 'wb') as f:\n",
    "                pickle.dump(X_srl, f)\n",
    "    else:\n",
    "        print(\"Load SRL from Pickle\")\n",
    "        with tqdm(total=os.path.getsize(pickle_path)) as pbar:\n",
    "            with open(pickle_path, 'rb') as f:\n",
    "                X_srl = pickle.load(f)\n",
    "                pbar.update(os.path.getsize(pickle_path))\n",
    "                \n",
    "    return X_srl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_X_srl(df_unlabeled[\"text\"], recalculate=True, pickle_path=\"../notebooks/FRISS_SRL_unlabeled.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def free_gpu():\n",
    "    print(torch.cuda.mem_get_info())\n",
    "    print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/distributed/distributed_c10d.py:181: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([30522, 768])\n",
      "<class 'torch.Tensor'> torch.Size([512, 768])\n",
      "<class 'torch.Tensor'> torch.Size([2, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([1, 512])\n",
      "<class 'torch.Tensor'> torch.Size([1, 512])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([768, 1536])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([15, 768])\n",
      "<class 'torch.Tensor'> torch.Size([15, 768])\n",
      "<class 'torch.Tensor'> torch.Size([15, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([15, 768])\n",
      "<class 'torch.Tensor'> torch.Size([15])\n",
      "<class 'torch.Tensor'> torch.Size([15, 768])\n",
      "<class 'torch.Tensor'> torch.Size([15])\n",
      "<class 'torch.Tensor'> torch.Size([15, 768])\n",
      "<class 'torch.Tensor'> torch.Size([15])\n",
      "<class 'torch.Tensor'> torch.Size([15, 768])\n",
      "<class 'torch.Tensor'> torch.Size([15])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 24, 32])\n",
      "<class 'torch.Tensor'> torch.Size([64, 24, 32])\n",
      "<class 'torch.Tensor'> torch.Size([64, 24, 10, 8])\n",
      "<class 'torch.Tensor'> torch.Size([64, 24, 10, 8])\n",
      "<class 'torch.Tensor'> torch.Size([64, 24, 10, 8])\n",
      "<class 'torch.Tensor'> torch.Size([64, 24, 10, 8])\n",
      "<class 'torch.Tensor'> torch.Size([64, 24, 10, 8])\n",
      "<class 'torch.Tensor'> torch.Size([64, 24, 10, 8])\n",
      "<class 'torch.Tensor'> torch.Size([64, 15])\n",
      "<class 'torch.Tensor'> torch.Size([64, 24, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 24, 10, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 24, 10, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 24, 10, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([64, 15])\n",
      "<class 'torch.Tensor'> torch.Size([64, 15])\n",
      "<class 'torch.Tensor'> torch.Size([64, 15])\n",
      "<class 'torch.Tensor'> torch.Size([64, 15])\n",
      "<class 'torch.Tensor'> torch.Size([64, 24, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 24, 10, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 24, 10, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 24, 10, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 15])\n",
      "<class 'torch.Tensor'> torch.Size([64, 15])\n",
      "<class 'torch.Tensor'> torch.Size([15, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 15])\n",
      "<class 'torch.Tensor'> torch.Size([64, 15])\n",
      "<class 'torch.Tensor'> torch.Size([15, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 15])\n",
      "<class 'torch.Tensor'> torch.Size([64, 15])\n",
      "<class 'torch.Tensor'> torch.Size([15, 768])\n",
      "<class 'torch.Tensor'> torch.Size([10, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([15, 768])\n",
      "<class 'torch.Tensor'> torch.Size([15])\n",
      "<class 'torch.Tensor'> torch.Size([1, 512])\n",
      "<class 'torch.Tensor'> torch.Size([1, 512])\n",
      "<class 'torch.Tensor'> torch.Size([768, 1536])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([30522, 768])\n",
      "<class 'torch.Tensor'> torch.Size([512, 768])\n",
      "<class 'torch.Tensor'> torch.Size([2, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([15, 768])\n",
      "<class 'torch.Tensor'> torch.Size([15])\n",
      "<class 'torch.Tensor'> torch.Size([15, 768])\n",
      "<class 'torch.Tensor'> torch.Size([15])\n",
      "<class 'torch.Tensor'> torch.Size([15, 768])\n",
      "<class 'torch.Tensor'> torch.Size([15])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "def list_gpu_tensors():\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            if torch.is_tensor(obj):\n",
    "                if obj.is_cuda:\n",
    "                    obj = obj.cpu()\n",
    "                    obj = obj.to(\"cpu\")\n",
    "                    print(type(obj), obj.size())\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "list_gpu_tensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "class ArticleDataset(Dataset):\n",
    "    def __init__(self, X, X_srl, tokenizer, labels=None, max_sentences_per_article=32, max_sentence_length=32, max_args_per_sentence=10, max_arg_length=16, _ignore_y=False):\n",
    "        self.X = X  # DataFrame where each row has multiple sentences\n",
    "        self.X_srl = X_srl  # DataFrame where each row has multiple dictionaries for SRL\n",
    "        self.labels = labels  # DataFrame where each row has a list of lists of integers\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_sentences_per_article = max_sentences_per_article\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.max_args_per_sentence = max_args_per_sentence\n",
    "        self.max_arg_length = max_arg_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentences = self.X.iloc[idx]\n",
    "        srl_data = self.X_srl.iloc[idx]\n",
    "\n",
    "        labels = None\n",
    "        if self.labels is False:\n",
    "            labels = self.labels.iloc[idx]\n",
    "        else:\n",
    "            # placeholder for labels\n",
    "            labels = [[0] * 15]\n",
    "\n",
    "        # Tokenize sentences and get attention masks\n",
    "        sentence_ids, sentence_attention_masks = [], []\n",
    "        for sentence in sentences:\n",
    "            encoded = self.tokenizer(sentence, add_special_tokens=True, max_length=self.max_sentence_length, truncation=True, padding='max_length', return_attention_mask=True)\n",
    "            sentence_ids.append(encoded['input_ids'])\n",
    "            sentence_attention_masks.append(encoded['attention_mask'])\n",
    "\n",
    "        # Padding for sentences if necessary\n",
    "        while len(sentence_ids) < self.max_sentences_per_article:\n",
    "            sentence_ids.append([0] * self.max_sentence_length)\n",
    "            sentence_attention_masks.append([0] * self.max_sentence_length)\n",
    "\n",
    "        sentence_ids = sentence_ids[:self.max_sentences_per_article]\n",
    "        sentence_attention_masks = sentence_attention_masks[:self.max_sentences_per_article]\n",
    "\n",
    "        # Process SRL data\n",
    "        predicates, arg0s, arg1s = [], [], []\n",
    "        predicate_attention_masks, arg0_attention_masks, arg1_attention_masks = [], [], []\n",
    "        for srl_items in srl_data:\n",
    "            sentence_predicates, sentence_arg0s, sentence_arg1s = [], [], []\n",
    "            sentence_predicate_masks, sentence_arg0_masks, sentence_arg1_masks = [], [], []\n",
    "\n",
    "            if not isinstance(srl_items, list):\n",
    "                srl_items = [srl_items]\n",
    "\n",
    "            for item in srl_items:\n",
    "                encoded_predicate = self.tokenizer(item[\"predicate\"], add_special_tokens=True, max_length=self.max_arg_length, truncation=True, padding='max_length', return_attention_mask=True)\n",
    "                encoded_arg0 = self.tokenizer(item[\"ARG0\"], add_special_tokens=True, max_length=self.max_arg_length, truncation=True, padding='max_length', return_attention_mask=True)\n",
    "                encoded_arg1 = self.tokenizer(item[\"ARG1\"], add_special_tokens=True, max_length=self.max_arg_length, truncation=True, padding='max_length', return_attention_mask=True)\n",
    "\n",
    "                sentence_predicates.append(encoded_predicate['input_ids'])\n",
    "                sentence_arg0s.append(encoded_arg0['input_ids'])\n",
    "                sentence_arg1s.append(encoded_arg1['input_ids'])\n",
    "\n",
    "                sentence_predicate_masks.append(encoded_predicate['attention_mask'])\n",
    "                sentence_arg0_masks.append(encoded_arg0['attention_mask'])\n",
    "                sentence_arg1_masks.append(encoded_arg1['attention_mask'])\n",
    "\n",
    "            # Padding for SRL elements\n",
    "            for _ in range(self.max_args_per_sentence):\n",
    "                sentence_predicates.append([0] * self.max_arg_length)\n",
    "                sentence_arg0s.append([0] * self.max_arg_length)\n",
    "                sentence_arg1s.append([0] * self.max_arg_length)\n",
    "\n",
    "                sentence_predicate_masks.append([0] * self.max_arg_length)\n",
    "                sentence_arg0_masks.append([0] * self.max_arg_length)\n",
    "                sentence_arg1_masks.append([0] * self.max_arg_length)\n",
    "\n",
    "            sentence_predicates = sentence_predicates[:self.max_args_per_sentence]\n",
    "            sentence_arg0s = sentence_arg0s[:self.max_args_per_sentence]\n",
    "            sentence_arg1s = sentence_arg1s[:self.max_args_per_sentence]\n",
    "\n",
    "            sentence_predicate_masks = sentence_predicate_masks[:self.max_args_per_sentence]\n",
    "            sentence_arg0_masks = sentence_arg0_masks[:self.max_args_per_sentence]\n",
    "            sentence_arg1_masks = sentence_arg1_masks[:self.max_args_per_sentence]\n",
    "\n",
    "            predicates.append(sentence_predicates)\n",
    "            arg0s.append(sentence_arg0s)\n",
    "            arg1s.append(sentence_arg1s)\n",
    "\n",
    "            predicate_attention_masks.append(sentence_predicate_masks)\n",
    "            arg0_attention_masks.append(sentence_arg0_masks)\n",
    "            arg1_attention_masks.append(sentence_arg1_masks)\n",
    "\n",
    "        # Padding for SRL data\n",
    "        srl_padding = [[0] * self.max_arg_length] * self.max_args_per_sentence\n",
    "        mask_padding = [[0] * self.max_arg_length] * self.max_args_per_sentence\n",
    "\n",
    "        predicates = (predicates + [srl_padding] * self.max_sentences_per_article)[:self.max_sentences_per_article]\n",
    "        arg0s = (arg0s + [srl_padding] * self.max_sentences_per_article)[:self.max_sentences_per_article]\n",
    "        arg1s = (arg1s + [srl_padding] * self.max_sentences_per_article)[:self.max_sentences_per_article]\n",
    "\n",
    "        predicate_attention_masks = (predicate_attention_masks + [mask_padding] * self.max_sentences_per_article)[:self.max_sentences_per_article]\n",
    "        arg0_attention_masks = (arg0_attention_masks + [mask_padding] * self.max_sentences_per_article)[:self.max_sentences_per_article]\n",
    "        arg1_attention_masks = (arg1_attention_masks + [mask_padding] * self.max_sentences_per_article)[:self.max_sentences_per_article]\n",
    "\n",
    "        data = {\n",
    "            'sentence_ids': torch.tensor(sentence_ids, dtype=torch.long),\n",
    "            'sentence_attention_masks': torch.tensor(sentence_attention_masks, dtype=torch.long),\n",
    "            'predicate_ids': torch.tensor(predicates, dtype=torch.long),\n",
    "            'predicate_attention_masks': torch.tensor(predicate_attention_masks, dtype=torch.long),\n",
    "            'arg0_ids': torch.tensor(arg0s, dtype=torch.long),\n",
    "            'arg0_attention_masks': torch.tensor(arg0_attention_masks, dtype=torch.long),\n",
    "            'arg1_ids': torch.tensor(arg1s, dtype=torch.long),\n",
    "            'arg1_attention_masks': torch.tensor(arg1_attention_masks, dtype=torch.long),\n",
    "            'labels': torch.tensor(labels[0], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    # Extract individual lists from the batch\n",
    "    sentence_ids = [item['sentence_ids'] for item in batch]\n",
    "    sentence_attention_masks = [item['sentence_attention_masks'] for item in batch]\n",
    "    predicate_ids = [item['predicate_ids'] for item in batch]\n",
    "    predicate_attention_masks = [item['predicate_attention_masks'] for item in batch]\n",
    "    arg0_ids = [item['arg0_ids'] for item in batch]\n",
    "    arg0_attention_masks = [item['arg0_attention_masks'] for item in batch]\n",
    "    arg1_ids = [item['arg1_ids'] for item in batch]\n",
    "    arg1_attention_masks = [item['arg1_attention_masks'] for item in batch]\n",
    "    labels = [item['labels'] for item in batch]\n",
    "    \n",
    "    # Pad each list\n",
    "    sentence_ids = torch.nn.utils.rnn.pad_sequence(sentence_ids, batch_first=True, padding_value=0)\n",
    "    sentence_attention_masks = torch.nn.utils.rnn.pad_sequence(sentence_attention_masks, batch_first=True, padding_value=0)\n",
    "    predicate_ids = torch.nn.utils.rnn.pad_sequence(predicate_ids, batch_first=True, padding_value=0)\n",
    "    predicate_attention_masks = torch.nn.utils.rnn.pad_sequence(predicate_attention_masks, batch_first=True, padding_value=0)\n",
    "    arg0_ids = torch.nn.utils.rnn.pad_sequence(arg0_ids, batch_first=True, padding_value=0)\n",
    "    arg0_attention_masks = torch.nn.utils.rnn.pad_sequence(arg0_attention_masks, batch_first=True, padding_value=0)\n",
    "    arg1_ids = torch.nn.utils.rnn.pad_sequence(arg1_ids, batch_first=True, padding_value=0)\n",
    "    arg1_attention_masks = torch.nn.utils.rnn.pad_sequence(arg1_attention_masks, batch_first=True, padding_value=0)\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=0)\n",
    "\n",
    "    # Create the output dictionary\n",
    "    output_dict = {\n",
    "        'sentence_ids': sentence_ids,\n",
    "        'sentence_attention_masks': sentence_attention_masks,\n",
    "        'predicate_ids': predicate_ids,\n",
    "        'predicate_attention_masks': predicate_attention_masks,\n",
    "        'arg0_ids': arg0_ids,\n",
    "        'arg0_attention_masks': arg0_attention_masks,\n",
    "        'arg1_ids': arg1_ids,\n",
    "        'arg1_attention_masks': arg1_attention_masks,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "def preprocess_df(df, recalculate_srl=False, pickle_path=\"../notebooks/FRISS_srl.pkl\", _ignore_y=False, _save = False):\n",
    "    # reset index of df\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Get X_srl\n",
    "    X_srl = get_X_srl(df[\"text\"], recalculate=recalculate_srl, pickle_path=pickle_path, _save = _save)\n",
    "\n",
    "    # reset index of X_srl\n",
    "    X_srl = X_srl.reset_index(drop=True)\n",
    "\n",
    "    # Aggregating 'text' column in df into a list of strings for each article_id\n",
    "    X_subset = df.groupby('article_id')['text'].apply(list).reset_index(name='text')\n",
    "    X_subset = X_subset['text']\n",
    "\n",
    "    # Assuming X_srl follows the same index order as df\n",
    "    X_srl_subset = X_srl.groupby(df['article_id']).apply(lambda x: x.values.tolist()).reset_index(name='srl_values')\n",
    "    X_srl_subset = X_srl_subset['srl_values']\n",
    "\n",
    "    if not _ignore_y:\n",
    "        # Columns to be one-hot encoded in y_subset\n",
    "        y_cols = ['Capacity and Resources', 'Crime and Punishment', 'Cultural Identity', \n",
    "                'Economic', 'External Regulation and Reputation', 'Fairness and Equality', \n",
    "                'Health and Safety', 'Legality, Constitutionality, Jurisdiction', \n",
    "                'Morality', 'Other', 'Policy Prescription and Evaluation', 'Political', \n",
    "                'Public Sentiment', 'Quality of Life', 'Security and Defense']\n",
    "\n",
    "        # Creating y_subset\n",
    "        y_subset = df.groupby('article_id')[y_cols].apply(lambda x: x.values.tolist()).reset_index(name='encoded_values')\n",
    "        y_subset = y_subset['encoded_values']\n",
    "    else:\n",
    "        # create empty y_subset\n",
    "        y_subset = [0] * len(X_subset)\n",
    "\n",
    "    return X_subset, X_srl_subset, y_subset\n",
    "\n",
    "def get_training_datasets(df, tokenizer, recalculate_srl=False, pickle_path=\"../notebooks/FRISS_srl.pkl\", batch_size=16, max_sentences_per_article=32, max_sentence_length=32,  max_args_per_sentence=10,  max_arg_length=16, test_size=0.1, _ignore_y=False):\n",
    "    print(\"IGNORE Y:\", _ignore_y)\n",
    "    X_subset, X_srl_subset, y_subset = preprocess_df(df, recalculate_srl=recalculate_srl, pickle_path=pickle_path, _ignore_y=_ignore_y)\n",
    "\n",
    "    # Len\n",
    "    print(\"X:\", len(X_subset))\n",
    "    print(\"X_srl:\", len(X_srl_subset))\n",
    "    print(\"y:\", len(y_subset))\n",
    "\n",
    "    print(\"CREATING DATASETS\")\n",
    "    \n",
    "    # Assuming X, X_srl, and y are already defined and have the same number of samples\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_subset, y_subset, test_size=test_size, random_state=42)\n",
    "    \n",
    "    print(\"TRAIN TEST SPLIT DONE\")\n",
    "    \n",
    "    X_srl_train, X_srl_test, _, _ = train_test_split(X_srl_subset, y_subset, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Create the dataset\n",
    "    train_dataset = ArticleDataset(X_train, X_srl_train, tokenizer, y_train, max_sentences_per_article, max_sentence_length,  max_args_per_sentence, max_arg_length)\n",
    "    test_dataset = ArticleDataset(X_test, X_srl_test, tokenizer, y_test, max_sentences_per_article, max_sentence_length, max_args_per_sentence, max_arg_length)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn, drop_last=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn, drop_last=True)\n",
    "    \n",
    "    print(\"CREATION DONE\")\n",
    "    return train_dataset, test_dataset , train_dataloader, test_dataloader\n",
    "\n",
    "\n",
    "def get_testing_dataset(df, tokenizer, recalculate_srl=False, pickle_path=\"../notebooks/FRISS_srl.pkl\", batch_size=16, max_sentences_per_article=32, max_sentence_length=32,  max_args_per_sentence=10, max_arg_length=16, sample_size=1000):\n",
    "    \"\"\"GET Datasets to test dict extraction\"\"\"\n",
    "    print(\"Get Testing Datasets for testing trained model\")\n",
    "    print()\n",
    "    X_subset, X_srl_subset, y_subset = preprocess_df(df, recalculate_srl=recalculate_srl, pickle_path=pickle_path, _ignore_y=True)\n",
    "\n",
    "    # take first sample_size samples\n",
    "    X_subset = X_subset[:sample_size]\n",
    "    X_srl_subset = X_srl_subset[:sample_size]\n",
    "    y_subset = y_subset[:sample_size]\n",
    "\n",
    "    # Len\n",
    "    print(\"X:\", len(X_subset))\n",
    "    print(\"X_srl:\", len(X_srl_subset))\n",
    "    print(\"y:\", len(y_subset))\n",
    "\n",
    "    print(\"CREATING DATASETS\")\n",
    "    \n",
    "    dataset = ArticleDataset(X_subset, X_srl_subset, tokenizer, y_subset, max_sentences_per_article, max_sentence_length,  max_args_per_sentence, max_arg_length)\n",
    "\n",
    "    # Create dataloaders\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn, drop_last=True)\n",
    "    \n",
    "    print(\"CREATION DONE\")\n",
    "    return dataset, dataloader\n",
    "\n",
    "# get dataset from string\n",
    "def get_dataset_from_string(string, tokenizer, max_sentences_per_article=32, max_sentence_length=32,  max_args_per_sentence=10, max_arg_length=16):\n",
    "    \"\"\"GET Datasets to test dict extraction\"\"\"\n",
    "    print(\"Get Testing Datasets for testing trained model\")\n",
    "    print()\n",
    "\n",
    "    # split text into sentences using nltk library\n",
    "    sentences = sent_tokenize(string)\n",
    "\n",
    "    # sentences to df and create article_id\n",
    "    df = pd.DataFrame(sentences, columns=['text'])\n",
    "    df['article_id'] = \"mock_article_id\"\n",
    "\n",
    "    X_subset, X_srl_subset, y_subset = preprocess_df(df, recalculate_srl=True, _ignore_y=True, _save = False)\n",
    "\n",
    "    # Len\n",
    "    print(\"X:\", len(X_subset))\n",
    "    print(\"X_srl:\", len(X_srl_subset))\n",
    "    print(\"y:\", len(y_subset))\n",
    "\n",
    "    print(\"CREATING DATASETS\")\n",
    "    \n",
    "    dataset = ArticleDataset(X_subset, X_srl_subset, tokenizer, y_subset, max_sentences_per_article, max_sentence_length,  max_args_per_sentence, max_arg_length)\n",
    "\n",
    "    # Create dataloaders\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    print(\"CREATION DONE\")\n",
    "    return dataset, dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Model\n",
    "The Model consist out of various Layers.\n",
    "\n",
    "1. SRL_Embedding\n",
    "2. Autoencoder\n",
    "3. FRISSLoss\n",
    "4. Unsupervised\n",
    "5. Supervised\n",
    "6. FRISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SRL_Embeddings\n",
    "\n",
    "The layer takes tensors of token IDs with the shape [batch_size, max_num_sentences, max_num_tokens] for the sentence, predicates, arg0 and arg1 and returns for each sentence an embedding with shape [batch_size, embedding_dim] for the sentence, predicate, arg0 and arg1. \n",
    "\n",
    "The single embedding for the sentence is extracted by taking the [CLS] token embedding. For the predicate, arg0 and arg1 by taking the mean over all word embeddings in this list of tokens. \n",
    "\n",
    "> Possible improvements: Better way of extracting the single embedding for predicate, arg0 and arg1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b14a7202e2c48dcbdf380273b80a06a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ae039f9aa6491b81af0ba9a7d1366f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shapes:  torch.Size([2, 12, 8]) torch.Size([2, 12, 9, 8]) torch.Size([2, 12, 9, 8]) torch.Size([2, 12, 9, 8])\n",
      "Outputs shapes:  torch.Size([2, 12, 768]) torch.Size([2, 12, 9, 768]) torch.Size([2, 12, 9, 768]) torch.Size([2, 12, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class SRL_Embeddings(nn.Module):\n",
    "    def __init__(self, bert_model_name=\"bert-base-uncased\"):\n",
    "        super(SRL_Embeddings, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(bert_model_name)\n",
    "        self.embedding_dim = 768  # for bert-base-uncased\n",
    "\n",
    "    def forward(self, sentence_ids, sentence_attention_masks, predicate_ids, predicate_attention_masks, arg0_ids, arg0_attention_masks, arg1_ids, arg1_attention_masks):\n",
    "        with torch.no_grad():\n",
    "            # Sentence embeddings\n",
    "            sentence_embeddings = self.bert_model(input_ids=sentence_ids.view(-1, sentence_ids.size(-1)), \n",
    "                                                  attention_mask=sentence_attention_masks.view(-1, sentence_attention_masks.size(-1)))[0]\n",
    "            sentence_embeddings = sentence_embeddings.view(sentence_ids.size(0), sentence_ids.size(1), -1, self.embedding_dim)\n",
    "            sentence_embeddings = sentence_embeddings.mean(dim=2)\n",
    "\n",
    "            # Predicate embeddings\n",
    "            predicate_embeddings = self.bert_model(input_ids=predicate_ids.view(-1, predicate_ids.size(-1)), \n",
    "                                                   attention_mask=predicate_attention_masks.view(-1, predicate_attention_masks.size(-1)))[0]\n",
    "            predicate_embeddings = predicate_embeddings.view(predicate_ids.size(0), predicate_ids.size(1), predicate_ids.size(2), -1, self.embedding_dim)\n",
    "            predicate_embeddings = predicate_embeddings.mean(dim=3)\n",
    "\n",
    "            # ARG0 embeddings\n",
    "            arg0_embeddings = self.bert_model(input_ids=arg0_ids.view(-1, arg0_ids.size(-1)), \n",
    "                                              attention_mask=arg0_attention_masks.view(-1, arg0_attention_masks.size(-1)))[0]\n",
    "            arg0_embeddings = arg0_embeddings.view(arg0_ids.size(0), arg0_ids.size(1), arg0_ids.size(2), -1, self.embedding_dim)\n",
    "            arg0_embeddings = arg0_embeddings.mean(dim=3)\n",
    "\n",
    "            # ARG1 embeddings\n",
    "            arg1_embeddings = self.bert_model(input_ids=arg1_ids.view(-1, arg1_ids.size(-1)), \n",
    "                                              attention_mask=arg1_attention_masks.view(-1, arg1_attention_masks.size(-1)))[0]\n",
    "            arg1_embeddings = arg1_embeddings.view(arg1_ids.size(0), arg1_ids.size(1), arg1_ids.size(2), -1, self.embedding_dim)\n",
    "            arg1_embeddings = arg1_embeddings.mean(dim=3)\n",
    "\n",
    "        return sentence_embeddings, predicate_embeddings, arg0_embeddings, arg1_embeddings\n",
    "\n",
    "# Generate dummy data for the SRL_Embeddings\n",
    "batch_size = 2\n",
    "num_sentences = 12\n",
    "sentence_length = 8\n",
    "num_args = 9\n",
    "predicate_length = 8\n",
    "arg0_length = 8\n",
    "arg1_length = 8\n",
    "\n",
    "# Dummy data for sentences, predicates, arg0, and arg1\n",
    "sentence_ids = torch.randint(0, 10000, (batch_size, num_sentences, sentence_length))\n",
    "predicate_ids = torch.randint(0, 10000, (batch_size, num_sentences, num_args, predicate_length))\n",
    "arg0_ids = torch.randint(0, 10000, (batch_size, num_sentences, num_args, arg0_length))\n",
    "arg1_ids = torch.randint(0, 10000, (batch_size, num_sentences, num_args, arg1_length))\n",
    "\n",
    "# Mock attention masks\n",
    "sentence_attention_masks = torch.randint(0, 2, (batch_size, num_sentences, sentence_length))\n",
    "predicate_attention_masks = torch.randint(0, 2, (batch_size, num_sentences, num_args, predicate_length))\n",
    "arg0_attention_masks = torch.randint(0, 2, (batch_size, num_sentences, num_args, arg0_length))\n",
    "arg1_attention_masks = torch.randint(0, 2, (batch_size, num_sentences, num_args, arg1_length))\n",
    "\n",
    "srl_embeddings = SRL_Embeddings()\n",
    "\n",
    "sentence_embeddings, predicate_embeddings, arg0_embeddings, arg1_embeddings = srl_embeddings(\n",
    "    sentence_ids, sentence_attention_masks, \n",
    "    predicate_ids, predicate_attention_masks, \n",
    "    arg0_ids, arg0_attention_masks, \n",
    "    arg1_ids, arg1_attention_masks\n",
    ")\n",
    "\n",
    "print(\"Inputs shapes: \", sentence_ids.shape, predicate_ids.shape, arg0_ids.shape, arg1_ids.shape)\n",
    "print(\"Outputs shapes: \", sentence_embeddings.shape, predicate_embeddings.shape, arg0_embeddings.shape, arg1_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shapes:\n",
      "p -> vhat: torch.Size([2, 768]), d: torch.Size([2, 20]), g: torch.Size([2, 20]), F: torch.Size([20, 768])\n",
      "a0 -> vhat: torch.Size([2, 768]), d: torch.Size([2, 20]), g: torch.Size([2, 20]), F: torch.Size([20, 768])\n",
      "a1 -> vhat: torch.Size([2, 768]), d: torch.Size([2, 20]), g: torch.Size([2, 20]), F: torch.Size([20, 768])\n",
      "NaN values:\n",
      "p -> vhat: False, d: False, g: False, F: False\n",
      "d:  tensor([[0.0200, 0.0505, 0.0359, 0.0191, 0.0505, 0.0585, 0.0541, 0.0228, 0.0475,\n",
      "         0.0144, 0.0322, 0.0760, 0.0715, 0.0178, 0.1491, 0.0708, 0.0701, 0.0571,\n",
      "         0.0202, 0.0620],\n",
      "        [0.0346, 0.0427, 0.0728, 0.0197, 0.0443, 0.0475, 0.0272, 0.0860, 0.0564,\n",
      "         0.0554, 0.0328, 0.0455, 0.0691, 0.0245, 0.0255, 0.0755, 0.0582, 0.0567,\n",
      "         0.0567, 0.0690]], grad_fn=<SoftmaxBackward0>)\n",
      "a0 -> vhat: False, d: False, g: False, F: False\n",
      "d:  tensor([[0.0636, 0.1202, 0.0432, 0.0411, 0.0133, 0.0342, 0.0440, 0.0404, 0.0979,\n",
      "         0.0193, 0.1185, 0.0346, 0.0263, 0.0747, 0.0273, 0.0574, 0.0390, 0.0491,\n",
      "         0.0305, 0.0254],\n",
      "        [0.0649, 0.0845, 0.0558, 0.0903, 0.0539, 0.0361, 0.0480, 0.0452, 0.0246,\n",
      "         0.0407, 0.0541, 0.0376, 0.0456, 0.0423, 0.0754, 0.0234, 0.0417, 0.0392,\n",
      "         0.0553, 0.0416]], grad_fn=<SoftmaxBackward0>)\n",
      "a1 -> vhat: False, d: False, g: False, F: False\n",
      "d:  tensor([[0.0570, 0.0196, 0.0403, 0.0486, 0.0274, 0.0399, 0.0572, 0.0378, 0.0606,\n",
      "         0.0387, 0.0618, 0.0540, 0.0549, 0.0737, 0.0556, 0.0823, 0.0660, 0.0207,\n",
      "         0.0547, 0.0491],\n",
      "        [0.0560, 0.0584, 0.0464, 0.0514, 0.0379, 0.0379, 0.0448, 0.0517, 0.0363,\n",
      "         0.0385, 0.0425, 0.0549, 0.1462, 0.0310, 0.0138, 0.0613, 0.0582, 0.0335,\n",
      "         0.0728, 0.0264]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import log_softmax, softmax\n",
    "\n",
    "class CombinedAutoencoder(nn.Module):\n",
    "    def __init__(self, D_w, D_h, K, dropout_prob=0.3):\n",
    "        super(CombinedAutoencoder, self).__init__()\n",
    "        \n",
    "        self.D_h = D_h\n",
    "        self.K = K\n",
    "        \n",
    "        # Shared feed-forward layer for all views\n",
    "        self.feed_forward_shared = nn.Linear(2 * D_w, D_h)\n",
    "        \n",
    "        # Unique feed-forward layers for each view\n",
    "        self.feed_forward_unique = nn.ModuleDict({\n",
    "            'a0': nn.Linear(D_h, K),\n",
    "            'p': nn.Linear(D_h, K),\n",
    "            'a1': nn.Linear(D_h, K),\n",
    "        })\n",
    "\n",
    "        # Initializing F matrices for each view\n",
    "        self.F_matrices = nn.ParameterDict({\n",
    "            'a0': nn.Parameter(torch.Tensor(K, D_w)),\n",
    "            'p': nn.Parameter(torch.Tensor(K, D_w)),\n",
    "            'a1': nn.Parameter(torch.Tensor(K, D_w)),\n",
    "        })\n",
    "\n",
    "        # init F matrices with xavier_uniform and nn.init.calculate_gain('relu')\n",
    "        for _, value in self.F_matrices.items():\n",
    "            nn.init.xavier_uniform_(value.data, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "        # Additional layers and parameters\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "        self.batch_norm = nn.BatchNorm1d(D_h)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.activation2 = nn.Sigmoid()\n",
    "\n",
    "    def sample_gumbel(self, shape, eps=1e-20, device='cpu'):\n",
    "        \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "        U = torch.rand(shape, device=device)\n",
    "        return -torch.log(-torch.log(U + eps) + eps)\n",
    "\n",
    "\n",
    "    def gumbel_softmax_sample(self, logits, t):\n",
    "        \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "        y = logits + self.sample_gumbel(logits.size(), device=logits.device)\n",
    "        return softmax(y / t, dim=-1)\n",
    "\n",
    "\n",
    "    def gumbel_logsoftmax_sample(self, logits, t):\n",
    "        \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "        y = logits + self.sample_gumbel(logits.size(), device=logits.device)\n",
    "        return log_softmax(y / t, dim=-1)\n",
    "\n",
    "\n",
    "    def custom_gumbel_softmax(self, logits, tau, hard=False, log=False):\n",
    "        \"\"\"Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
    "        Args:\n",
    "        logits: [batch_size, n_class] unnormalized log-probs\n",
    "        tau: non-negative scalar\n",
    "        hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
    "        Returns:\n",
    "        [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
    "        If hard=True, then the returned sample will be one-hot, otherwise it will\n",
    "        be a probabilitiy distribution that sums to 1 across classes\n",
    "        \"\"\"\n",
    "        if log:\n",
    "            y = self.gumbel_logsoftmax_sample(logits, tau)\n",
    "        else:\n",
    "            y = self.gumbel_softmax_sample(logits, tau)\n",
    "        if hard:\n",
    "            shape = y.size()\n",
    "            _, ind = y.max(dim=-1)\n",
    "            y_hard = torch.zeros_like(y).view(-1, shape[-1])\n",
    "            y_hard.scatter_(1, ind.view(-1, 1), 1)\n",
    "            y_hard = y_hard.view(*shape)\n",
    "            # Set gradients w.r.t. y_hard gradients w.r.t. y\n",
    "            y_hard = (y_hard - y).detach() + y\n",
    "            return y_hard\n",
    "        return y\n",
    "\n",
    "    def forward(self, v_p, v_a0, v_a1, v_sentence, tau):\n",
    "        h_p = self.process_through_shared(v_p, v_sentence)\n",
    "        h_a0 = self.process_through_shared(v_a0, v_sentence)\n",
    "        h_a1 = self.process_through_shared(v_a1, v_sentence)\n",
    "\n",
    "        logits_p = self.feed_forward_unique['p'](h_p)\n",
    "        logits_a0 = self.feed_forward_unique['a0'](h_a0)\n",
    "        logits_a1 = self.feed_forward_unique['a1'](h_a1) \n",
    "\n",
    "        d_p = torch.softmax(logits_p, dim=1)\n",
    "        d_a0 = torch.softmax(logits_a0, dim=1)\n",
    "        d_a1 = torch.softmax(logits_a1, dim=1)\n",
    "\n",
    "        # TODO - Paper said we pass the output of softmax into the Gumbel-Softmax but code passes the logits\n",
    "\n",
    "        #g_p = self.custom_gumbel_softmax(d_p, tau=tau, hard=False, log=True)\n",
    "        #g_a0 = self.custom_gumbel_softmax(d_a0, tau=tau, hard=False, log=True)\n",
    "        #g_a1 = self.custom_gumbel_softmax(d_a1, tau=tau, hard=False, log=True)\n",
    "\n",
    "        g_p = self.custom_gumbel_softmax(logits_p, tau=tau, hard=False, log=False)\n",
    "        g_a0 = self.custom_gumbel_softmax(logits_a0, tau=tau, hard=False, log=False)\n",
    "        g_a1 = self.custom_gumbel_softmax(logits_a1, tau=tau, hard=False, log=False)\n",
    "\n",
    "        vhat_p = torch.matmul(g_p, self.F_matrices['p'])\n",
    "        vhat_a0 = torch.matmul(g_a0, self.F_matrices['a0'])\n",
    "        vhat_a1 = torch.matmul(g_a1, self.F_matrices['a1'])\n",
    "\n",
    "        return {\n",
    "            \"p\": {\"vhat\": vhat_p, \"d\": d_p, \"g\": g_p, \"F\": self.F_matrices['p']},\n",
    "            \"a0\": {\"vhat\": vhat_a0, \"d\": d_a0, \"g\": g_a0, \"F\": self.F_matrices['a0']},\n",
    "            \"a1\": {\"vhat\": vhat_a1, \"d\": d_a1, \"g\": g_a1, \"F\": self.F_matrices['a1']}\n",
    "        }\n",
    "        \n",
    "    def process_through_shared(self, v_z, v_sentence):\n",
    "        # Concatenating v_z with the sentence embedding\n",
    "        concatenated = torch.cat((v_z, v_sentence), dim=-1)\n",
    "        \n",
    "        # Applying dropout\n",
    "        dropped = self.dropout1(concatenated)\n",
    "\n",
    "        # Passing through the shared linear layer\n",
    "        h_shared = self.feed_forward_shared(dropped)\n",
    "\n",
    "        # Applying batch normalization and ReLU activation\n",
    "        h_shared = self.batch_norm(h_shared)\n",
    "        h_shared = self.activation(h_shared)\n",
    "\n",
    "        # Applying dropout again\n",
    "        h_shared = self.dropout2(h_shared)\n",
    "\n",
    "        return h_shared\n",
    "\n",
    "# Mock Data Preparation\n",
    "D_h = 768\n",
    "batch_size = 2\n",
    "embedding_dim = 768\n",
    "K = 20\n",
    "tau = 0.9\n",
    "\n",
    "# Generating mock embeddings for article, predicate, ARG0, ARG1, and their corresponding sentence embeddings\n",
    "article_embedding = torch.randn(batch_size, embedding_dim)\n",
    "v_p = torch.randn(batch_size, embedding_dim)\n",
    "v_a0 = torch.randn(batch_size, embedding_dim)\n",
    "v_a1 = torch.randn(batch_size, embedding_dim)\n",
    "\n",
    "# Testing CombinedAutoencoder\n",
    "autoencoder = CombinedAutoencoder(embedding_dim, D_h, K)\n",
    "outputs = autoencoder(v_p, v_a0, v_a1, article_embedding, tau)\n",
    "\n",
    "# Check shapes of the outputs\n",
    "print(\"Output shapes:\")\n",
    "for key, value in outputs.items():\n",
    "    print(f\"{key} -> vhat: {value['vhat'].shape}, d: {value['d'].shape}, g: {value['g'].shape}, F: {value['F'].shape}\")\n",
    "\n",
    "# check if tensor have nan values\n",
    "def check_nan(tensor):\n",
    "    # if tensor has any nan values, return True\n",
    "    if torch.isnan(tensor).any():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Check if any of the outputs have NaN values\n",
    "print(\"NaN values:\")\n",
    "for key, value in outputs.items():\n",
    "    print(f\"{key} -> vhat: {check_nan(value['vhat'])}, d: {check_nan(value['d'])}, g: {check_nan(value['g'])}, F: {check_nan(value['F'])}\")\n",
    "    print(f\"d: \", value['d'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FRISSLoss\n",
    "\n",
    "The layer calculates the unsupervised loss for predicate, arg0 and arg1. \n",
    "\n",
    "The forward function takes as input 3 dicts with the parameters `v`, `v_hat`, `g` and `F`. Where `v` is the embedding of the predicate, arg0 or arg1. The `v_hat` (size: [batch_size, embedding_dim]) is the reconstructed embedding for the predicate, arg0 and arg1. The `g` is the gumbel softmax result (size: [batch_size, embedding_dim]). The `F` (size: [K, embedding_dim]) which is the descriptor dictionary.\n",
    "\n",
    "The layer returns the loss for each batch. So the output is [batch_size]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRiSSLoss output: tensor([780048.0000, 780046.9375])\n"
     ]
    }
   ],
   "source": [
    "class FRISSLoss(nn.Module):\n",
    "    def __init__(self, lambda_orthogonality, M, t):\n",
    "        super(FRISSLoss, self).__init__()\n",
    "        \n",
    "        self.lambda_orthogonality = lambda_orthogonality\n",
    "        self.M = M\n",
    "        self.t = t\n",
    "        self.triplet_loss = nn.TripletMarginLoss(margin=M)\n",
    "\n",
    "    def contrastive_loss(self, v, vhat, negatives):\n",
    "        batch_size = vhat.size(0)\n",
    "        N = negatives.size(0)\n",
    "        loss = torch.zeros(batch_size, device=v.device)\n",
    "\n",
    "        # Calculate true distance between reconstructed and real embeddings\n",
    "        true_distance = self.l2(vhat, v)\n",
    "\n",
    "        for i in range(N):  # loop over each element in \"negatives\"\n",
    "            \n",
    "            # Tranform negative from [embedding dim] to [batch size, embedding_dim] \n",
    "            negative = negatives[i, :].expand(v.size(0), -1)\n",
    "\n",
    "            # Calculate negative distance for current negative embedding\n",
    "            negative_distance = self.l2(vhat, negative)\n",
    "\n",
    "            # Compute loss based on the provided logic: l2(vhat, v) + 1 + l2(vhat, negative) and clamp to 0 if below 0\n",
    "            current_loss = 1 + true_distance - negative_distance\n",
    "            loss += torch.clamp(current_loss, min=0.0)\n",
    "\n",
    "        # Normalize the total loss by N\n",
    "        return loss / N\n",
    "\n",
    "    \n",
    "    def l2(self, u, v):\n",
    "        return torch.sqrt(torch.sum((u - v) ** 2, dim=1))\n",
    "    \n",
    "    def focal_triplet_loss_WRONG(self, v, vhat_z, g, F):\n",
    "        losses = []\n",
    "        for i in range(F.size(0)):  # Iterate over each negative example\n",
    "            # For each negative, compute the loss against the anchor and positive\n",
    "            loss = self.triplet_loss(vhat_z, v, F[i].unsqueeze(0).expand(v.size(0), -1))\n",
    "            losses.append(loss)\n",
    "\n",
    "        loss_tensor = torch.stack(losses) \n",
    "        loss = loss_tensor.mean(dim=0).mean()\n",
    "        return loss\n",
    "    \n",
    "    def focal_triplet_loss(self, v, vhat_z, g, F):\n",
    "        _, indices = torch.topk(g, self.t, largest=False, dim=1)\n",
    "\n",
    "        F_t = torch.stack([F[indices[i]] for i in range(g.size(0))])\n",
    "\n",
    "        g_tz = torch.stack([g[i, indices[i]] for i in range(g.size(0))])\n",
    "                    \n",
    "        g_t = g_tz / g_tz.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        # if division by zero set all nan values to 0\n",
    "        g_t[torch.isnan(g_t)] = 0\n",
    "        \n",
    "        m_t = self.M * ((1 - g_t)**2)\n",
    "\n",
    "        # Initializing loss\n",
    "        loss = torch.zeros_like(v[:, 0])\n",
    "        \n",
    "        # Iteratively adding to the loss for each negative embedding\n",
    "        for i in range(self.t):\n",
    "            current_v_t = F_t[:, i]\n",
    "            current_m_t = m_t[:, i]\n",
    "            \n",
    "            current_loss = current_m_t + self.l2(vhat_z, v) - self.l2(vhat_z, current_v_t)\n",
    "            \n",
    "            loss += torch.max(torch.zeros_like(current_loss), current_loss)\n",
    "             \n",
    "        # Normalizing\n",
    "        loss = loss / self.t\n",
    "        return loss\n",
    "\n",
    "    def orthogonality_term(self, F, reg=1e-4):\n",
    "        gram_matrix = torch.mm(F, F.T)  # Compute the Gram matrix F * F^T\n",
    "        identity_matrix = torch.eye(gram_matrix.size(0), device=gram_matrix.device)  # Create an identity matrix\n",
    "        ortho_loss = (gram_matrix - identity_matrix).abs().sum()\n",
    "        return ortho_loss\n",
    "\n",
    "\n",
    "    def forward(self, p, a0, a1, p_negatives, a0_negatives, a1_negatives):\n",
    "        # Extract components from dictionary for predicate p\n",
    "        v_p, vhat_p, d_p, g_p, F_p = p[\"v\"], p[\"vhat\"], p[\"d\"], p[\"g\"], p[\"F\"]\n",
    "        \n",
    "        # Extract components from dictionary for ARG0\n",
    "        v_a0, vhat_a0, d_a0, g_a0, F_a0 = a0[\"v\"], a0[\"vhat\"], a0[\"d\"], a0[\"g\"], a0[\"F\"]\n",
    "\n",
    "        # Extract components from dictionary for ARG1\n",
    "        v_a1, vhat_a1, d_a1, g_a1, F_a1 = a1[\"v\"], a1[\"vhat\"], a1[\"d\"], a1[\"g\"], a1[\"F\"]\n",
    "        \n",
    "         # Calculate losses for predicate\n",
    "        Ju_p = self.contrastive_loss(v_p, vhat_p, p_negatives)        \n",
    "        Jt_p = self.focal_triplet_loss(v_p, vhat_p, g_p, F_p)        \n",
    "        Jz_p = Ju_p + Jt_p + self.lambda_orthogonality * self.orthogonality_term(F_p) ** 2\n",
    "        \n",
    "        # Calculate losses for ARG0\n",
    "        Ju_a0 = self.contrastive_loss(v_a0, vhat_a0, a0_negatives)\n",
    "        Jt_a0 = self.focal_triplet_loss(v_a0, vhat_a0, g_a0, F_a0)\n",
    "        Jz_a0 = Ju_a0 + Jt_a0 + self.lambda_orthogonality * self.orthogonality_term(F_a0) ** 2\n",
    "        \n",
    "        # Calculate losses for ARG1\n",
    "        Ju_a1 = self.contrastive_loss(v_a1, vhat_a1, a1_negatives)\n",
    "        Jt_a1 = self.focal_triplet_loss(v_a1, vhat_a1, g_a1, F_a1)\n",
    "        Jz_a1 = Ju_a1 + Jt_a1 + self.lambda_orthogonality * self.orthogonality_term(F_a1) ** 2\n",
    "        \n",
    "        if torch.isnan(Jz_p).any():\n",
    "            print(\"Jz_p has nan\")\n",
    "            \n",
    "        if torch.isnan(Jz_a0).any():\n",
    "            print(\"Jz_a0 has nan\")\n",
    "            \n",
    "        if torch.isnan(Jz_a1).any():\n",
    "            print(\"Jz_a1 has nan\")\n",
    "        \n",
    "        # Aggregate the losses\n",
    "        loss = Jz_p + Jz_a0 + Jz_a1\n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "# Mock Data Preparation\n",
    "batch_size = 2\n",
    "embedding_dim = 768\n",
    "K = 15  # Number of frames/descriptors\n",
    "\n",
    "# Generating mock embeddings for article, predicate, ARG0, ARG1 and their reconstructions\n",
    "article_embedding = torch.randn(batch_size, embedding_dim)\n",
    "v_p = torch.randn(batch_size, embedding_dim)\n",
    "vhat_p = torch.randn(batch_size, embedding_dim)\n",
    "\n",
    "v_a0 = torch.randn(batch_size, embedding_dim)\n",
    "vhat_a0 = torch.randn(batch_size, embedding_dim)\n",
    "\n",
    "v_a1 = torch.randn(batch_size, embedding_dim)\n",
    "vhat_a1 = torch.randn(batch_size, embedding_dim)\n",
    "\n",
    "# Generating mock descriptor weights and descriptor matrices for predicate, ARG0, ARG1\n",
    "d_p = torch.randn(batch_size, K)\n",
    "d_a0 = torch.randn(batch_size, K)\n",
    "d_a1 = torch.randn(batch_size, K)\n",
    "\n",
    "F_p = torch.randn(K, embedding_dim)\n",
    "F_a0 = torch.randn(K, embedding_dim)\n",
    "F_a1 = torch.randn(K, embedding_dim)\n",
    "\n",
    "g_p = torch.randn(batch_size, K)\n",
    "g_a0 = torch.randn(batch_size, K)\n",
    "g_a1 = torch.randn(batch_size, K)\n",
    "\n",
    "# Generating some negative samples (let's assume 5 negative samples per batch entry)\n",
    "num_negatives = 8\n",
    "negatives_p = torch.randn(num_negatives, embedding_dim)\n",
    "negatives_a0 = torch.randn(num_negatives, embedding_dim)\n",
    "negatives_a1 = torch.randn(num_negatives, embedding_dim)\n",
    "\n",
    "# Initialize loss function\n",
    "lambda_orthogonality = 1e-3\n",
    "\n",
    "t = 8  # Number of descriptors with smallest weights for negative samples\n",
    "M = t\n",
    "\n",
    "loss_fn = FRISSLoss(lambda_orthogonality, M, t)\n",
    "\n",
    "# Organizing inputs into dictionaries\n",
    "p = {\"v\": v_p, \"vhat\": vhat_p, \"d\": d_p, \"g\": g_p, \"F\": F_p}\n",
    "a0 = {\"v\": v_a0, \"vhat\": vhat_a0, \"d\": d_a0, \"g\": g_a0, \"F\": F_a0}\n",
    "a1 = {\"v\": v_a1, \"vhat\": vhat_a1, \"d\": d_a1, \"g\": g_a1, \"F\": F_a1}\n",
    "\n",
    "loss_fn = FRISSLoss(lambda_orthogonality, M, t)\n",
    "loss = loss_fn(p, a0, a1, negatives_p, negatives_a0, negatives_a1)\n",
    "print(\"FRiSSLoss output:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. FRISSUnsupervised\n",
    "\n",
    "The `FRISSUnsupervised` layer integrates multiple autoencoders and the previously described `FRISSLoss` layer to achieve an unsupervised learning process over the predicates and their arguments.\n",
    "\n",
    "### Forward Method:\n",
    "\n",
    "**Inputs**:\n",
    "1. **v_p**: Embedding of the predicate with size: [batch_size, D_w].\n",
    "2. **v_a0**: Embedding of the ARG0 (first argument) with size: [batch_size, D_w].\n",
    "3. **v_a1**: Embedding of the ARG1 (second argument) with size: [batch_size, D_w].\n",
    "4. **v_article**: Embedding of the article with size: [batch_size, D_w].\n",
    "5. **negatives**: Tensor containing negative samples with size: [batch_size, num_negatives, D_w].\n",
    "6. **tau**: A scalar parameter for the Gumbel softmax in the autoencoder.\n",
    "\n",
    "**Outputs**:\n",
    "- A dictionary `results` containing:\n",
    "    - **loss**: A tensor representing the combined unsupervised loss over the batch with size: [batch_size].\n",
    "    - **p**: Dictionary containing components for the predicate, including reconstructed embedding (`vhat`), descriptor weights (`d`), Gumbel softmax result (`g`), and the descriptor matrix (`F`).\n",
    "    - **a0**: Same as `p` but for ARG0.\n",
    "    - **a1**: Same as `p` but for ARG1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results' Shapes:\n",
      "loss: tensor([3121.1079, 3116.3066], grad_fn=<AddBackward0>)\n",
      "p -> vhat: torch.Size([2, 768]), d: torch.Size([2, 20]), g: torch.Size([2, 20]), F: torch.Size([20, 768])\n",
      "a0 -> vhat: torch.Size([2, 768]), d: torch.Size([2, 20]), g: torch.Size([2, 20]), F: torch.Size([20, 768])\n",
      "a1 -> vhat: torch.Size([2, 768]), d: torch.Size([2, 20]), g: torch.Size([2, 20]), F: torch.Size([20, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming you have already defined CombinedAutoencoder and its methods as provided earlier.\n",
    "\n",
    "class FRISSUnsupervised(nn.Module):\n",
    "    def __init__(self, D_w, D_h, K, num_frames, lambda_orthogonality, M, t, dropout_prob=0.3):\n",
    "        super(FRISSUnsupervised, self).__init__()\n",
    "        \n",
    "        self.loss_fn = FRISSLoss(lambda_orthogonality, M, t)      \n",
    "        \n",
    "        # Using the CombinedAutoencoder instead of individual Autoencoders\n",
    "        self.combined_autoencoder = CombinedAutoencoder(D_w, D_h, K, dropout_prob=dropout_prob)\n",
    "\n",
    "    def forward(self, v_p, v_a0, v_a1, v_sentence, p_negatives, a0_negatives, a1_negatives, tau):\n",
    "        outputs = self.combined_autoencoder(v_p, v_a0, v_a1, v_sentence, tau)\n",
    "\n",
    "        outputs_p = outputs[\"p\"]\n",
    "        outputs_p[\"v\"] = v_p\n",
    "        \n",
    "        outputs_a0 = outputs[\"a0\"]\n",
    "        outputs_a0[\"v\"] = v_a0\n",
    "        \n",
    "        outputs_a1 = outputs[\"a1\"]\n",
    "        outputs_a1[\"v\"] = v_a1\n",
    "        \n",
    "        loss = self.loss_fn(\n",
    "            outputs_p,\n",
    "            outputs_a0, \n",
    "            outputs_a1, \n",
    "            p_negatives, a0_negatives, a1_negatives\n",
    "        )\n",
    "\n",
    "        results = {\n",
    "            \"loss\": loss,\n",
    "            \"p\": outputs[\"p\"],\n",
    "            \"a0\": outputs[\"a0\"],\n",
    "            \"a1\": outputs[\"a1\"]\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Mock Data Preparation\n",
    "D_h = 768\n",
    "batch_size = 2\n",
    "embedding_dim = 768\n",
    "K = 20\n",
    "num_frames = 15\n",
    "tau = 0.9\n",
    "lambda_orthogonality = 0.1  # Placeholder value, please replace with your actual value\n",
    "M = 7  # Placeholder value, please replace with your actual value\n",
    "t = 7  # Placeholder value, please replace with your actual value\n",
    "\n",
    "# Generating mock embeddings for article, predicate, ARG0, ARG1, and their corresponding sentence embeddings\n",
    "article_embedding = torch.randn(batch_size, embedding_dim)\n",
    "v_p = torch.randn(batch_size, embedding_dim)\n",
    "v_a0 = torch.randn(batch_size, embedding_dim)\n",
    "v_a1 = torch.randn(batch_size, embedding_dim)\n",
    "\n",
    "# Generating some negative samples (let's assume 5 negative samples per batch entry)\n",
    "num_negatives = 10\n",
    "negatives_p = torch.randn(num_negatives, embedding_dim)\n",
    "negatives_a0 = torch.randn(num_negatives, embedding_dim)\n",
    "negatives_a1 = torch.randn(num_negatives, embedding_dim)\n",
    "\n",
    "# Testing FRISSUnsupervised\n",
    "unsupervised_module = FRISSUnsupervised(embedding_dim, D_h, K, num_frames, lambda_orthogonality, M, t)\n",
    "results = unsupervised_module(v_p, v_a0, v_a1, article_embedding, negatives_p, negatives_a0, negatives_a1, tau)\n",
    "\n",
    "# Print the results' shapes for verification\n",
    "print(\"Results' Shapes:\")\n",
    "for key, value in results.items():\n",
    "    if key == \"loss\":\n",
    "        print(f\"{key}: {value}\")\n",
    "    else:\n",
    "        print(f\"{key} -> vhat: {value['vhat'].shape}, d: {value['d'].shape}, g: {value['g'].shape}, F: {value['F'].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. FRISSSupervised\n",
    "\n",
    "The layer takes the embeddings from the args and the sentence and predicts frames. \n",
    "\n",
    "The embeddings for the args are averaged for each arg individually and then averaged on args level. The final embedding is feed into a linear layer and passed through a sigmoid function. \n",
    "\n",
    "The sentence embedding is feed into a linear layer and then into a relu function. After again in a linear function and then averaged. The average embeddung is again feed into a linear layer and lastly in a signoid function. \n",
    "\n",
    "It returns a span and sentence based prediction of shape [batch_size, num_frames]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 15]), torch.Size([2, 15]), torch.Size([2, 15]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FRISSSupervised(nn.Module):\n",
    "    def __init__(self, D_w, K, num_frames, dropout_prob=0.3):\n",
    "        super(FRISSSupervised, self).__init__()\n",
    "\n",
    "        self.D_w = D_w\n",
    "                \n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.feed_forward_sentence1 = nn.Linear(D_w, D_w)\n",
    "        self.feed_forward_sentence2 = nn.Linear(D_w, num_frames)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Adding two dropout layers\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "    def forward(self, d_p, d_a0, d_a1, vs):\n",
    "        # Span-based Classification   \n",
    "\n",
    "        # Aggregate the SRL descriptors to have one descriptor per sentence\n",
    "        d_p = d_p.mean(dim=2)\n",
    "        d_a0 = d_a0.mean(dim=2)\n",
    "        d_a1 = d_a1.mean(dim=2)\n",
    "\n",
    "        # Take the mean over descriptors\n",
    "        w_u = (d_p + d_a0 + d_a1) / 3\n",
    "\n",
    "        w_u = w_u.sum(dim=1)\n",
    "\n",
    "        # Sentence-based Classification\n",
    "\n",
    "        # Apply the first dropout to vs\n",
    "        vs = self.dropout1(vs)\n",
    "\n",
    "        ws = self.relu(self.feed_forward_sentence1(vs))\n",
    "\n",
    "        # Mean over sentences and apply the second dropout\n",
    "        ws = self.dropout2(ws.mean(dim=1))\n",
    "\n",
    "        # Pass through the second feed forward network\n",
    "        ws = self.feed_forward_sentence2(ws)\n",
    "\n",
    "        # The softmax layer is commented out as it is not used with CrossEntropyLoss\n",
    "        # ys_hat = self.softmax(ws)\n",
    "\n",
    "        # combined pred = sum of span-based and sentence-based predictions\n",
    "        combined = w_u + ws\n",
    "\n",
    "        return w_u, ws, combined\n",
    "\n",
    "\n",
    "# Mock Data Preparation\n",
    "\n",
    "batch_size = 2\n",
    "embedding_dim = 768\n",
    "num_frames = 15  # Assuming the number of frames is equal to K for simplicity\n",
    "num_sentences = 32\n",
    "K = 15\n",
    "num_args = 9\n",
    "\n",
    "# Generating mock dsz representations for predicate, ARG0, ARG1\n",
    "d_p = torch.randn(batch_size, num_sentences, num_args, K)\n",
    "d_a0 = torch.randn(batch_size, num_sentences, num_args, K)\n",
    "d_a1 = torch.randn(batch_size, num_sentences, num_args, K) \n",
    "\n",
    "# Adjusting the num_heads parameter\n",
    "srl_heads = 4\n",
    "sentence_heads = 8\n",
    "\n",
    "# Adjust the mock sentence embeddings shape\n",
    "vs = torch.randn(batch_size, num_sentences, embedding_dim)\n",
    "\n",
    "# Initialize and test the supervised module\n",
    "supervised_module = FRISSSupervised(embedding_dim, K, num_frames)\n",
    "\n",
    "# Forward pass the mock data\n",
    "yu_hat, ys_hat, combined_pred = supervised_module(d_p, d_a0, d_a1, vs)\n",
    "yu_hat.shape, ys_hat.shape, combined_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. FRISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(9.1418, grad_fn=<DivBackward0>),\n",
       " torch.Size([2, 14]),\n",
       " torch.Size([2, 14]),\n",
       " torch.Size([2, 14]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FRISS(nn.Module):\n",
    "    def __init__(self, embedding_dim, D_h, lambda_orthogonality, M, t, num_sentences, K, num_frames, dropout_prob=0.3, bert_model_name=\"bert-base-uncased\"):\n",
    "        super(FRISS, self).__init__()\n",
    "        \n",
    "        # Aggregation layer replaced with SRL_Embeddings\n",
    "        self.aggregation = SRL_Embeddings(bert_model_name)\n",
    "        \n",
    "        # Unsupervised training module\n",
    "        self.unsupervised = FRISSUnsupervised(embedding_dim, D_h, K, num_frames, lambda_orthogonality, M, t, dropout_prob=dropout_prob)\n",
    "        \n",
    "        # Supervised training module\n",
    "        self.supervised = FRISSSupervised(embedding_dim, K, num_frames, dropout_prob=dropout_prob)\n",
    "        \n",
    "    def negative_sampling(self, embeddings, num_negatives=8):\n",
    "        batch_size, num_sentences, num_args, embedding_dim = embeddings.size()\n",
    "        all_negatives = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            for j in range(num_sentences):\n",
    "                # Flatten the arguments dimension to sample across all arguments in the sentence\n",
    "                flattened_embeddings = embeddings[i, j].view(-1, embedding_dim)\n",
    "                \n",
    "                # Get indices of non-padded embeddings (assuming padding is represented by all-zero vectors)\n",
    "                non_padded_indices = torch.where(torch.any(flattened_embeddings != 0, dim=1))[0]\n",
    "\n",
    "                # Randomly sample negative indices from non-padded embeddings\n",
    "                if len(non_padded_indices) > 0:\n",
    "                    negative_indices = non_padded_indices[torch.randint(0, len(non_padded_indices), (num_negatives,))]\n",
    "                else:\n",
    "                    # If no non-padded embeddings, use zeros\n",
    "                    negative_indices = torch.zeros(num_negatives, dtype=torch.long)\n",
    "\n",
    "                negative_samples = flattened_embeddings[negative_indices, :]\n",
    "                all_negatives.append(negative_samples)\n",
    "\n",
    "        # Concatenate all negative samples into a single tensor\n",
    "        all_negatives = torch.cat(all_negatives, dim=0)\n",
    "\n",
    "        # If more samples than required, randomly select 'num_negatives' samples\n",
    "        if all_negatives.size(0) > num_negatives:\n",
    "            indices = torch.randperm(all_negatives.size(0))[:num_negatives]\n",
    "            all_negatives = all_negatives[indices]\n",
    "\n",
    "        return all_negatives\n",
    "    \n",
    "    def forward(self, sentence_ids, sentence_attention_masks, predicate_ids, predicate_attention_masks, arg0_ids, arg0_attention_masks, arg1_ids, arg1_attention_masks, tau):\n",
    "        # Convert input IDs to embeddings\n",
    "        sentence_embeddings, predicate_embeddings, arg0_embeddings, arg1_embeddings = self.aggregation(sentence_ids, sentence_attention_masks, predicate_ids, predicate_attention_masks, arg0_ids, arg0_attention_masks, arg1_ids, arg1_attention_masks)\n",
    "        \n",
    "        # Handle multiple spans by averaging predictions\n",
    "        unsupervised_losses = torch.zeros((sentence_embeddings.size(0),), device=sentence_embeddings.device)\n",
    "        \n",
    "        # Creating storage for aggregated d tensors\n",
    "        d_p_list, d_a0_list, d_a1_list = [], [], []\n",
    "        \n",
    "        negatives_p = self.negative_sampling(predicate_embeddings)\n",
    "        negatives_a0 = self.negative_sampling(arg0_embeddings)\n",
    "        negatives_a1 = self.negative_sampling(arg1_embeddings)\n",
    "\n",
    "        # Process each sentence \n",
    "        for sentence_idx in range(sentence_embeddings.size(1)):\n",
    "            s_sentence_span = sentence_embeddings[:, sentence_idx, :]\n",
    "\n",
    "            d_p_sentence_list = []\n",
    "            d_a0_sentence_list = []\n",
    "            d_a1_sentence_list = []\n",
    "\n",
    "            # Process each span\n",
    "            for span_idx in range(predicate_embeddings.size(2)):                \n",
    "                v_p_span = predicate_embeddings[:, sentence_idx, span_idx, :]\n",
    "                v_a0_span = arg0_embeddings[:, sentence_idx, span_idx, :]\n",
    "                v_a1_span = arg1_embeddings[:, sentence_idx, span_idx, :]\n",
    "\n",
    "                # Feed the embeddings to the unsupervised module\n",
    "                unsupervised_results = self.unsupervised(v_p_span, v_a0_span, v_a1_span, s_sentence_span, negatives_p, negatives_a0, negatives_a1, tau)                \n",
    "                unsupervised_losses += unsupervised_results[\"loss\"]\n",
    "                \n",
    "                if torch.isnan(unsupervised_results[\"loss\"]).any():\n",
    "                    print(\"loss is nan\")\n",
    "                \n",
    "                # Use the vhat (reconstructed embeddings) for supervised predictions\n",
    "                d_p_sentence_list.append(unsupervised_results['p']['d'])\n",
    "                d_a0_sentence_list.append(unsupervised_results['a0']['d'])\n",
    "                d_a1_sentence_list.append(unsupervised_results['a1']['d'])        \n",
    "\n",
    "\n",
    "            # Aggregating across all spans\n",
    "            d_p_sentence = torch.stack(d_p_sentence_list, dim=1)\n",
    "            d_a0_sentence = torch.stack(d_a0_sentence_list, dim=1)\n",
    "            d_a1_sentence = torch.stack(d_a1_sentence_list, dim=1)\n",
    "\n",
    "            d_p_list.append(d_p_sentence)\n",
    "            d_a0_list.append(d_a0_sentence)\n",
    "            d_a1_list.append(d_a1_sentence)\n",
    "\n",
    "        # Aggregating across all spans\n",
    "        d_p_aggregated = torch.stack(d_p_list, dim=1)\n",
    "        d_a0_aggregated = torch.stack(d_a0_list, dim=1)\n",
    "        d_a1_aggregated = torch.stack(d_a1_list, dim=1)\n",
    "        \n",
    "        # Supervised predictions\n",
    "        span_pred, sentence_pred, combined_pred = self.supervised(d_p_aggregated, d_a0_aggregated, d_a1_aggregated, sentence_embeddings)\n",
    "    \n",
    "        # Identify valid (non-nan) losses\n",
    "        valid_losses = ~torch.isnan(unsupervised_losses)\n",
    "\n",
    "        # Take average by summing the valid losses and dividing by num sentences so that padded sentences are also taken in equation\n",
    "        unsupervised_loss = unsupervised_losses[valid_losses].sum() / (sentence_embeddings.shape[1] * sentence_embeddings.shape[2])\n",
    "        \n",
    "        return unsupervised_loss, span_pred, sentence_pred, combined_pred\n",
    "\n",
    "\n",
    "# Set the necessary parameters\n",
    "batch_size = 2\n",
    "embedding_dim = 768\n",
    "K = 14  # Number of frames/descriptors\n",
    "num_frames = 14  # Assuming the number of frames is equal to K for simplicity\n",
    "D_h = 512  # Dimension of the hidden representation\n",
    "lambda_orthogonality = 0.1\n",
    "M = 8\n",
    "t = 8\n",
    "tau = 1.0\n",
    "\n",
    "# Define some mock token IDs data parameters\n",
    "max_sentences_per_article = 8\n",
    "max_sentence_length = 10\n",
    "num_sentences = max_sentences_per_article\n",
    "max_args_per_sentence = 3\n",
    "\n",
    "# Generating mock token IDs for predicate, ARG0, ARG1, and their corresponding sentences\n",
    "# We assume a vocab size of 30522 (standard BERT vocab size) for simplicity.\n",
    "vocab_size = 30522\n",
    "\n",
    "sentence_ids = torch.randint(0, vocab_size, (batch_size, max_sentences_per_article, max_sentence_length))\n",
    "predicate_ids = torch.randint(0, vocab_size, (batch_size, max_sentences_per_article, max_args_per_sentence, max_sentence_length))\n",
    "arg0_ids = torch.randint(0, vocab_size, (batch_size, max_sentences_per_article, max_args_per_sentence, max_sentence_length))\n",
    "arg1_ids = torch.randint(0, vocab_size, (batch_size, max_sentences_per_article, max_args_per_sentence, max_sentence_length))\n",
    "\n",
    "sentence_embeddings = torch.randn(batch_size, max_sentences_per_article, embedding_dim)\n",
    "predicate_embeddings = torch.randn(batch_size, max_sentences_per_article, max_args_per_sentence, embedding_dim)\n",
    "arg0_embeddings = torch.randn(batch_size, max_sentences_per_article, max_args_per_sentence, embedding_dim)\n",
    "arg1_embeddings = torch.randn(batch_size, max_sentences_per_article, max_args_per_sentence, embedding_dim)\n",
    "\n",
    "# Mock attention masks\n",
    "sentence_attention_masks = torch.randint(0, 2, (batch_size, max_sentences_per_article, max_sentence_length))\n",
    "predicate_attention_masks = torch.randint(0, 2, (batch_size, max_sentences_per_article, max_args_per_sentence, max_sentence_length))\n",
    "arg0_attention_masks = torch.randint(0, 2, (batch_size, max_sentences_per_article, max_args_per_sentence, max_sentence_length))\n",
    "arg1_attention_masks = torch.randint(0, 2, (batch_size, max_sentences_per_article, max_args_per_sentence, max_sentence_length))\n",
    "\n",
    "# Initialize the FRISS model\n",
    "friss_model = FRISS(embedding_dim, D_h, lambda_orthogonality, M, t, num_sentences, K=K, num_frames=num_frames)\n",
    "\n",
    "# Forward pass the mock data\n",
    "unsupervised_loss, span_pred, sentence_pred, combined_pred = friss_model(sentence_ids, sentence_attention_masks, predicate_ids, predicate_attention_masks, arg0_ids, arg0_attention_masks, arg1_ids, arg1_attention_masks, 1)\n",
    "unsupervised_loss, span_pred.shape, sentence_pred.shape, combined_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Testing Datasets for testing trained model\n",
      "\n",
      "Load SRL from Pickle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb97ae18609f43f18d7b3c369a37ab76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67865808 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 10000\n",
      "X_srl: 10000\n",
      "y: 10000\n",
      "CREATING DATASETS\n",
      "CREATION DONE\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "max_sentences_per_article = 24\n",
    "max_sentence_length = 32\n",
    "\n",
    "max_args_per_sentence = 10\n",
    "max_arg_length = 8\n",
    "\n",
    "sample_size = 10_000\n",
    "\n",
    "dataset, dataloader = get_testing_dataset(df_unlabeled, tokenizer, recalculate_srl=False, batch_size=batch_size, max_sentences_per_article=max_sentences_per_article, max_sentence_length=max_sentence_length, max_arg_length=max_arg_length, sample_size=sample_size, pickle_path=\"../notebooks/FRISS_SRL_unlabeled.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Testing Datasets for testing trained model\n",
      "\n",
      "Recalculate SRL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1349b55f1e4360aaa9f464ee799cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 1\n",
      "X_srl: 1\n",
      "y: 1\n",
      "CREATING DATASETS\n",
      "CREATION DONE\n"
     ]
    }
   ],
   "source": [
    "example_article = \"\"\"\n",
    "BILL ON IMMIGRANT WORKERS DIES. Legislation to allow nearly twice as many computer-savvy foreigners and other high-skilled immigrants into the country next year apparently has died in Congress. The House passed the compromise measure last month, 288-133, but Sen. Tom Harkin, D-Iowa, had blocked a vote when in the Senate. The proposal, backed by high-tech companies, would raise the limit of so- called H-1B visas granted each year to skilled workers from abroad. Only 65,000 visas are now granted each year; the bill would raise the annual cap to 115,500 for the next two years and to 107,500 in 2001. The ceiling would return to 65,000 in 2002.\n",
    "\"\"\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# get dataset from string\n",
    "example_dataset, example_dataloader = get_dataset_from_string(example_article, tokenizer, max_sentences_per_article=32, max_sentence_length=32,  max_args_per_sentence=10, max_arg_length=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_path(path, embedding_dim, D_h, lambda_orthogonality, M, t, num_sentences, K, num_frames, dropout_prob, bert_model_name, device='cuda'):\n",
    "    \"\"\"\n",
    "    Loads the weights into an instance of the model class from the given path.\n",
    "    \n",
    "    Args:\n",
    "    - model_class (torch.nn.Module): The class of the model (uninitialized).\n",
    "    - path (str): Path to the saved weights.\n",
    "    - device (str): Device to load the model on ('cpu' or 'cuda').\n",
    "    \n",
    "    Returns:\n",
    "    - model (torch.nn.Module): Model with weights loaded.\n",
    "    \"\"\"\n",
    "\n",
    "    # Model instantiation\n",
    "    model = FRISS(embedding_dim, D_h, lambda_orthogonality, M, t, num_sentences, K, num_frames, dropout_prob=dropout_prob, bert_model_name=bert_model_name)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    \n",
    "    #model.eval()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "embedding_dim = 768\n",
    "num_frames = 15\n",
    "\n",
    "D_h = 768\n",
    "lambda_orthogonality = 1e-3\n",
    "\n",
    "K = num_frames\n",
    "t = 8\n",
    "M = 8\n",
    "tau_min = 0.5\n",
    "tau_decay = 5e-4\n",
    "\n",
    "dropout_prob = 0.3\n",
    "\n",
    "friss_model_path = \"bert-base-uncased\"\n",
    "bert_model_path = \"bert-base-uncased\"\n",
    "\n",
    "model = load_model_from_path('models/friss-new-v2/model_checkpoint_epoch_4.pth', embedding_dim, D_h, lambda_orthogonality, M, t, num_sentences, K, num_frames, dropout_prob, bert_model_path, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def inspect(model, dataloader, device='cuda'):\n",
    "    \"\"\"\n",
    "    Make predictions with the given model and dataloader.\n",
    "    \n",
    "    Args:\n",
    "    - model (torch.nn.Module): The model to make predictions with.\n",
    "    - dataloader (DataLoader): DataLoader for the dataset to predict on.\n",
    "    - device (str): Device to make predictions on ('cpu' or 'cuda').\n",
    "    \n",
    "    Returns:\n",
    "    - predicted_labels (list of lists): List containing the predicted labels for each instance.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # dim\n",
    "    batch_size = dataloader.batch_size\n",
    "    num_sentences = dataloader.dataset.max_sentences_per_article\n",
    "    max_args_per_sentence = dataloader.dataset.max_args_per_sentence   \n",
    "    K = 15\n",
    "\n",
    "    all_preds_span = []\n",
    "    \n",
    "    # Initialize usage lists for each label\n",
    "    all_used_labels_p = []\n",
    "    all_used_labels_a0 = []\n",
    "    all_used_labels_a1 = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Wrap the dataloader with tqdm for batch progress\n",
    "        for batch in tqdm(dataloader, desc=\"Processing Batches\"):\n",
    "            used_labels_p = []\n",
    "            used_labels_a0 = []\n",
    "            used_labels_a1 = []\n",
    "    \n",
    "            sentence_ids = batch['sentence_ids'].to(device)\n",
    "            sentence_attention_masks = batch['sentence_attention_masks'].to(device)\n",
    "\n",
    "            predicate_ids = batch['predicate_ids'].to(device)\n",
    "            predicate_attention_masks = batch['predicate_attention_masks'].to(device)\n",
    "            \n",
    "            arg0_ids = batch['arg0_ids'].to(device)\n",
    "            arg0_attention_masks = batch['arg0_attention_masks'].to(device)\n",
    "\n",
    "            arg1_ids = batch['arg1_ids'].to(device)\n",
    "            arg1_attention_masks = batch['arg1_attention_masks'].to(device)\t\n",
    "\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            sentence_embeddings, predicate_embeddings, arg0_embeddings, arg1_embeddings = model.aggregation(sentence_ids, sentence_attention_masks, predicate_ids, predicate_attention_masks, arg0_ids, arg0_attention_masks, arg1_ids, arg1_attention_masks)\n",
    "            \n",
    "            # Process each span\n",
    "            for sentence_idx in range(sentence_embeddings.size(1)):\n",
    "                used_sentence_labels_p = []\n",
    "                used_sentence_labels_a0 = []\n",
    "                used_sentence_labels_a1 = []\n",
    "\n",
    "                s_sentence_span = sentence_embeddings[:, sentence_idx, :]\n",
    "\n",
    "                for span_idx in range(predicate_embeddings.size(2)):                    \n",
    "                    v_p_span = predicate_embeddings[:, sentence_idx, span_idx, :]\n",
    "                    v_a0_span = arg0_embeddings[:, sentence_idx, span_idx, :]\n",
    "                    v_a1_span = arg1_embeddings[:, sentence_idx, span_idx, :]\n",
    "\n",
    "                    #unsupervised.combined_autoencoder v_p, v_a0, v_a1, v_sentence, tau\n",
    "                    output = model.unsupervised.combined_autoencoder(v_p_span, v_a0_span, v_a1_span, s_sentence_span, 0.6)\n",
    "                    \n",
    "                    used_sentence_labels_p.append(output[\"p\"][\"g\"].cpu().numpy())\n",
    "                    used_sentence_labels_a0.append(output[\"a0\"][\"g\"].cpu().numpy())\n",
    "                    used_sentence_labels_a1.append(output[\"a1\"][\"g\"].cpu().numpy())\n",
    "                \n",
    "                used_labels_p.append(used_sentence_labels_p)\n",
    "                used_labels_a0.append(used_sentence_labels_a0)\n",
    "                used_labels_a1.append(used_sentence_labels_a1)\n",
    "            \n",
    "            # Forward pass\n",
    "            _, span_logits, sentence_logits, combined_logits = model(sentence_ids, sentence_attention_masks, predicate_ids, predicate_attention_masks, arg0_ids, arg0_attention_masks, arg1_ids, arg1_attention_masks, 0.5)\n",
    "            combined_pred = (torch.softmax(combined_logits, dim=-1) > 0.5).float()\n",
    "\n",
    "            all_preds_span.append(combined_pred.cpu().numpy())\n",
    "                \n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            all_used_labels_p.append(used_labels_p)\n",
    "            all_used_labels_a0.append(used_labels_a0)\n",
    "            all_used_labels_a1.append(used_labels_a1)\n",
    "\n",
    "    predictions = np.vstack(all_preds_span)\n",
    "    \n",
    "    all_used_labels_p = np.vstack(all_used_labels_p)\n",
    "    all_used_labels_a0 = np.vstack(all_used_labels_a0)\n",
    "    all_used_labels_a1 = np.vstack(all_used_labels_a1)\n",
    "\n",
    "    # reshape from (iterator (1), num sentences 24, num spans 10, batch size 64, classes 15) to (batch size 64, num sentences 24, num spans 10, classes 15)\n",
    "    all_used_labels_p = all_used_labels_p.reshape(len(dataloader), batch_size, num_sentences, max_args_per_sentence, K)\n",
    "    all_used_labels_a0 = all_used_labels_a0.reshape(len(dataloader), batch_size, num_sentences, max_args_per_sentence, K)\n",
    "    all_used_labels_a1 = all_used_labels_a1.reshape(len(dataloader), batch_size, num_sentences, max_args_per_sentence, K)\n",
    "\n",
    "    return predictions, all_used_labels_p, all_used_labels_a0, all_used_labels_a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6f2b26323b4d44a4ed200213e9c085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "predicted_labels, used_labels_p, used_labels_a0, used_labels_a1 = inspect(model, dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [267], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m span_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicate_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m][elem_idx][sentence_idx])):            \n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Update the lists for each category\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cat_idx, category \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(y_columns):\n\u001b[0;32m---> 21\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mused_labels_p\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_idx\u001b[49m\u001b[43m]\u001b[49m[sentence_idx][span_idx][cat_idx] \u001b[38;5;241m>\u001b[39m boundary:\n\u001b[1;32m     22\u001b[0m             category_lists_p[category]\u001b[38;5;241m.\u001b[39mappend(ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicate_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m][elem_idx][sentence_idx][span_idx]\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m used_labels_a0[batch_idx][elem_idx][sentence_idx][span_idx][cat_idx] \u001b[38;5;241m>\u001b[39m boundary:\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "category_lists_p = {category: [] for category in y_columns}\n",
    "category_lists_a1 = {category: [] for category in y_columns}\n",
    "category_lists_a0 = {category: [] for category in y_columns}\n",
    "\n",
    "batch_size = len(dataloader)\n",
    "\n",
    "boundary = 0.5\n",
    "\n",
    "for batch_idx in range(batch_size):\n",
    "\n",
    "    # Iterate over each sentence\n",
    "    ds = dataloader.dataset[batch_idx]\n",
    "\n",
    "    for elem_idx in range(len(ds[\"predicate_ids\"])):\n",
    "    \n",
    "        for sentence_idx in range(len(ds[\"predicate_ids\"][elem_idx])):\n",
    "            # loop over spans\n",
    "            for span_idx in range(len(ds[\"predicate_ids\"][elem_idx][sentence_idx])):            \n",
    "                # Update the lists for each category\n",
    "                for cat_idx, category in enumerate(y_columns):\n",
    "                    if used_labels_p[batch_idx][elem_idx][sentence_idx][span_idx][cat_idx] > boundary:\n",
    "                        category_lists_p[category].append(ds[\"predicate_ids\"][elem_idx][sentence_idx][span_idx].int().numpy())\n",
    "                    \n",
    "                    if used_labels_a0[batch_idx][elem_idx][sentence_idx][span_idx][cat_idx] > boundary:\n",
    "                        category_lists_a0[category].append(ds[\"arg0_ids\"][elem_idx][sentence_idx][span_idx].int().numpy())\n",
    "                        \n",
    "                    if used_labels_a1[batch_idx][elem_idx][sentence_idx][span_idx][cat_idx] > boundary:\n",
    "                        category_lists_a1[category].append(ds[\"arg1_ids\"][elem_idx][sentence_idx][span_idx].int().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Ensure you have downloaded the necessary NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def decode_tokens(token_dict, tokenizer, remove_stopwords=False, lemmatize=False):\n",
    "    decoded_data = {}\n",
    "    stop_words = set(stopwords.words('english')) if remove_stopwords else set()\n",
    "    lemmatizer = WordNetLemmatizer() if lemmatize else None\n",
    "\n",
    "    for category, token_lists in token_dict.items():\n",
    "        decoded_data[category] = []\n",
    "        for tokens in token_lists:\n",
    "            if np.any(tokens > 0):\n",
    "                # Convert tokens to a list if it's a tensor or numpy array\n",
    "                if isinstance(tokens, torch.Tensor):\n",
    "                    tokens = tokens.tolist()\n",
    "                elif isinstance(tokens, np.ndarray):\n",
    "                    tokens = tokens.tolist()\n",
    "\n",
    "                # Decode the tokens\n",
    "                decoded_text = tokenizer.decode(tokens, skip_special_tokens=True).strip()\n",
    "\n",
    "                # Remove non-alphabetic characters (but keep spaces)\n",
    "                decoded_text = re.sub(r'[^A-Za-z ]', '', decoded_text)\n",
    "\n",
    "                # Tokenize, optionally lemmatize, and remove stop words\n",
    "                words = word_tokenize(decoded_text)\n",
    "                processed_words = [lemmatizer.lemmatize(word.lower()) if lemmatizer else word.lower() for word in words if word.lower() not in stop_words]\n",
    "\n",
    "                # Join the words back into a string and ensure it's not empty\n",
    "                processed_text = ' '.join(processed_words)\n",
    "                if processed_text:\n",
    "                    decoded_data[category].append(processed_text)\n",
    "\n",
    "    return decoded_data\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "# Decode the token IDs for each ARG\n",
    "decoded_predicate = decode_tokens(category_lists_p, tokenizer, remove_stopwords=True, lemmatize=True)\n",
    "decoded_arg0 = decode_tokens(category_lists_a0, tokenizer, remove_stopwords=True, lemmatize=True)\n",
    "decoded_arg1 = decode_tokens(category_lists_a1, tokenizer, remove_stopwords=True, lemmatize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_idf_per_category(data_dict):\n",
    "    \"\"\"\n",
    "    Calculate the inverse document frequency (IDF) for each word in each category in the data_dict.\n",
    "    Returns a dictionary with the same keys as the input, where the values are sorted lists of tuples (word, IDF score).\n",
    "    \"\"\"\n",
    "    category_idfs = {}\n",
    "\n",
    "    for category, documents in data_dict.items():\n",
    "        word_counts = {}\n",
    "        # Total number of documents in the current category\n",
    "        N = len(documents)\n",
    "\n",
    "        # Count the frequency of each word in the current category\n",
    "        for doc in documents:\n",
    "            unique_words = set(doc.split())\n",
    "            for word in unique_words:\n",
    "                word_counts[word] = word_counts.get(word, 0) + 1\n",
    "\n",
    "        # Calculate IDF for each word in the current category\n",
    "        idfs = {word: math.log(N / (1 + count)) for word, count in word_counts.items()}\n",
    "\n",
    "        # Sort the idfs by score\n",
    "        sorted_idfs = sorted(idfs.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        category_idfs[category] = sorted_idfs\n",
    "\n",
    "    return category_idfs\n",
    "\n",
    "\n",
    "# Calculate IDF scores for each category\n",
    "idf_predicate = calculate_idf_per_category(decoded_predicate)\n",
    "idf_arg0 = calculate_idf_per_category(decoded_arg0)\n",
    "idf_arg1 = calculate_idf_per_category(decoded_arg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33/3975524772.py:34: FutureWarning: this method is deprecated in favour of `Styler.hide(axis=\"index\")`\n",
      "  df_full_table.style.hide_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_24d03\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_24d03_level0_col0\" class=\"col_heading level0 col0\" >Frame</th>\n",
       "      <th id=\"T_24d03_level0_col1\" class=\"col_heading level0 col1\" >Predicate</th>\n",
       "      <th id=\"T_24d03_level0_col2\" class=\"col_heading level0 col2\" >ARG0</th>\n",
       "      <th id=\"T_24d03_level0_col3\" class=\"col_heading level0 col3\" >ARG1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_24d03_row0_col0\" class=\"data row0 col0\" >Economic</td>\n",
       "      <td id=\"T_24d03_row0_col1\" class=\"data row0 col1\" >gave, confront, borrowed, passport, admit</td>\n",
       "      <td id=\"T_24d03_row0_col2\" class=\"data row0 col2\" >colleague, provision, network, current</td>\n",
       "      <td id=\"T_24d03_row0_col3\" class=\"data row0 col3\" >taste, vast, owen, appearance, immigration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_24d03_row1_col0\" class=\"data row1 col0\" >Crime and Punishment</td>\n",
       "      <td id=\"T_24d03_row1_col1\" class=\"data row1 col1\" >curt, need, increase, rts, gave</td>\n",
       "      <td id=\"T_24d03_row1_col2\" class=\"data row1 col2\" >area, highway, system, member, federally</td>\n",
       "      <td id=\"T_24d03_row1_col3\" class=\"data row1 col3\" >lit, need, part, system, member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_24d03_row2_col0\" class=\"data row2 col0\" >Fairness and Equality</td>\n",
       "      <td id=\"T_24d03_row2_col1\" class=\"data row2 col1\" >fails, called, qualified, owns, th</td>\n",
       "      <td id=\"T_24d03_row2_col2\" class=\"data row2 col2\" >colorado</td>\n",
       "      <td id=\"T_24d03_row2_col3\" class=\"data row2 col3\" >policy, immigrant, already, enough, raise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_24d03_row3_col0\" class=\"data row3 col0\" >Capacity and Resources</td>\n",
       "      <td id=\"T_24d03_row3_col1\" class=\"data row3 col1\" >paid, think, start, wrote, help</td>\n",
       "      <td id=\"T_24d03_row3_col2\" class=\"data row3 col2\" >highway, vehicle, late, deal, wage</td>\n",
       "      <td id=\"T_24d03_row3_col3\" class=\"data row3 col3\" >illegal, publicly, immigrant, demand, immigration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_24d03_row4_col0\" class=\"data row4 col0\" >Cultural Identity</td>\n",
       "      <td id=\"T_24d03_row4_col1\" class=\"data row4 col1\" >saw, restrict, need, coming, vet</td>\n",
       "      <td id=\"T_24d03_row4_col2\" class=\"data row4 col2\" >area, gr, highway, philadelphia, member</td>\n",
       "      <td id=\"T_24d03_row4_col3\" class=\"data row4 col3\" >area, development, ca, system, plenty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_24d03_row5_col0\" class=\"data row5 col0\" >Morality</td>\n",
       "      <td id=\"T_24d03_row5_col1\" class=\"data row5 col1\" >gate, gr, oversee, owed, want</td>\n",
       "      <td id=\"T_24d03_row5_col2\" class=\"data row5 col2\" >l, curt, rum, proposed, democratic</td>\n",
       "      <td id=\"T_24d03_row5_col3\" class=\"data row5 col3\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_24d03_row6_col0\" class=\"data row6 col0\" >Policy Prescription and Evaluation</td>\n",
       "      <td id=\"T_24d03_row6_col1\" class=\"data row6 col1\" >restrict, ied, admit, deal, sat</td>\n",
       "      <td id=\"T_24d03_row6_col2\" class=\"data row6 col2\" >area, gr, ca, female, president</td>\n",
       "      <td id=\"T_24d03_row6_col3\" class=\"data row6 col3\" >information, ballot, law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_24d03_row7_col0\" class=\"data row7 col0\" >Other</td>\n",
       "      <td id=\"T_24d03_row7_col1\" class=\"data row7 col1\" >killed, need</td>\n",
       "      <td id=\"T_24d03_row7_col2\" class=\"data row7 col2\" >l, senator, ne, member, immigration</td>\n",
       "      <td id=\"T_24d03_row7_col3\" class=\"data row7 col3\" >special, russian, rum, community, proposal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_24d03_row8_col0\" class=\"data row8 col0\" >Legality, Constitutionality, Jurisdiction</td>\n",
       "      <td id=\"T_24d03_row8_col1\" class=\"data row8 col1\" >down, passed, need, want, addressed</td>\n",
       "      <td id=\"T_24d03_row8_col2\" class=\"data row8 col2\" >democratic, illegal, goodwill, immigration, unemployment</td>\n",
       "      <td id=\"T_24d03_row8_col3\" class=\"data row8 col3\" >area, restrict, refuse, vehicle, outrage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_24d03_row9_col0\" class=\"data row9 col0\" >External Regulation and Reputation</td>\n",
       "      <td id=\"T_24d03_row9_col1\" class=\"data row9 col1\" >produce, ing, curt, passed, challenging</td>\n",
       "      <td id=\"T_24d03_row9_col2\" class=\"data row9 col2\" >deputy, enforced, amount, owen, applicant</td>\n",
       "      <td id=\"T_24d03_row9_col3\" class=\"data row9 col3\" >disaster, reform, enforcement, economic, plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_24d03_row10_col0\" class=\"data row10 col0\" >Public Sentiment</td>\n",
       "      <td id=\"T_24d03_row10_col1\" class=\"data row10 col1\" >seek, need, lose, crack, aid</td>\n",
       "      <td id=\"T_24d03_row10_col2\" class=\"data row10 col2\" >area, daughter, reversal, illegal, federal</td>\n",
       "      <td id=\"T_24d03_row10_col3\" class=\"data row10 col3\" >customer, system, member, advertisement, welfare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_24d03_row11_col0\" class=\"data row11 col0\" >Health and Safety</td>\n",
       "      <td id=\"T_24d03_row11_col1\" class=\"data row11 col1\" >seek, saw, release, restrict, need</td>\n",
       "      <td id=\"T_24d03_row11_col2\" class=\"data row11 col2\" >highway, rum, engage, owen, system</td>\n",
       "      <td id=\"T_24d03_row11_col3\" class=\"data row11 col3\" >release, view, system, method, immigration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_24d03_row12_col0\" class=\"data row12 col0\" >Quality of Life</td>\n",
       "      <td id=\"T_24d03_row12_col1\" class=\"data row12 col1\" >favor, illuminated, used, getting, wanted</td>\n",
       "      <td id=\"T_24d03_row12_col2\" class=\"data row12 col2\" >people, van, house</td>\n",
       "      <td id=\"T_24d03_row12_col3\" class=\"data row12 col3\" >area, highway, development, member, solution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_24d03_row13_col0\" class=\"data row13 col0\" >Security and Defense</td>\n",
       "      <td id=\"T_24d03_row13_col1\" class=\"data row13 col1\" >passed, proposed, say, wanted, adopt</td>\n",
       "      <td id=\"T_24d03_row13_col2\" class=\"data row13 col2\" >people, vote, name, witness</td>\n",
       "      <td id=\"T_24d03_row13_col3\" class=\"data row13 col3\" >avenue, highway, philadelphia, solution, passport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_24d03_row14_col0\" class=\"data row14 col0\" >Political</td>\n",
       "      <td id=\"T_24d03_row14_col1\" class=\"data row14 col1\" >increase, coming, crack, cend, cap</td>\n",
       "      <td id=\"T_24d03_row14_col2\" class=\"data row14 col2\" >area, gr, chain, ca, member</td>\n",
       "      <td id=\"T_24d03_row14_col3\" class=\"data row14 col3\" >morning, area, restrict, welfare, deal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe29e6f0be0>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_dataframe_with_limit(decoded_predicate, decoded_arg0, decoded_arg1, word_limit):\n",
    "    # Initialize a list to collect DataFrame rows\n",
    "    rows = []\n",
    "\n",
    "    # Populate the list with rows\n",
    "    for frame in set(decoded_predicate) | set(decoded_arg0) | set(decoded_arg1):\n",
    "        # Get the lists, limiting the number of words and joining them with a comma\n",
    "        pred_words = ', '.join([s.strip() for s in list(set(decoded_predicate.get(frame, [])))[:word_limit] if s])\n",
    "        arg0_words = ', '.join(list(set(decoded_arg0.get(frame, [])))[:word_limit])\n",
    "        arg1_words = ', '.join(list(set(decoded_arg1.get(frame, [])))[:word_limit])\n",
    "\n",
    "        # Create a dictionary for the row\n",
    "        row = {\n",
    "            \"Frame\": frame,\n",
    "            \"Predicate\": pred_words,\n",
    "            \"ARG0\": arg0_words,\n",
    "            \"ARG1\": arg1_words\n",
    "        }\n",
    "        \n",
    "        # Append the row dictionary to the rows list\n",
    "        rows.append(row)\n",
    "\n",
    "    # Convert the list of rows to a DataFrame\n",
    "    df_full_table = pd.DataFrame(rows)\n",
    "\n",
    "    return df_full_table\n",
    "\n",
    "# Example usage\n",
    "# Assuming decoded_predicate, decoded_arg0, decoded_arg1 are already defined\n",
    "word_limit = 5  # Set your word limit here\n",
    "df_full_table = create_dataframe_with_limit(decoded_predicate, decoded_arg0, decoded_arg1, word_limit)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_full_table.style.hide_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65ace2522b94205a6237c2f4d3ed0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "predicted_labels, used_labels_p, used_labels_a0, used_labels_a1 = inspect(model, example_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBILL ON IMMIGRANT WORKERS DIES. Legislation to allow nearly twice as many computer-savvy foreigners and other high-skilled immigrants into the country next year apparently has died in Congress. The House passed the compromise measure last month, 288-133, but Sen. Tom Harkin, D-Iowa, had blocked a vote when in the Senate. The proposal, backed by high-tech companies, would raise the limit of so- called H-1B visas granted each year to skilled workers from abroad. Only 65,000 visas are now granted each year; the bill would raise the annual cap to 115,500 for the next two years and to 107,500 in 2001. The ceiling would return to 65,000 in 2002.\\n'"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from termcolor import colored, COLORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Frame: \u001b[34mEconomic\u001b[0m\n",
      "\n",
      "\n",
      "BILL ON IMMIGRANT WORKERS DIES. (p: , a0: , a1: )\n",
      "Legislation to allow nearly twice as many computer-savvy foreigners and other high-skilled immigrants into the country next year apparently has died in Congress. (p: \u001b[34mallow\u001b[0m, \u001b[33mdied\u001b[0m, a0: \u001b[32mlegislation\u001b[0m, a1: \u001b[32mnearly\u001b[0m \u001b[32mtwice\u001b[0m \u001b[32mas\u001b[0m \u001b[32mmany\u001b[0m \u001b[32mcomputer\u001b[0m \u001b[32m-\u001b[0m \u001b[32msavvy\u001b[0m \u001b[32mforeigners\u001b[0m \u001b[32mand\u001b[0m \u001b[32mother\u001b[0m \u001b[32mhigh\u001b[0m \u001b[32m-\u001b[0m, \u001b[32mlegislation\u001b[0m \u001b[32mto\u001b[0m \u001b[32mallow\u001b[0m \u001b[32mnearly\u001b[0m \u001b[32mtwice\u001b[0m \u001b[32mas\u001b[0m \u001b[32mmany\u001b[0m \u001b[32mcomputer\u001b[0m \u001b[32m-\u001b[0m \u001b[32msavvy\u001b[0m \u001b[32mforeigners\u001b[0m \u001b[32mand\u001b[0m)\n",
      "The House passed the compromise measure last month, 288-133, but Sen. Tom Harkin, D-Iowa, had blocked a vote when in the Senate. (p: \u001b[37mpassed\u001b[0m, \u001b[33mblocked\u001b[0m, a0: \u001b[37mthe\u001b[0m \u001b[37mhouse\u001b[0m, \u001b[37msen.\u001b[0m \u001b[37mtom\u001b[0m \u001b[37mharkin,\u001b[0m \u001b[37md\u001b[0m \u001b[37m-\u001b[0m \u001b[37miowa,\u001b[0m, a1: \u001b[37mthe\u001b[0m \u001b[37mcompromise\u001b[0m \u001b[37mmeasure\u001b[0m, \u001b[37ma\u001b[0m \u001b[37mvote\u001b[0m)\n",
      "The proposal, backed by high-tech companies, would raise the limit of so- called H-1B visas granted each year to skilled workers from abroad. (p: \u001b[33mbacked\u001b[0m, \u001b[33mraise\u001b[0m, \u001b[33mgranted\u001b[0m, a0: \u001b[32mby\u001b[0m \u001b[32mhigh\u001b[0m \u001b[32m-\u001b[0m \u001b[32mtech\u001b[0m \u001b[32mcompanies\u001b[0m, \u001b[32mthe\u001b[0m \u001b[32mproposal,\u001b[0m \u001b[32mbacked\u001b[0m \u001b[32mby\u001b[0m \u001b[32mhigh\u001b[0m \u001b[32m-\u001b[0m \u001b[32mtech\u001b[0m \u001b[32mcompanies,\u001b[0m, a1: \u001b[31mthe\u001b[0m \u001b[31mproposal\u001b[0m, \u001b[31mthe\u001b[0m \u001b[31mlimit\u001b[0m \u001b[31mof\u001b[0m \u001b[31mso\u001b[0m \u001b[31m-\u001b[0m \u001b[31mcalled\u001b[0m \u001b[31mh\u001b[0m \u001b[31m-\u001b[0m \u001b[31m1b\u001b[0m \u001b[31mvisas\u001b[0m \u001b[31mgranted\u001b[0m \u001b[31meach\u001b[0m \u001b[31myear\u001b[0m \u001b[31mto\u001b[0m, \u001b[31mso\u001b[0m \u001b[31m-\u001b[0m \u001b[31mcalled\u001b[0m \u001b[31mh\u001b[0m \u001b[31m-\u001b[0m \u001b[31m1b\u001b[0m \u001b[31mvisas\u001b[0m)\n",
      "Only 65,000 visas are now granted each year; the bill would raise the annual cap to 115,500 for the next two years and to 107,500 in 2001. (p: , a0: , a1: )\n",
      "The ceiling would return to 65,000 in 2002. (p: , a0: , a1: )\n",
      "\n",
      "Color Legend:\n",
      "Cultural Identity: \u001b[30m█\u001b[0m\n",
      "Economic: \u001b[34m█\u001b[0m\n",
      "Capacity and Resources: \u001b[32m█\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Placeholder functions - you'll need to replace these with your actual functions\n",
    "def decode_token_ids(token_ids):\n",
    "    # Replace with your actual tokenizer decode call\n",
    "    return tokenizer.decode(token_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "# Define your categories and their associated colors\n",
    "category_colors = {frame: np.random.choice(list(COLORS.keys())) for frame in y_columns}\n",
    "\n",
    "# Function to color a word based on its category\n",
    "def color_word(word, category):\n",
    "    if category in category_colors:\n",
    "        return colored(word, category_colors[category])\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "# Function to process and color the article based on predictions\n",
    "def color_article(article, predicted_labels, used_predicates, used_arg0, used_arg1, y_columns):\n",
    "\n",
    "    # get col name from 1 hot predicted_labels\n",
    "    frame = y_columns[np.where(predicted_labels[0] == 1)[0][0]]\n",
    "    \n",
    "    # Print the predicted frame with color coding\n",
    "    print(f\"Predicted Frame: {colored(frame, category_colors[frame])}\\n\")\n",
    "\n",
    "    # Split article into sentences using NLTK\n",
    "    sentences = nltk.sent_tokenize(article)\n",
    "    \n",
    "    # Loop through the predictions and color the words accordingly\n",
    "    for sentence_idx in range(len(sentences)):\n",
    "        current_sent = sentences[sentence_idx]\n",
    "\n",
    "        current_predicates = []\n",
    "        current_arg0s = []\n",
    "        current_arg1s = []\n",
    "\n",
    "        predicted_frames = []\n",
    "\n",
    "        for span_idx in range(used_predicates.shape[3]):\n",
    "            for cat_idx, category in enumerate(y_columns):\n",
    "                if used_predicates[0][0][sentence_idx][span_idx][cat_idx] > 0.5:\n",
    "                    token_ids = example_dataset[0][\"predicate_ids\"][sentence_idx][span_idx].int().numpy()\n",
    "                    decoded_tokens = decode_token_ids(token_ids)\n",
    "                    decoded_words = decoded_tokens.split()\n",
    "\n",
    "                    predicted_frames.append(category)\n",
    "                \n",
    "                    # check if word not empty\n",
    "                    if decoded_words:\n",
    "                        colored_words = [color_word(word, category) for word in decoded_words]\n",
    "                        colored_sentence = ' '.join(colored_words)\n",
    "                        current_predicates.append(colored_sentence)\n",
    "\n",
    "                if used_arg0[0][0][sentence_idx][span_idx][cat_idx] > 0.5:\n",
    "                    token_ids = example_dataset[0][\"arg0_ids\"][sentence_idx][span_idx].int().numpy()\n",
    "                    decoded_tokens = decode_token_ids(token_ids)\n",
    "                    decoded_words = decoded_tokens.split()\n",
    "                \n",
    "                    predicted_frames.append(category)\n",
    "\n",
    "                    # check if word not empty\n",
    "                    if decoded_words:\n",
    "                        colored_words = [color_word(word, category) for word in decoded_words]\n",
    "                        colored_sentence = ' '.join(colored_words)\n",
    "                        current_arg0s.append(colored_sentence)\n",
    "\n",
    "                if used_arg1[0][0][sentence_idx][span_idx][cat_idx] > 0.5:\n",
    "                    token_ids = example_dataset[0][\"arg1_ids\"][sentence_idx][span_idx].int().numpy()\n",
    "                    decoded_tokens = decode_token_ids(token_ids)\n",
    "                    decoded_words = decoded_tokens.split()\n",
    "                \n",
    "                    predicted_frames.append(category)\n",
    "\n",
    "                    # check if word not empty\n",
    "                    if decoded_words:\n",
    "                        colored_words = [color_word(word, category) for word in decoded_words]\n",
    "                        colored_sentence = ' '.join(colored_words)\n",
    "                        current_arg1s.append(colored_sentence)\n",
    "        \n",
    "        print(current_sent, f\"(p: {', '.join(current_predicates)}, a0: {', '.join(current_arg0s)}, a1: {', '.join(current_arg1s)})\")\n",
    "\n",
    "    # Print color legend for used categories\n",
    "    print(\"\\nColor Legend:\")\n",
    "    for category in set(predicted_frames):\n",
    "        print(f\"{category}: {colored('█', category_colors[category])}\")\n",
    "\n",
    "# Process each label type\n",
    "colored_article_p = color_article(example_article, predicted_labels, used_labels_p, used_labels_a0, used_labels_a1, y_columns)\n",
    "\n",
    "colored_article_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05c4f9fa65704ea5ba7f80e879e08510": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f54181f857a4110bf9976a56c97de97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fbfe002ccd541f9b6ab62ed4eebef35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1048f064e69b46d497b65cb9b88d0142": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc871ed94e764fe884ffdafca1445bfe",
       "IPY_MODEL_b4e7e77911e5408b84d89ccaff134708",
       "IPY_MODEL_c322e99ad9504207b7cfb9ae2ca9d6b1"
      ],
      "layout": "IPY_MODEL_dd92db5892be4357a6446146d9e9a0dd"
     }
    },
    "145c8616bab245358c8052beac5bd2bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20d6b378a69744e4a327d929c391b475": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "364a4257f8a641e18b7bde39e63a618d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "409a73804fc34a63a619a42b9468be46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "475020323c07410e87d366a6f553aafb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_145c8616bab245358c8052beac5bd2bc",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ca901348dcd1428ebecc55d659fa40d1",
      "value": 28
     }
    },
    "4ddbb3fa3b924a9e9650f51204580f8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a5458551f974a94b61ff658ae59fa70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b48b8b79d6a4ff1b0655a6bfcf7a422": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c06d626b5ee4fe8bdb9be7fb879aae0",
      "placeholder": "​",
      "style": "IPY_MODEL_779202125255413cb719a43fe5d14ce7",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "5d40c6e034fd4b278969dd928cc07dff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f4b55ead6884f3790a3acfa43232fc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87907508c4eb43f3a27858f1d397ca99",
      "placeholder": "​",
      "style": "IPY_MODEL_d21ed2e527464a0ca0cb2b3b4fad928a",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "650f8e0f82e849f58a47507291b15500": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbb672669b9f4c36873048cfa1d2daf6",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cf42b39e3be94c90b3a63d05783481a3",
      "value": 231508
     }
    },
    "67ea6145091b440da6b4c5d5f8695aa9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ac495a816994aaeb8926c6c97d103ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ddbb3fa3b924a9e9650f51204580f8d",
      "placeholder": "​",
      "style": "IPY_MODEL_a115ed03534a4c64a17fa55d93a0f93a",
      "value": " 570/570 [00:00&lt;00:00, 47.0kB/s]"
     }
    },
    "71add6bf108545af8db6aeb392793759": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5f4b55ead6884f3790a3acfa43232fc9",
       "IPY_MODEL_475020323c07410e87d366a6f553aafb",
       "IPY_MODEL_e2454ec2f5904e0bacde56ae7d4089a9"
      ],
      "layout": "IPY_MODEL_0f54181f857a4110bf9976a56c97de97"
     }
    },
    "779202125255413cb719a43fe5d14ce7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "87907508c4eb43f3a27858f1d397ca99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c06d626b5ee4fe8bdb9be7fb879aae0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e13dccd922946ab873cc287fcca5baf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93fa55d130db463c8ddffc947f2e99cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a6d16261d5b4693b09acf83dcb38920": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0265a21ae504485ab59207228c1f6d6",
      "placeholder": "​",
      "style": "IPY_MODEL_8e13dccd922946ab873cc287fcca5baf",
      "value": " 232k/232k [00:00&lt;00:00, 9.51MB/s]"
     }
    },
    "a0265a21ae504485ab59207228c1f6d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a115ed03534a4c64a17fa55d93a0f93a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a74bacc051494d1ea0f4cbd656505cfe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4e7e77911e5408b84d89ccaff134708": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67ea6145091b440da6b4c5d5f8695aa9",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bef37b47c8ee49778464c05adcffa30d",
      "value": 466062
     }
    },
    "b83493088cd24629a04ec612aa522ed4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c222d2a5e4664f9b9aefed7f093d4a4e",
       "IPY_MODEL_fa94f90b735f418fb2b502f7877b5306",
       "IPY_MODEL_6ac495a816994aaeb8926c6c97d103ae"
      ],
      "layout": "IPY_MODEL_409a73804fc34a63a619a42b9468be46"
     }
    },
    "bef37b47c8ee49778464c05adcffa30d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c222d2a5e4664f9b9aefed7f093d4a4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_364a4257f8a641e18b7bde39e63a618d",
      "placeholder": "​",
      "style": "IPY_MODEL_93fa55d130db463c8ddffc947f2e99cd",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "c322e99ad9504207b7cfb9ae2ca9d6b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d40c6e034fd4b278969dd928cc07dff",
      "placeholder": "​",
      "style": "IPY_MODEL_f6b3c67d61114db5810bd78339a218d9",
      "value": " 466k/466k [00:00&lt;00:00, 1.88MB/s]"
     }
    },
    "ca901348dcd1428ebecc55d659fa40d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cf42b39e3be94c90b3a63d05783481a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d21ed2e527464a0ca0cb2b3b4fad928a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d568d9b894694b6fb432456031cee230": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbb672669b9f4c36873048cfa1d2daf6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd92db5892be4357a6446146d9e9a0dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2454ec2f5904e0bacde56ae7d4089a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20d6b378a69744e4a327d929c391b475",
      "placeholder": "​",
      "style": "IPY_MODEL_05c4f9fa65704ea5ba7f80e879e08510",
      "value": " 28.0/28.0 [00:00&lt;00:00, 1.97kB/s]"
     }
    },
    "e9ee9acc5e414c65ad10b8864cc07b07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f19c187b1e8c4bbe9fda366f24f2b79e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b48b8b79d6a4ff1b0655a6bfcf7a422",
       "IPY_MODEL_650f8e0f82e849f58a47507291b15500",
       "IPY_MODEL_9a6d16261d5b4693b09acf83dcb38920"
      ],
      "layout": "IPY_MODEL_d568d9b894694b6fb432456031cee230"
     }
    },
    "f6b3c67d61114db5810bd78339a218d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa94f90b735f418fb2b502f7877b5306": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a74bacc051494d1ea0f4cbd656505cfe",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0fbfe002ccd541f9b6ab62ed4eebef35",
      "value": 570
     }
    },
    "fc871ed94e764fe884ffdafca1445bfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a5458551f974a94b61ff658ae59fa70",
      "placeholder": "​",
      "style": "IPY_MODEL_e9ee9acc5e414c65ad10b8864cc07b07",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
