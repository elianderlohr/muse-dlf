{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier - Try 1\n",
    "\n",
    "Classify if a article has the Morality Frame or not using just the article as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../../data/')\n",
    "\n",
    "labels_path = \"data/en/train-labels-subtask-2.txt\"\n",
    "articles_path = \"data/en/train-articles-subtask-2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>frames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>832959523</td>\n",
       "      <td>Morality,Security_and_defense,Policy_prescript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>833039623</td>\n",
       "      <td>Political,Crime_and_punishment,External_regula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>833032367</td>\n",
       "      <td>Political,Crime_and_punishment,Fairness_and_eq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>814777937</td>\n",
       "      <td>Political,Morality,Fairness_and_equality,Exter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>821744708</td>\n",
       "      <td>Policy_prescription_and_evaluation,Political,L...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                             frames\n",
       "0   832959523  Morality,Security_and_defense,Policy_prescript...\n",
       "1   833039623  Political,Crime_and_punishment,External_regula...\n",
       "2   833032367  Political,Crime_and_punishment,Fairness_and_eq...\n",
       "3   814777937  Political,Morality,Fairness_and_equality,Exter...\n",
       "4   821744708  Policy_prescription_and_evaluation,Political,L..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dev-labels-subtask-2.txt file\n",
    "labels_df = pd.read_csv(labels_path, sep=\"\\t\")\n",
    "\n",
    "# Rename the columns for easier processing\n",
    "labels_df.columns = [\"article_id\", \"frames\"]\n",
    "\n",
    "\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>frames</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>832959523</td>\n",
       "      <td>Morality,Security_and_defense,Policy_prescript...</td>\n",
       "      <td>How Theresa May Botched\\n\\nThose were the time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>833039623</td>\n",
       "      <td>Political,Crime_and_punishment,External_regula...</td>\n",
       "      <td>Robert Mueller III Rests His Case—Dems NEVER W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>833032367</td>\n",
       "      <td>Political,Crime_and_punishment,Fairness_and_eq...</td>\n",
       "      <td>Robert Mueller Not Recommending Any More Indic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>814777937</td>\n",
       "      <td>Political,Morality,Fairness_and_equality,Exter...</td>\n",
       "      <td>The Far Right Is Trying to Co-opt the Yellow V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>821744708</td>\n",
       "      <td>Policy_prescription_and_evaluation,Political,L...</td>\n",
       "      <td>‘Special place in hell’ for those who promoted...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                             frames  \\\n",
       "0   832959523  Morality,Security_and_defense,Policy_prescript...   \n",
       "1   833039623  Political,Crime_and_punishment,External_regula...   \n",
       "2   833032367  Political,Crime_and_punishment,Fairness_and_eq...   \n",
       "3   814777937  Political,Morality,Fairness_and_equality,Exter...   \n",
       "4   821744708  Policy_prescription_and_evaluation,Political,L...   \n",
       "\n",
       "                                             content  \n",
       "0  How Theresa May Botched\\n\\nThose were the time...  \n",
       "1  Robert Mueller III Rests His Case—Dems NEVER W...  \n",
       "2  Robert Mueller Not Recommending Any More Indic...  \n",
       "3  The Far Right Is Trying to Co-opt the Yellow V...  \n",
       "4  ‘Special place in hell’ for those who promoted...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A function to read the article text given its ID\n",
    "def get_article_content(article_id):\n",
    "    try:\n",
    "        with open(f\"{articles_path}/article{article_id}.txt\", \"r\") as f:\n",
    "            return f.read()\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "\n",
    "df = labels_df\n",
    "\n",
    "# Apply the function to get the article content\n",
    "df[\"content\"] = df[\"article_id\"].apply(get_article_content)\n",
    "\n",
    "# Drop rows where content could not be found\n",
    "df.dropna(subset=[\"content\"], inplace=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>frames</th>\n",
       "      <th>content</th>\n",
       "      <th>frames_list</th>\n",
       "      <th>Morality</th>\n",
       "      <th>Security_and_defense</th>\n",
       "      <th>Policy_prescription_and_evaluation</th>\n",
       "      <th>Legality_Constitutionality_and_jurisprudence</th>\n",
       "      <th>Economic</th>\n",
       "      <th>Political</th>\n",
       "      <th>Crime_and_punishment</th>\n",
       "      <th>External_regulation_and_reputation</th>\n",
       "      <th>Public_opinion</th>\n",
       "      <th>Fairness_and_equality</th>\n",
       "      <th>Capacity_and_resources</th>\n",
       "      <th>Quality_of_life</th>\n",
       "      <th>Cultural_identity</th>\n",
       "      <th>Health_and_safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>832959523</td>\n",
       "      <td>Morality,Security_and_defense,Policy_prescript...</td>\n",
       "      <td>How Theresa May Botched\\n\\nThose were the time...</td>\n",
       "      <td>[Morality, Security_and_defense, Policy_prescr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>833039623</td>\n",
       "      <td>Political,Crime_and_punishment,External_regula...</td>\n",
       "      <td>Robert Mueller III Rests His Case—Dems NEVER W...</td>\n",
       "      <td>[Political, Crime_and_punishment, External_reg...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>833032367</td>\n",
       "      <td>Political,Crime_and_punishment,Fairness_and_eq...</td>\n",
       "      <td>Robert Mueller Not Recommending Any More Indic...</td>\n",
       "      <td>[Political, Crime_and_punishment, Fairness_and...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>814777937</td>\n",
       "      <td>Political,Morality,Fairness_and_equality,Exter...</td>\n",
       "      <td>The Far Right Is Trying to Co-opt the Yellow V...</td>\n",
       "      <td>[Political, Morality, Fairness_and_equality, E...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>821744708</td>\n",
       "      <td>Policy_prescription_and_evaluation,Political,L...</td>\n",
       "      <td>‘Special place in hell’ for those who promoted...</td>\n",
       "      <td>[Policy_prescription_and_evaluation, Political...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                             frames  \\\n",
       "0   832959523  Morality,Security_and_defense,Policy_prescript...   \n",
       "1   833039623  Political,Crime_and_punishment,External_regula...   \n",
       "2   833032367  Political,Crime_and_punishment,Fairness_and_eq...   \n",
       "3   814777937  Political,Morality,Fairness_and_equality,Exter...   \n",
       "4   821744708  Policy_prescription_and_evaluation,Political,L...   \n",
       "\n",
       "                                             content  \\\n",
       "0  How Theresa May Botched\\n\\nThose were the time...   \n",
       "1  Robert Mueller III Rests His Case—Dems NEVER W...   \n",
       "2  Robert Mueller Not Recommending Any More Indic...   \n",
       "3  The Far Right Is Trying to Co-opt the Yellow V...   \n",
       "4  ‘Special place in hell’ for those who promoted...   \n",
       "\n",
       "                                         frames_list  Morality  \\\n",
       "0  [Morality, Security_and_defense, Policy_prescr...         1   \n",
       "1  [Political, Crime_and_punishment, External_reg...         0   \n",
       "2  [Political, Crime_and_punishment, Fairness_and...         0   \n",
       "3  [Political, Morality, Fairness_and_equality, E...         1   \n",
       "4  [Policy_prescription_and_evaluation, Political...         0   \n",
       "\n",
       "   Security_and_defense  Policy_prescription_and_evaluation  \\\n",
       "0                     1                                   1   \n",
       "1                     0                                   1   \n",
       "2                     0                                   0   \n",
       "3                     1                                   0   \n",
       "4                     0                                   1   \n",
       "\n",
       "   Legality_Constitutionality_and_jurisprudence  Economic  Political  \\\n",
       "0                                             1         1          0   \n",
       "1                                             1         0          1   \n",
       "2                                             1         0          1   \n",
       "3                                             0         1          1   \n",
       "4                                             1         0          1   \n",
       "\n",
       "   Crime_and_punishment  External_regulation_and_reputation  Public_opinion  \\\n",
       "0                     0                                   0               0   \n",
       "1                     1                                   1               1   \n",
       "2                     1                                   1               0   \n",
       "3                     0                                   1               1   \n",
       "4                     0                                   1               0   \n",
       "\n",
       "   Fairness_and_equality  Capacity_and_resources  Quality_of_life  \\\n",
       "0                      0                       0                0   \n",
       "1                      0                       0                0   \n",
       "2                      1                       0                0   \n",
       "3                      1                       0                0   \n",
       "4                      0                       0                0   \n",
       "\n",
       "   Cultural_identity  Health_and_safety  \n",
       "0                  0                  0  \n",
       "1                  0                  0  \n",
       "2                  0                  0  \n",
       "3                  0                  0  \n",
       "4                  0                  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the frames column into a list of frames\n",
    "df[\"frames_list\"] = df[\"frames\"].str.split(\",\")\n",
    "\n",
    "# create for each frame a new column with the frame as name and 1 if the frame is present in the article and 0 if not\n",
    "for frame in df[\"frames_list\"].explode().unique():\n",
    "    df[frame] = df[\"frames_list\"].apply(lambda x: 1 if frame in x else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"content\"]\n",
    "y = df.drop(columns=[\"article_id\", \"frames\", \"frames_list\", \"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    How Theresa May Botched\\n\\nThose were the time...\n",
       "1    Robert Mueller III Rests His Case—Dems NEVER W...\n",
       "2    Robert Mueller Not Recommending Any More Indic...\n",
       "3    The Far Right Is Trying to Co-opt the Yellow V...\n",
       "4    ‘Special place in hell’ for those who promoted...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Morality</th>\n",
       "      <th>Security_and_defense</th>\n",
       "      <th>Policy_prescription_and_evaluation</th>\n",
       "      <th>Legality_Constitutionality_and_jurisprudence</th>\n",
       "      <th>Economic</th>\n",
       "      <th>Political</th>\n",
       "      <th>Crime_and_punishment</th>\n",
       "      <th>External_regulation_and_reputation</th>\n",
       "      <th>Public_opinion</th>\n",
       "      <th>Fairness_and_equality</th>\n",
       "      <th>Capacity_and_resources</th>\n",
       "      <th>Quality_of_life</th>\n",
       "      <th>Cultural_identity</th>\n",
       "      <th>Health_and_safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Morality  Security_and_defense  Policy_prescription_and_evaluation  \\\n",
       "0         1                     1                                   1   \n",
       "1         0                     0                                   1   \n",
       "2         0                     0                                   0   \n",
       "3         1                     1                                   0   \n",
       "4         0                     0                                   1   \n",
       "\n",
       "   Legality_Constitutionality_and_jurisprudence  Economic  Political  \\\n",
       "0                                             1         1          0   \n",
       "1                                             1         0          1   \n",
       "2                                             1         0          1   \n",
       "3                                             0         1          1   \n",
       "4                                             1         0          1   \n",
       "\n",
       "   Crime_and_punishment  External_regulation_and_reputation  Public_opinion  \\\n",
       "0                     0                                   0               0   \n",
       "1                     1                                   1               1   \n",
       "2                     1                                   1               0   \n",
       "3                     0                                   1               1   \n",
       "4                     0                                   1               0   \n",
       "\n",
       "   Fairness_and_equality  Capacity_and_resources  Quality_of_life  \\\n",
       "0                      0                       0                0   \n",
       "1                      0                       0                0   \n",
       "2                      1                       0                0   \n",
       "3                      1                       0                0   \n",
       "4                      0                       0                0   \n",
       "\n",
       "   Cultural_identity  Health_and_safety  \n",
       "0                  0                  0  \n",
       "1                  0                  0  \n",
       "2                  0                  0  \n",
       "3                  0                  0  \n",
       "4                  0                  0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Morality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Morality\n",
       "0         1\n",
       "1         0\n",
       "2         0\n",
       "3         1\n",
       "4         0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify y to binary classification morality or Security_and_defense\n",
    "y = y[[\"Morality\"]]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Morality\n",
       "0           230\n",
       "1           202\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(432, 432)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import AdamW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "BATCH_SIZE = 16\n",
    "train_dataset = ArticleDataset(X, y, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_22348\\318797460.py:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  'label': torch.tensor(label, dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  2129, 14781,  2089, 28516,  7690,  2216,  2020,  1996,  2335,\n",
       "          1529,  1996,  2335,  3931,  1015,  2003,  1997,  2254,  2324,  1010,\n",
       "          2418,  1012,  7776,  2090,  1996,  2142,  2983,  1998,  1996,  2647,\n",
       "          2586,  2055,  7987, 10288,  4183,  2020,  2074,  2927,  1012,  1996,\n",
       "          1523,  2017,  1521,  2222,  2022, 10560,  1524, 24416,  1999,  1996,\n",
       "         17653,  2839, 10057,  1996,  7729,  1996,  2329,  2231,  2104,  2089,\n",
       "          7645,  2076,  1996,  7566,  1012,  3728,  2008,  7729,  2038,  5399,\n",
       "          2904,  1012,  2023, 12117, 12326,  2001,  2579,  2055,  2019,  3178,\n",
       "          3283,  1024,  1996,  4035,  7009,  1024,  2114,  1996,  2110,  1024,\n",
       "          2019,  1012,  1012,  1012,  2222,  7974,  5349,  6038,  1044,  1012,\n",
       "         25235,  3781,  1012,  2190,  3976,  1024,  1002,  2260,  1012,  5585,\n",
       "          4965,  2047,  1002,  1023,  1012,  5709,  1006,  2004,  1997,  2184,\n",
       "          1024,  2423,  3968,  2102,  1011,  4751,  1007, 14781,  2089,  2038,\n",
       "          2056,  2016,  1523, 25664,  8069,  1524,  1996,  2866,  2097,  2681,\n",
       "          1996,  7327,  2007,  1037,  3066,  1998,  2016,  2003,  2145,  1523,\n",
       "          2551,  2006,  1524, 12725,  3323,  1521,  1055,  3820,  1012,  7194,\n",
       "          1999,  9371,  1010,  2016,  2056,  2008,  2016,  2018,  1523,  3167,\n",
       "          9038,  1524,  2058,  2014,  5227,  2000,  8536,  7987, 10288,  4183,\n",
       "          1010,  2021,  2056,  2009,  2097,  3499,  2051,  2005, 12616,  2000,\n",
       "          2191,  1037,  1523,  2345,  3601,  1524,  1012,  2012,  1996,  7327,\n",
       "          6465,  1996,  7610,  3764,  2000,  1996,  2060,  2676,  4177,  2000,\n",
       "          3046,  2000,  2131,  2037,  5150,  2005,  1037,  8536,  3458,  2756,\n",
       "          2233,  1012,  5564,  1010,  7441,  2522, 15185,  6038,  2056,  2010,\n",
       "          7566,  1999,  9371,  2020,  1523,  2200, 26157,  1524,  1012,  4035,\n",
       "          9371, 11370,  4205, 13779,  2056,  3680,  2089,  3764,  2000,  7327,\n",
       "          4177,  2005,  3938,  2781,  1998,  2001,  2356,  2195,  2335,  2054,\n",
       "          2014,  9530,  3436, 11916,  3488,  2020,  2065,  2016,  2439,  1996,\n",
       "          2353,  1523, 15902,  3789,  1524,  2006,  2014,  3066,  1999,  3323,\n",
       "          1012,  2413,  2343, 14459, 26632,  2078,  2038,  7420,  2008,  2065,\n",
       "         12616,  3789,  2091,  3680,  2089,  1521,  1055,  7327, 10534,  3820,\n",
       "          2279,  2733,  1010,  1996,  2866,  2097,  2681,  2302,  1037,  3066,\n",
       "          1012,  2089,  2356,  1996,  7327,  2000,  2693,  1996,  2524, 22402,\n",
       "          2233,  2756,  7987, 10288,  4183,  3058,  2000,  2238,  2382,  1012,\n",
       "          2016,  2089,  2022,  2445,  2089,  2603,  1010,  1996,  2154,  1997,\n",
       "          7327,  3864,  1010,  2004,  1037, 12014,  2021,  2069,  2065,  2014,\n",
       "          3066,  5235,  1996,  2329,  3323,  1012,  1037,  2053,  1011,  3066,\n",
       "          5823,  2041,  2006,  2233,  2756,  2052,  3443, 14395,  8488,  2005,\n",
       "          2706,  1012,  2009,  2052,  2022, 23546,  2005,  3725,  1521,  1055,\n",
       "          4610,  1012,  2089,  1521,  1055, 10534,  3820,  2001,  2525,  5444,\n",
       "          2091,  3807,  1012,  2065,  2009,  3310,  2000,  1037,  2353,  3789,\n",
       "          1999,  3323,  2009,  2003,  2200,  3497,  2000,  8246,  2153,  1012,\n",
       "         19687,  3044,  1010,  2040,  2017,  2323,  2035,  3191,  1010,  7480,\n",
       "          2014,  7987, 10288,  4183,  4133, 16360,  2651,  2007,  2023,  1024,\n",
       "          2057,  1521,  2310,  2042,  2062, 21877, 18719, 23738,  2594,  2084,\n",
       "          2087, 15957,  2055,  1996, 16593,  1997,  1996,  2866, 13002,  1996,\n",
       "         12398,  1997,  1037,  2053,  1011,  3066,  7987, 10288,  4183,  1012,\n",
       "          2057,  2089,  2025,  2031,  2042, 21877, 18719, 23738,  2594,  2438,\n",
       "          1012,  2045,  2003,  2145,  1996,  6061,  2008,  2089,  3138,  1037,\n",
       "          8380,  3014,  2735,  1010,  2021,  2008,  2052,  2022,  1996,  2203,\n",
       "          1997,  2014,  2476,  1998,  3497,  2036,  1996,  2203,  1997,  1996,\n",
       "          4603,  2283,  1024,  2085,  2045,  2003,  1037,  2759,  5245,  2005,\n",
       "          2019,   102]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'label': tensor([1])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try train_dataset\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Define the device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Move the model to the device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\elias\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_22348\\318797460.py:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  'label': torch.tensor(label, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
