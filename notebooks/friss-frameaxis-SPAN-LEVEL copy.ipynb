{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../data/')\n",
    "\n",
    "labels_path = \"data/en/dev-labels-subtask-3.txt\"\n",
    "articles_path = \"data/en/dev-articles-subtask-3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>persuasion_technique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>813452859</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>813452859</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>813452859</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>813452859</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>813452859</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  sentence_id persuasion_technique\n",
       "0   813452859            1                  NaN\n",
       "1   813452859            3                  NaN\n",
       "2   813452859            4                  NaN\n",
       "3   813452859            5                  NaN\n",
       "4   813452859            6                  NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dev-labels-subtask-2.txt file\n",
    "labels_df = pd.read_csv(labels_path, sep='\\t', header=None, names=[\"article_id\", \"sentence_id\", \"persuasion_technique\"])\n",
    "\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>persuasion_technique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>813452859</td>\n",
       "      <td>7</td>\n",
       "      <td>Michael Swadling: I guess her only chance is i...</td>\n",
       "      <td>False_Dilemma-No_Choice,Loaded_Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>813452859</td>\n",
       "      <td>9</td>\n",
       "      <td>There is a chance; as unfortunately there are ...</td>\n",
       "      <td>False_Dilemma-No_Choice,Loaded_Language,Name_C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>813452859</td>\n",
       "      <td>11</td>\n",
       "      <td>Michael Swadling: The EU withdrawal act is in ...</td>\n",
       "      <td>Conversation_Killer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>813452859</td>\n",
       "      <td>12</td>\n",
       "      <td>I often use the example of an iPhone to people...</td>\n",
       "      <td>Conversation_Killer,Red_Herring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>813452859</td>\n",
       "      <td>15</td>\n",
       "      <td>Michael Swadling: The EU makes a profit on its...</td>\n",
       "      <td>Obfuscation-Vagueness-Confusion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  sentence_id                                           sentence  \\\n",
       "0   813452859            7  Michael Swadling: I guess her only chance is i...   \n",
       "1   813452859            9  There is a chance; as unfortunately there are ...   \n",
       "2   813452859           11  Michael Swadling: The EU withdrawal act is in ...   \n",
       "3   813452859           12  I often use the example of an iPhone to people...   \n",
       "4   813452859           15  Michael Swadling: The EU makes a profit on its...   \n",
       "\n",
       "                                persuasion_technique  \n",
       "0            False_Dilemma-No_Choice,Loaded_Language  \n",
       "1  False_Dilemma-No_Choice,Loaded_Language,Name_C...  \n",
       "2                                Conversation_Killer  \n",
       "3                    Conversation_Killer,Red_Herring  \n",
       "4                    Obfuscation-Vagueness-Confusion  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique article IDs from the dev-labels data\n",
    "unique_article_ids = labels_df['article_id'].unique()\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "\n",
    "# For each unique article ID, read the corresponding article file and join with the dev-labels data\n",
    "for article_id in unique_article_ids:\n",
    "    # Construct the file path for the article\n",
    "    file_path = f\"{articles_path}/article{article_id}.txt\"\n",
    "    \n",
    "    try:\n",
    "        # Load the article file\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Read the article sentences into a list\n",
    "            sentences = file.readlines()\n",
    "\n",
    "        # Filter dev-labels data for the current article_id and where persuasion_technique is not NaN\n",
    "        relevant_rows = labels_df[(labels_df['article_id'] == article_id) & (~labels_df['persuasion_technique'].isna())]\n",
    "\n",
    "        # For each relevant row, get the corresponding sentence and persuasion technique and append to the results list\n",
    "        for _, row in relevant_rows.iterrows():\n",
    "            sentence = sentences[row['sentence_id'] - 1].strip()  # Subtracting 1 because list indexing starts from 0\n",
    "            technique = row['persuasion_technique']\n",
    "            results.append([article_id, row['sentence_id'], sentence, technique])\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        # If the file for an article_id doesn't exist, continue to the next one\n",
    "        continue\n",
    "\n",
    "# Convert the results list to a dataframe\n",
    "df = pd.DataFrame(results, columns=['article_id', 'sentence_id', 'sentence', 'persuasion_technique'])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>persuasion_technique</th>\n",
       "      <th>persuasion_technique_list</th>\n",
       "      <th>False_Dilemma-No_Choice</th>\n",
       "      <th>Loaded_Language</th>\n",
       "      <th>Name_Calling-Labeling</th>\n",
       "      <th>Conversation_Killer</th>\n",
       "      <th>Red_Herring</th>\n",
       "      <th>...</th>\n",
       "      <th>Flag_Waving</th>\n",
       "      <th>Doubt</th>\n",
       "      <th>Whataboutism</th>\n",
       "      <th>Appeal_to_Fear-Prejudice</th>\n",
       "      <th>Causal_Oversimplification</th>\n",
       "      <th>Appeal_to_Hypocrisy</th>\n",
       "      <th>Appeal_to_Popularity</th>\n",
       "      <th>Appeal_to_Authority</th>\n",
       "      <th>Straw_Man</th>\n",
       "      <th>Guilt_by_Association</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>813452859</td>\n",
       "      <td>7</td>\n",
       "      <td>Michael Swadling: I guess her only chance is i...</td>\n",
       "      <td>False_Dilemma-No_Choice,Loaded_Language</td>\n",
       "      <td>[False_Dilemma-No_Choice, Loaded_Language]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>813452859</td>\n",
       "      <td>9</td>\n",
       "      <td>There is a chance; as unfortunately there are ...</td>\n",
       "      <td>False_Dilemma-No_Choice,Loaded_Language,Name_C...</td>\n",
       "      <td>[False_Dilemma-No_Choice, Loaded_Language, Nam...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>813452859</td>\n",
       "      <td>11</td>\n",
       "      <td>Michael Swadling: The EU withdrawal act is in ...</td>\n",
       "      <td>Conversation_Killer</td>\n",
       "      <td>[Conversation_Killer]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>813452859</td>\n",
       "      <td>12</td>\n",
       "      <td>I often use the example of an iPhone to people...</td>\n",
       "      <td>Conversation_Killer,Red_Herring</td>\n",
       "      <td>[Conversation_Killer, Red_Herring]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>813452859</td>\n",
       "      <td>15</td>\n",
       "      <td>Michael Swadling: The EU makes a profit on its...</td>\n",
       "      <td>Obfuscation-Vagueness-Confusion</td>\n",
       "      <td>[Obfuscation-Vagueness-Confusion]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  sentence_id                                           sentence  \\\n",
       "0   813452859            7  Michael Swadling: I guess her only chance is i...   \n",
       "1   813452859            9  There is a chance; as unfortunately there are ...   \n",
       "2   813452859           11  Michael Swadling: The EU withdrawal act is in ...   \n",
       "3   813452859           12  I often use the example of an iPhone to people...   \n",
       "4   813452859           15  Michael Swadling: The EU makes a profit on its...   \n",
       "\n",
       "                                persuasion_technique  \\\n",
       "0            False_Dilemma-No_Choice,Loaded_Language   \n",
       "1  False_Dilemma-No_Choice,Loaded_Language,Name_C...   \n",
       "2                                Conversation_Killer   \n",
       "3                    Conversation_Killer,Red_Herring   \n",
       "4                    Obfuscation-Vagueness-Confusion   \n",
       "\n",
       "                           persuasion_technique_list  False_Dilemma-No_Choice  \\\n",
       "0         [False_Dilemma-No_Choice, Loaded_Language]                        1   \n",
       "1  [False_Dilemma-No_Choice, Loaded_Language, Nam...                        1   \n",
       "2                              [Conversation_Killer]                        0   \n",
       "3                 [Conversation_Killer, Red_Herring]                        0   \n",
       "4                  [Obfuscation-Vagueness-Confusion]                        0   \n",
       "\n",
       "   Loaded_Language  Name_Calling-Labeling  Conversation_Killer  Red_Herring  \\\n",
       "0                1                      0                    0            0   \n",
       "1                1                      1                    0            0   \n",
       "2                0                      0                    1            0   \n",
       "3                0                      0                    1            1   \n",
       "4                0                      0                    0            0   \n",
       "\n",
       "   ...  Flag_Waving  Doubt  Whataboutism  Appeal_to_Fear-Prejudice  \\\n",
       "0  ...            0      0             0                         0   \n",
       "1  ...            0      0             0                         0   \n",
       "2  ...            0      0             0                         0   \n",
       "3  ...            0      0             0                         0   \n",
       "4  ...            0      0             0                         0   \n",
       "\n",
       "   Causal_Oversimplification  Appeal_to_Hypocrisy  Appeal_to_Popularity  \\\n",
       "0                          0                    0                     0   \n",
       "1                          0                    0                     0   \n",
       "2                          0                    0                     0   \n",
       "3                          0                    0                     0   \n",
       "4                          0                    0                     0   \n",
       "\n",
       "   Appeal_to_Authority  Straw_Man  Guilt_by_Association  \n",
       "0                    0          0                     0  \n",
       "1                    0          0                     0  \n",
       "2                    0          0                     0  \n",
       "3                    0          0                     0  \n",
       "4                    0          0                     0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the frames column into a list of frames\n",
    "df[\"persuasion_technique_list\"] = df[\"persuasion_technique\"].str.split(\",\")\n",
    "\n",
    "# create for each frame a new column with the frame as name and 1 if the frame is present in the article and 0 if not\n",
    "for frame in df[\"persuasion_technique_list\"].explode().unique():\n",
    "    df[frame] = df[\"persuasion_technique_list\"].apply(lambda x: 1 if frame in x else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"sentence\"]\n",
    "y = df.drop(columns=[\"article_id\", \"sentence_id\", \"sentence\", \"persuasion_technique\", \"persuasion_technique_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Michael Swadling: I guess her only chance is i...\n",
       "1    There is a chance; as unfortunately there are ...\n",
       "2    Michael Swadling: The EU withdrawal act is in ...\n",
       "3    I often use the example of an iPhone to people...\n",
       "4    Michael Swadling: The EU makes a profit on its...\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False_Dilemma-No_Choice</th>\n",
       "      <th>Loaded_Language</th>\n",
       "      <th>Name_Calling-Labeling</th>\n",
       "      <th>Conversation_Killer</th>\n",
       "      <th>Red_Herring</th>\n",
       "      <th>Obfuscation-Vagueness-Confusion</th>\n",
       "      <th>Exaggeration-Minimisation</th>\n",
       "      <th>Repetition</th>\n",
       "      <th>Slogans</th>\n",
       "      <th>Flag_Waving</th>\n",
       "      <th>Doubt</th>\n",
       "      <th>Whataboutism</th>\n",
       "      <th>Appeal_to_Fear-Prejudice</th>\n",
       "      <th>Causal_Oversimplification</th>\n",
       "      <th>Appeal_to_Hypocrisy</th>\n",
       "      <th>Appeal_to_Popularity</th>\n",
       "      <th>Appeal_to_Authority</th>\n",
       "      <th>Straw_Man</th>\n",
       "      <th>Guilt_by_Association</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   False_Dilemma-No_Choice  Loaded_Language  Name_Calling-Labeling  \\\n",
       "0                        1                1                      0   \n",
       "1                        1                1                      1   \n",
       "2                        0                0                      0   \n",
       "3                        0                0                      0   \n",
       "4                        0                0                      0   \n",
       "\n",
       "   Conversation_Killer  Red_Herring  Obfuscation-Vagueness-Confusion  \\\n",
       "0                    0            0                                0   \n",
       "1                    0            0                                0   \n",
       "2                    1            0                                0   \n",
       "3                    1            1                                0   \n",
       "4                    0            0                                1   \n",
       "\n",
       "   Exaggeration-Minimisation  Repetition  Slogans  Flag_Waving  Doubt  \\\n",
       "0                          0           0        0            0      0   \n",
       "1                          0           0        0            0      0   \n",
       "2                          0           0        0            0      0   \n",
       "3                          0           0        0            0      0   \n",
       "4                          0           0        0            0      0   \n",
       "\n",
       "   Whataboutism  Appeal_to_Fear-Prejudice  Causal_Oversimplification  \\\n",
       "0             0                         0                          0   \n",
       "1             0                         0                          0   \n",
       "2             0                         0                          0   \n",
       "3             0                         0                          0   \n",
       "4             0                         0                          0   \n",
       "\n",
       "   Appeal_to_Hypocrisy  Appeal_to_Popularity  Appeal_to_Authority  Straw_Man  \\\n",
       "0                    0                     0                    0          0   \n",
       "1                    0                     0                    0          0   \n",
       "2                    0                     0                    0          0   \n",
       "3                    0                     0                    0          0   \n",
       "4                    0                     0                    0          0   \n",
       "\n",
       "   Guilt_by_Association  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 1120)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\elias\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] Die angegebene Prozedur wurde nicht gefunden\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\elias\\AppData\\Local\\Temp\\tmpt9i9kftq\\config.json as plain json\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "from allennlp_models.structured_prediction.models import srl_bert\n",
    "\n",
    "# Load the SRL predictor\n",
    "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def extract_srl_components(article, predictor):\n",
    "    \"\"\"\n",
    "    Extract SRL components for an article.\n",
    "    \"\"\"\n",
    "    srl = predictor.predict(sentence=article)\n",
    "    \n",
    "    extracted_data = []\n",
    "    for verb_entry in srl['verbs']:\n",
    "        predicate = verb_entry['verb']\n",
    "        tags = verb_entry['tags']\n",
    "        \n",
    "        arg0_indices = [i for i, tag in enumerate(tags) if tag in ['B-ARG0', 'I-ARG0']]\n",
    "        arg1_indices = [i for i, tag in enumerate(tags) if tag in ['B-ARG1', 'I-ARG1']]\n",
    "        \n",
    "        arg0 = [srl['words'][i] for i in arg0_indices] if arg0_indices else []\n",
    "        arg1 = [srl['words'][i] for i in arg1_indices] if arg1_indices else []\n",
    "        \n",
    "        extracted_data.append({\n",
    "            'predicate': [predicate],\n",
    "            'ARG0': arg0,\n",
    "            'ARG1': arg1\n",
    "        })\n",
    "        \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'predicate': ['turned'], 'ARG0': [], 'ARG1': ['The', 'red', 'horse']},\n",
       " {'predicate': ['fought'],\n",
       "  'ARG0': ['The', 'red', 'horse'],\n",
       "  'ARG1': ['the', 'fly']}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_srl_components(\"The red horse simply turned around and fought off the fly with its tail.\", predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_member(a, b):\n",
    "    a_set = set(a)\n",
    "    b_set = set(b)\n",
    "    if a_set & b_set:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested_tags_list = [\"B-V\", \"B-ARGM-MOD\", \"B-ARGM-DIR\", \"B-ARGM-NEG\", 'B-ARG0', 'B-ARG1', \"B-ARG2\", \"B-ARG3\",\n",
    "                        \"B-ARG4\"]\n",
    "from collections import defaultdict\n",
    "def get_predicate_span_tags_dict(tags):\n",
    "    # Initial Structure of span_tags_dict: {\"B-V\": [(30, 31)], \"B-ARG2\": [(28,28), (32,40),...]}\n",
    "    predicate_span_tags_dict = defaultdict(list)\n",
    "    i = 0\n",
    "    while i < len(tags):\n",
    "        if tags[i] in interested_tags_list:\n",
    "            start_index = i\n",
    "            i += 1\n",
    "            while i < len(tags) and tags[i][0] == 'I':\n",
    "                i += 1\n",
    "            end_index = i - 1\n",
    "            predicate_span_tags_dict[tags[start_index]].append((start_index, end_index))\n",
    "            continue\n",
    "        else:\n",
    "            i += 1\n",
    "    return predicate_span_tags_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "real_args_list = ['B-ARG0', 'B-ARG1', \"B-ARG2\", \"B-ARG3\", \"B-ARG4\"]\n",
    "\n",
    "def process_srl_sents_for_one_doc(srl_doc):\n",
    "    doc_words = list()\n",
    "\n",
    "    doc_span_tags = list()\n",
    "    for srl_sent in srl_doc:\n",
    "        sent_span_tags = list()\n",
    "        for srl_verb in srl_sent['verbs']:\n",
    "            tags = srl_verb['tags']\n",
    "            predicate_span_tags_dict = get_predicate_span_tags_dict(tags)\n",
    "\n",
    "            # Pattern 1: The srl unit should have verb present\n",
    "            if \"B-V\" not in predicate_span_tags_dict.keys():\n",
    "                continue\n",
    "            # Pattern 2: If there are more than one verb, choose the first one for now.\n",
    "            if len(predicate_span_tags_dict['B-V']) > 1:\n",
    "                predicate_span_tags_dict['B-V'] = [predicate_span_tags_dict['B-V'][0]]\n",
    "            # Pattern 3: The srl unit should have at least one real arg\n",
    "            if not common_member(list(predicate_span_tags_dict.keys()), real_args_list):\n",
    "                continue\n",
    "            # Pattern 4: If there are more than one particular type of arg, choose the one closest to the verb:\n",
    "            # E.G. [ARG1: UNCLE SAM] [ARGM-MOD: CAN'T] [V: TURN] [ARGM-DIR: BACK] [ARG1: ON LEGAL U.S. IMMIGRANTS] .\n",
    "            assert len(predicate_span_tags_dict['B-V']) == 1\n",
    "            appro_verb_pos = int((predicate_span_tags_dict['B-V'][0][0] + predicate_span_tags_dict['B-V'][0][1]) / 2)\n",
    "            for tag, poss in predicate_span_tags_dict.items():\n",
    "                if len(poss) > 1:\n",
    "                    appro_poss = [int((pos[0] + pos[1]) / 2) for pos in poss]\n",
    "                    appro_diff_from_verb = [abs(appro_pos - appro_verb_pos) for appro_pos in appro_poss]\n",
    "                    index = np.where(appro_diff_from_verb == np.amin(\n",
    "                        appro_diff_from_verb))  # The returned index is a tuple (array([0, 2]),)\n",
    "                    predicate_span_tags_dict[tag] = [predicate_span_tags_dict[tag][index[0][0]]]\n",
    "\n",
    "            sent_span_tags.append(predicate_span_tags_dict)\n",
    "        if len(sent_span_tags) > 0:\n",
    "            doc_span_tags.append(sent_span_tags)\n",
    "            sent_words = srl_sent['words']\n",
    "            doc_words.append(sent_words)\n",
    "    # for each doc\n",
    "    return doc_words, doc_span_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbs': [{'verb': 'guess',\n",
       "   'description': 'Michael Swadling : [ARG0: I] [V: guess] [ARG1: her only chance is if Labour decides that they want to dishonour democracy and effectively keep us in the EU] .',\n",
       "   'tags': ['O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-ARG0',\n",
       "    'B-V',\n",
       "    'B-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'O']},\n",
       "  {'verb': 'is',\n",
       "   'description': 'Michael Swadling : I guess [ARG1: her only chance] [V: is] [ARG2: if Labour decides that they want to dishonour democracy and effectively keep us in the EU] .',\n",
       "   'tags': ['O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'B-V',\n",
       "    'B-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'O']},\n",
       "  {'verb': 'decides',\n",
       "   'description': 'Michael Swadling : I guess her only chance is if [ARG0: Labour] [V: decides] [ARG1: that they want to dishonour democracy and effectively keep us in the EU] .',\n",
       "   'tags': ['O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-ARG0',\n",
       "    'B-V',\n",
       "    'B-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'O']},\n",
       "  {'verb': 'want',\n",
       "   'description': 'Michael Swadling : I guess her only chance is if Labour decides that [ARG0: they] [V: want] [ARG1: to dishonour democracy and effectively keep us in the EU] .',\n",
       "   'tags': ['O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-ARG0',\n",
       "    'B-V',\n",
       "    'B-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'O']},\n",
       "  {'verb': 'dishonour',\n",
       "   'description': 'Michael Swadling : I guess her only chance is if Labour decides that [ARG0: they] want to [V: dishonour] [ARG1: democracy] and effectively keep us in the EU .',\n",
       "   'tags': ['O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-ARG0',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-V',\n",
       "    'B-ARG1',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O']},\n",
       "  {'verb': 'keep',\n",
       "   'description': 'Michael Swadling : I guess her only chance is if Labour decides that [ARG0: they] want to dishonour democracy and [ARGM-MNR: effectively] [V: keep] [ARG1: us] [ARG2: in the EU] .',\n",
       "   'tags': ['O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-ARG0',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-ARGM-MNR',\n",
       "    'B-V',\n",
       "    'B-ARG1',\n",
       "    'B-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'O']}],\n",
       " 'words': ['Michael',\n",
       "  'Swadling',\n",
       "  ':',\n",
       "  'I',\n",
       "  'guess',\n",
       "  'her',\n",
       "  'only',\n",
       "  'chance',\n",
       "  'is',\n",
       "  'if',\n",
       "  'Labour',\n",
       "  'decides',\n",
       "  'that',\n",
       "  'they',\n",
       "  'want',\n",
       "  'to',\n",
       "  'dishonour',\n",
       "  'democracy',\n",
       "  'and',\n",
       "  'effectively',\n",
       "  'keep',\n",
       "  'us',\n",
       "  'in',\n",
       "  'the',\n",
       "  'EU',\n",
       "  '.']}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srls = predictor.predict(sentence=X[0])\n",
    "srls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['The',\n",
       "   'red',\n",
       "   'horse',\n",
       "   'simply',\n",
       "   'turned',\n",
       "   'around',\n",
       "   'and',\n",
       "   'fought',\n",
       "   'off',\n",
       "   'the',\n",
       "   'fly',\n",
       "   'with',\n",
       "   'its',\n",
       "   'tail']],\n",
       " [[defaultdict(list,\n",
       "               {'B-ARG1': [(0, 2)], 'B-V': [(4, 4)], 'B-ARGM-DIR': [(5, 5)]}),\n",
       "   defaultdict(list,\n",
       "               {'B-ARG0': [(0, 2)],\n",
       "                'B-V': [(7, 7)],\n",
       "                'B-ARG1': [(9, 10)],\n",
       "                'B-ARG2': [(11, 13)]})]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_srl_sents_for_one_doc([srls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Michael Swadling: I guess her only chance is if Labour decides that they want to dishonour democracy and effectively keep us in the EU.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_article = X[0]\n",
    "test_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extract_srl_components(test_article, predictor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SRL embeddings for each article\n",
    "srl_embeddings = [extract_srl_components(article, predictor) for article in X[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'predicate': ['guess'],\n",
       "  'ARG0': ['I'],\n",
       "  'ARG1': ['her',\n",
       "   'only',\n",
       "   'chance',\n",
       "   'is',\n",
       "   'if',\n",
       "   'Labour',\n",
       "   'decides',\n",
       "   'that',\n",
       "   'they',\n",
       "   'want',\n",
       "   'to',\n",
       "   'dishonour',\n",
       "   'democracy',\n",
       "   'and',\n",
       "   'effectively',\n",
       "   'keep',\n",
       "   'us',\n",
       "   'in',\n",
       "   'the',\n",
       "   'EU']},\n",
       " {'predicate': ['is'], 'ARG0': [], 'ARG1': ['her', 'only', 'chance']},\n",
       " {'predicate': ['decides'],\n",
       "  'ARG0': ['Labour'],\n",
       "  'ARG1': ['that',\n",
       "   'they',\n",
       "   'want',\n",
       "   'to',\n",
       "   'dishonour',\n",
       "   'democracy',\n",
       "   'and',\n",
       "   'effectively',\n",
       "   'keep',\n",
       "   'us',\n",
       "   'in',\n",
       "   'the',\n",
       "   'EU']},\n",
       " {'predicate': ['want'],\n",
       "  'ARG0': ['they'],\n",
       "  'ARG1': ['to',\n",
       "   'dishonour',\n",
       "   'democracy',\n",
       "   'and',\n",
       "   'effectively',\n",
       "   'keep',\n",
       "   'us',\n",
       "   'in',\n",
       "   'the',\n",
       "   'EU']},\n",
       " {'predicate': ['dishonour'], 'ARG0': ['they'], 'ARG1': ['democracy']},\n",
       " {'predicate': ['keep'], 'ARG0': ['they'], 'ARG1': ['us']}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srl_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\elias\\OneDrive\\Dokumente\\Git\\MasterThesis\\notebooks\\friss-frameaxis-SPAN-LEVEL.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# transform the list of dicts to 3 lists\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m predicates \u001b[39m=\u001b[39m [srl\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mpredicate\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m srl \u001b[39min\u001b[39;00m srl_embeddings]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m arg0s \u001b[39m=\u001b[39m [srl\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mARG0\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m srl \u001b[39min\u001b[39;00m srl_embeddings]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m arg1s \u001b[39m=\u001b[39m [srl\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mARG1\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m srl \u001b[39min\u001b[39;00m srl_embeddings]\n",
      "\u001b[1;32mc:\\Users\\elias\\OneDrive\\Dokumente\\Git\\MasterThesis\\notebooks\\friss-frameaxis-SPAN-LEVEL.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# transform the list of dicts to 3 lists\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m predicates \u001b[39m=\u001b[39m [srl\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39m\u001b[39mpredicate\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m srl \u001b[39min\u001b[39;00m srl_embeddings]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m arg0s \u001b[39m=\u001b[39m [srl\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mARG0\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m srl \u001b[39min\u001b[39;00m srl_embeddings]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m arg1s \u001b[39m=\u001b[39m [srl\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mARG1\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m srl \u001b[39min\u001b[39;00m srl_embeddings]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# transform the list of dicts to 3 lists\n",
    "predicates = [srl.get(\"predicate\", \"\") for srl in srl_embeddings]\n",
    "arg0s = [srl.get(\"ARG0\", \"\") for srl in srl_embeddings]\n",
    "arg1s = [srl.get('ARG1') for srl in srl_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_to_wordwise_embeddings(strings_list):\n",
    "    all_embeddings = []\n",
    "\n",
    "    for s in strings_list:\n",
    "        # If none, return empty embedding\n",
    "        if s is None:\n",
    "            all_embeddings.append([torch.zeros(768, device=device)])\n",
    "            continue\n",
    "        \n",
    "        word_embeddings = []\n",
    "\n",
    "        # Split the string into words\n",
    "        words = s.split()\n",
    "\n",
    "        # Tokenize and get embeddings for each word\n",
    "        for word in words:\n",
    "            inputs = tokenizer(word, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "            \n",
    "            word_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().detach()\n",
    "            word_embeddings.append(word_embedding)\n",
    "\n",
    "        all_embeddings.append(word_embeddings)\n",
    "\n",
    "    return all_embeddings\n",
    "\n",
    "# Note: This refactored function assumes that the tokenizer and model are already defined and loaded in the global scope.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 8.7686e-02, -1.7619e-01, -2.0995e-01,  6.3118e-02, -2.5592e-02,\n",
       "         -1.2145e-01,  2.6319e-01, -1.0966e-01,  1.7178e-01, -3.7934e-01,\n",
       "         -2.1645e-01,  6.7345e-02,  4.3943e-02, -5.4717e-03, -2.2551e-01,\n",
       "         -2.2371e-01,  1.8952e-02,  3.3047e-02, -7.3294e-02,  1.3794e-01,\n",
       "          1.1153e-01,  1.0966e-01,  1.2979e-01,  1.1445e-01,  7.3667e-02,\n",
       "          3.7715e-01, -2.8807e-01, -1.8478e-01, -4.0824e-01,  1.0867e-01,\n",
       "         -1.3929e-01, -2.7609e-01, -8.6871e-03,  3.9589e-01, -2.2685e-01,\n",
       "         -1.4674e-01, -8.6000e-03, -9.9858e-02, -3.7821e-01, -1.4144e-01,\n",
       "         -6.5044e-02, -8.4578e-02,  1.3387e-01, -9.6754e-02, -9.9444e-02,\n",
       "          6.1538e-02, -3.3527e-01,  7.5753e-02, -1.0591e-01,  3.1784e-01,\n",
       "         -2.7297e-01,  2.2933e-01,  2.7825e-02,  4.5593e-01,  6.9887e-02,\n",
       "          8.5220e-05,  3.1045e-01,  1.2441e-01, -2.5211e-01, -2.7717e-01,\n",
       "          2.7479e-01,  1.8580e-01, -4.0700e-02, -5.0711e-04,  2.2583e-01,\n",
       "          4.4431e-02,  3.6134e-01, -2.7713e-01, -3.5400e-01,  2.6072e-01,\n",
       "         -1.4478e-01, -2.7009e-01,  2.5298e-01, -2.5702e-01,  2.7503e-01,\n",
       "          2.7323e-02,  4.1812e-02,  3.3041e-01,  3.1695e-01,  2.8906e-02,\n",
       "          1.6804e-01,  1.4391e-01,  4.1791e-02,  3.2218e-01, -5.4848e-02,\n",
       "          8.1304e-02, -4.7497e-02,  1.3945e-02, -3.2880e-01,  6.9566e-02,\n",
       "          7.0716e-02,  6.0298e-02,  1.5134e-01, -2.2589e-02,  2.8664e-02,\n",
       "         -1.0149e-01, -7.6728e-02,  2.3542e-02,  1.3628e-01, -3.4628e-01,\n",
       "         -2.7619e-01, -3.7677e-01, -2.3987e-02,  3.5267e-01, -2.7230e-01,\n",
       "          8.5194e-02, -1.4563e-01,  5.9848e-02,  4.8426e-02, -8.6826e-01,\n",
       "          3.6443e-01,  1.4588e-01,  1.4476e-01, -9.3457e-02, -4.6052e-02,\n",
       "          1.3503e-01,  1.7436e-01,  1.0563e-01,  2.4370e-01,  2.1810e-01,\n",
       "         -3.1100e-01, -7.4800e-02,  9.1031e-02,  5.2893e-01,  6.5468e-02,\n",
       "          2.0657e-01, -2.0368e-01, -5.9095e-01, -3.1052e-01, -3.7666e-01,\n",
       "         -2.1435e-01,  3.8374e-01,  1.7664e-01,  3.9521e-01, -1.3355e-01,\n",
       "          4.5213e-02, -1.7406e-02, -8.7551e-02, -1.4900e-01, -1.7254e-02,\n",
       "          6.7327e-02,  4.8654e-01, -1.1383e+00, -1.8860e-01,  8.8951e-02,\n",
       "         -1.5819e-01,  2.5678e-01, -4.7415e-02,  1.8601e-01, -3.1896e-02,\n",
       "          2.5599e-01,  1.7793e-01, -3.8569e-01, -3.2504e-01, -2.5309e-01,\n",
       "         -2.0808e-01,  4.3815e-02,  4.7323e-02,  1.7206e-01,  4.0548e-01,\n",
       "          2.1608e-01,  3.0684e-01,  1.1828e-01,  2.8239e-01, -1.1187e-01,\n",
       "         -1.3330e-01, -2.9016e-01,  6.8539e-01,  3.3857e-01,  8.0470e-03,\n",
       "         -3.0309e-01, -3.0370e-01,  2.9498e-01,  2.8861e-01, -4.2889e-01,\n",
       "          3.4693e-01,  3.4337e-01,  2.3554e-01, -2.6614e-02, -1.3505e-01,\n",
       "         -2.8109e+00,  1.6229e-01, -1.8126e-01, -2.1535e-01,  2.7510e-02,\n",
       "         -6.3795e-02,  1.1123e-01, -3.1828e-01,  4.1948e-01, -2.5166e-01,\n",
       "         -2.3471e-01, -2.0032e-01, -2.1014e-01,  1.0748e-01,  2.6559e-01,\n",
       "         -2.0176e-01,  3.7738e-02,  4.5510e-02,  3.8764e-01, -3.1556e-02,\n",
       "          2.4890e-01, -5.6408e-02,  3.7724e-01,  2.0803e-01,  2.4280e-02,\n",
       "          1.1005e+00,  7.7247e-02, -2.5690e-01,  1.4572e-01,  1.1276e-01,\n",
       "         -5.5257e-01,  5.6251e-01,  2.1541e-01, -4.1564e-01,  3.2553e-01,\n",
       "         -1.8708e-01,  2.7888e-01, -2.7437e-01, -2.6017e-01,  4.0683e-02,\n",
       "          8.4123e-02, -1.0307e-01, -3.5565e-02,  4.7743e-03, -1.7084e-01,\n",
       "         -4.0103e-01,  2.8793e-01, -2.2359e-02,  1.3946e-01, -1.9529e-01,\n",
       "         -2.5176e-01, -3.0510e-01,  1.9501e-01,  1.9158e-01, -1.1784e-01,\n",
       "          1.9147e-01,  2.0147e-01,  1.0114e-01, -1.2328e-01, -9.1714e-02,\n",
       "         -4.7974e-02,  1.5342e-01,  3.1199e-01,  2.1877e-01, -3.3148e-01,\n",
       "          4.5770e-02,  4.0264e-01,  4.7508e-02,  3.9333e-01, -1.3966e-01,\n",
       "         -1.5208e-01, -3.7776e-01, -1.8682e-02, -1.4403e-01, -1.0283e-01,\n",
       "          6.2806e-02, -8.4946e-02, -1.6570e-01,  4.8609e-01,  6.9195e-02,\n",
       "          1.5043e-01,  1.0987e-01,  4.7406e-01, -6.1482e-02, -3.2931e-02,\n",
       "          4.9852e-01,  2.1976e-01, -9.9245e-03, -1.1284e-01,  1.9897e-01,\n",
       "          7.0570e-02, -7.7556e-02, -2.2557e-02, -1.4382e+00, -1.6824e-02,\n",
       "         -2.2841e-01,  2.9575e-01,  1.2383e-01,  1.9651e-01,  3.2797e-02,\n",
       "         -2.6104e-01,  6.1896e-02,  7.1147e-02,  9.5623e-02,  4.6336e-01,\n",
       "         -4.1794e-01, -2.3037e-01, -3.8821e-01,  2.7430e-01, -3.5876e-01,\n",
       "         -6.6045e-02,  1.4851e-01,  2.0788e-01,  5.1817e-03,  1.8624e-01,\n",
       "          4.6446e-03,  7.7202e-03,  2.0900e-01, -5.2530e-01, -1.1094e-01,\n",
       "          4.0441e-02, -1.4382e-01, -8.4898e-02, -1.9751e-01,  1.8410e-01,\n",
       "          1.5707e-01,  3.7846e-02,  1.9173e-01, -2.1234e+00, -3.2835e-01,\n",
       "          2.3912e-01, -4.7612e-01,  1.2410e-01, -9.5117e-02, -1.4214e-02,\n",
       "         -6.0135e-02, -1.0043e-01, -6.0500e-03,  2.9858e-01, -2.0512e-01,\n",
       "          1.8577e-01,  2.5646e-01,  5.4734e-02, -1.4196e-01, -3.3389e-01,\n",
       "         -5.6813e-02, -5.3281e-01,  2.7022e-02, -1.2607e-01, -5.7086e-03,\n",
       "          3.2321e-01, -1.7603e-01,  8.8825e-02,  1.3926e-01, -3.9223e-01,\n",
       "          2.4983e-01, -3.4251e-01, -4.2311e-02, -2.1311e-01, -3.1172e-01,\n",
       "         -1.9113e-01,  1.5443e-01,  1.2418e-01,  1.3219e-01,  2.3651e-01,\n",
       "          1.0350e-01,  8.4956e-01, -1.5944e-01,  2.4109e-01,  2.0948e-01,\n",
       "          1.0570e-01, -1.2275e-01, -1.0134e-01, -1.5272e-01,  2.3468e-01,\n",
       "         -3.2509e-01,  4.0128e-02,  6.8137e-02,  2.0530e-01, -1.9721e-01,\n",
       "          1.2551e-01, -1.1132e-01, -6.6323e-02, -1.5432e-01,  7.1167e-02,\n",
       "          2.5560e-01,  4.2154e-02, -2.8970e-01,  5.3296e-02, -1.3594e-01,\n",
       "          2.3635e-01,  3.4010e-01, -6.6886e-01,  4.2932e-02, -1.1719e-02,\n",
       "          9.0573e-02,  1.4716e-01, -5.6695e-02, -1.0253e-01, -2.8969e-01,\n",
       "          2.5444e-02, -7.7265e-01, -4.1531e-01,  2.3959e-01, -3.7382e-01,\n",
       "          4.6654e-02,  3.4400e-01, -2.2508e-01,  2.6567e-02,  3.2994e-02,\n",
       "          2.4601e-01,  1.7908e-01,  8.1465e-02,  1.9661e-01,  1.4443e-01,\n",
       "         -2.9560e-01,  6.0544e-02, -1.7523e-01,  9.4455e-02,  5.4418e-02,\n",
       "          1.8067e-02,  1.4766e-01,  2.5372e-01,  1.9198e-01,  3.4107e-01,\n",
       "         -2.8251e-01,  1.0138e-01,  1.8213e-01, -2.2003e-01, -2.6694e-01,\n",
       "         -6.0458e-02,  2.4739e-03, -3.4166e-04,  1.2942e-01, -5.3107e-01,\n",
       "         -1.4005e-01, -1.7931e-01, -1.9629e-01,  2.8089e-01, -1.1286e-01,\n",
       "          2.4937e-01,  2.4228e-01,  1.7693e-01, -8.6983e-02, -1.3085e-01,\n",
       "         -2.8885e-02, -1.5635e-01,  2.4187e-01,  6.2736e-02,  3.0357e-01,\n",
       "          1.8376e-01,  2.7036e-01,  3.0895e-02,  5.1434e-02, -4.4973e-03,\n",
       "         -3.5091e-01, -3.0648e-01,  1.1878e-01,  1.9670e-01,  8.7217e-03,\n",
       "          1.5703e-01, -3.9555e-01, -2.9173e-01,  1.4956e-01,  1.9495e-01,\n",
       "          4.6437e-01,  1.1317e-01,  2.8999e-01,  4.4560e-01,  1.2939e-01,\n",
       "         -3.9721e-01,  1.3888e-02,  1.6032e-01,  2.9096e-01, -2.0764e-01,\n",
       "          1.9911e-01,  3.9318e-01,  2.7389e-01,  2.7237e-01, -2.5032e-01,\n",
       "          4.0475e-01, -6.5141e-02, -1.6029e-01, -2.2381e-01,  9.6608e-02,\n",
       "         -1.9011e-01, -4.0616e-01,  3.2070e-01, -1.2165e-01, -2.1806e-02,\n",
       "         -5.5410e-03,  1.4547e-01,  9.7962e-03, -4.7295e-02,  2.7703e-02,\n",
       "          6.7633e-03, -2.9149e-01,  8.7302e-02,  5.1233e-01, -2.4582e-01,\n",
       "          1.5048e-01,  8.6349e-02, -2.0529e-01,  1.5105e-01,  3.7374e-02,\n",
       "         -3.5408e-01, -5.0277e-02, -4.9204e-02,  6.6620e-02, -1.8066e-01,\n",
       "          1.4122e-01, -9.7434e-02,  2.4643e-01,  6.1549e-02, -4.6078e-01,\n",
       "         -3.9569e-01,  1.2143e-01,  4.9012e-01,  2.1675e-01, -4.7200e-01,\n",
       "         -1.9612e-01, -9.7382e-02, -5.9920e-02,  1.6872e-01,  2.6703e-01,\n",
       "          1.8263e-02,  3.6852e-02,  3.7883e-01,  2.8278e-01, -2.7710e-01,\n",
       "         -3.9369e-01,  6.3239e-03, -1.5128e-01, -1.1087e-02,  5.7789e-02,\n",
       "          2.4100e-01, -4.3619e-01, -3.7082e-01,  2.6121e-01, -1.1369e-01,\n",
       "         -2.3560e-01, -1.7523e-01,  2.4152e-03,  3.6764e-01,  1.7591e-01,\n",
       "          2.0897e-01,  3.8461e-01, -3.0874e-01, -3.1623e-01, -1.6589e-01,\n",
       "          2.6035e-02,  1.3330e-01,  3.7436e-01, -3.0998e-02, -2.7991e-01,\n",
       "         -3.7746e-01,  1.2415e-01,  7.4820e-02,  1.2745e-01,  2.2448e-01,\n",
       "         -2.1353e-01, -1.3168e-02,  2.5499e-01,  8.3236e-02, -4.5469e-01,\n",
       "          9.9492e-02, -2.6429e-01, -1.7165e-01, -5.3105e-02, -4.2513e-01,\n",
       "         -5.4215e-01,  7.0679e-02, -4.4001e-02, -6.1316e-02,  1.8771e-01,\n",
       "          4.3827e-01,  4.0729e-01,  3.1940e-01, -1.7890e-01, -2.0898e-01,\n",
       "          2.7152e-01, -6.4395e-03, -7.2077e-02, -6.4284e-01, -1.1446e-01,\n",
       "          7.4661e-02,  1.8315e-01, -5.4607e-02, -1.3635e-01,  2.1886e-01,\n",
       "          1.7087e-01, -2.2297e-01, -7.2412e-02,  9.8143e-03,  1.7588e-02,\n",
       "         -1.2254e-01,  2.6346e-01,  4.6416e-01, -9.8890e-02,  2.7692e-01,\n",
       "         -1.7182e-01,  3.5039e-01, -2.2215e-01,  3.0314e-02,  1.5501e-01,\n",
       "         -2.3266e-01, -4.2806e-01,  1.3442e-01,  1.1064e+00,  4.7731e-01,\n",
       "         -2.5230e-01, -1.0625e-01,  2.0979e-01, -3.2569e-01,  1.3019e-01,\n",
       "          5.4621e-02, -1.1422e-01, -6.1602e-01,  1.4730e-01, -8.1084e-02,\n",
       "         -8.7363e-02,  1.4726e-01, -1.7397e-01,  1.8705e-01, -2.6983e-01,\n",
       "          3.1521e-01, -3.0938e-01, -6.7600e-02,  3.2012e-02,  8.6505e-02,\n",
       "         -8.8145e-02, -1.1527e-01, -2.2030e-01,  2.1616e-01,  1.1144e-01,\n",
       "         -1.4338e-01,  6.6706e-02, -9.2104e-02, -4.8933e-01, -7.0988e-02,\n",
       "          1.8580e-01,  4.0104e-01, -6.6094e-01,  7.2767e-02, -8.5062e-02,\n",
       "         -7.0616e-01,  1.1655e-01,  2.1834e-01,  5.2112e-02, -6.1337e-02,\n",
       "          4.2179e-01,  2.6918e-01,  2.8476e-01,  1.7339e-01, -3.6007e-01,\n",
       "         -1.8460e-01, -2.1274e-01,  1.1453e-01,  4.3110e-01,  2.1243e-01,\n",
       "         -6.1476e-02,  3.8990e-01,  7.8446e-02, -2.2109e-01,  3.2120e-01,\n",
       "         -5.8969e-02, -1.5332e-01, -4.1843e-01,  4.2470e-02, -1.1846e-01,\n",
       "          9.7003e-02,  2.2970e-02, -1.6828e-01, -7.9901e-02,  2.7353e-01,\n",
       "         -9.2537e-02, -3.6732e-03,  2.0021e-01, -1.1123e-01, -2.6055e-01,\n",
       "         -4.0585e-01,  5.3710e-02, -2.8003e-01, -9.2940e-02,  1.6167e-01,\n",
       "          1.1964e-01, -3.2361e-01, -1.0994e+00,  1.7951e-01, -1.2642e-01,\n",
       "         -1.5111e-01, -4.3392e-02,  7.5903e-02,  4.4052e-01,  1.6096e-01,\n",
       "         -3.6646e-01, -1.5733e-01, -1.5646e-01,  3.4156e-01,  2.0232e-01,\n",
       "          2.0095e-02, -4.3030e-03, -4.7297e-03,  4.8656e-02, -1.4480e-01,\n",
       "          4.8556e-01, -4.5163e-01, -5.1741e-02, -5.5352e-02, -7.5987e-02,\n",
       "         -8.0837e-03,  5.1694e-02,  6.0797e-01, -5.7168e-01, -1.2733e-01,\n",
       "          9.9710e-02,  9.6705e-02, -4.0947e-02,  2.6292e-01, -1.8757e-01,\n",
       "         -2.9609e-02, -1.5179e-01,  1.9930e-01,  1.7565e-01,  2.2963e-01,\n",
       "         -1.5006e-01,  3.7952e-01,  3.8300e-01,  4.4286e-01, -4.3082e-02,\n",
       "         -2.3330e-01, -2.6152e-02, -2.4828e-01,  7.6365e-02,  5.4445e-01,\n",
       "         -2.2517e-01, -1.7276e-02, -4.8816e-01,  3.6263e-02,  1.2225e-01,\n",
       "         -1.2527e+00,  2.7209e-01, -7.5234e-02, -5.1923e-02, -2.6617e-02,\n",
       "          1.0327e-01,  1.4463e-01, -3.6380e-01, -2.7799e-01, -1.3293e-01,\n",
       "          8.5219e-02, -3.1069e-02, -1.0464e-01, -4.9737e-03, -5.2192e-01,\n",
       "          2.7477e-01,  9.3443e-02,  2.8383e-02,  7.6981e-02,  3.0021e-01,\n",
       "         -1.1475e-01,  1.5989e-01,  8.1920e-02, -4.1379e-01, -1.0560e-01,\n",
       "         -1.2544e-01, -4.7945e-02, -6.2601e-02, -2.5696e-01,  1.6989e-02,\n",
       "         -3.1683e-02, -2.4783e-01, -2.9991e+00, -3.0037e-02,  1.2054e-01,\n",
       "         -1.8490e-02,  7.0461e-02, -1.8302e-01,  4.7387e-01, -2.5567e-02,\n",
       "         -3.2687e-02, -2.0972e-01,  1.8047e-02, -4.3475e-01,  1.5617e-01,\n",
       "          9.4240e-02, -2.0388e-01, -1.3669e-01]),\n",
       " tensor([ 2.3950e-01,  9.3166e-02, -3.4383e-01, -1.1932e-01, -1.5680e-01,\n",
       "         -2.4416e-02,  2.3234e-01, -1.0008e-02, -4.6964e-02, -3.6022e-01,\n",
       "         -2.2805e-01,  1.2904e-02,  3.5516e-02,  3.5496e-01, -2.7296e-02,\n",
       "          8.4738e-02,  1.0316e-01,  3.2289e-01, -9.7702e-02,  1.3748e-01,\n",
       "          3.3596e-01, -1.0633e-01,  4.7621e-02,  5.1823e-02,  1.6067e-01,\n",
       "          2.6252e-01, -3.4381e-01, -2.8353e-01,  1.2903e-02,  5.4658e-02,\n",
       "         -2.3082e-02, -3.0229e-01,  1.0115e-01,  3.9645e-01,  9.7777e-02,\n",
       "         -2.7036e-01, -2.0911e-03, -1.1967e-01, -3.9564e-01, -9.1860e-02,\n",
       "         -3.4332e-01, -1.8933e-01,  1.8473e-01, -2.4838e-01,  4.8106e-01,\n",
       "         -2.6298e-02, -5.5369e-02, -1.0458e-01,  2.2758e-03,  1.7154e-01,\n",
       "         -2.7773e-01,  1.4517e-01, -9.5326e-02,  2.7245e-01, -7.6464e-02,\n",
       "          2.3123e-01,  2.1803e-01,  2.3670e-01, -2.6166e-01, -2.6857e-01,\n",
       "          1.4178e-01, -8.2611e-02, -2.3447e-01,  8.8565e-02,  1.8722e-01,\n",
       "          2.4608e-01,  1.0658e-01, -3.6867e-02, -5.5896e-01,  3.3299e-01,\n",
       "         -1.3858e-01, -2.3246e-01,  4.6670e-01, -2.3100e-01,  2.4597e-01,\n",
       "          2.4926e-02, -3.9186e-01,  1.7866e-01,  2.8078e-02, -8.9596e-02,\n",
       "          2.9543e-01,  7.6295e-02,  4.1753e-01,  2.4414e-01,  1.6934e-01,\n",
       "          2.1953e-01,  1.3937e-02, -2.7809e-01,  5.8449e-02,  2.3290e-01,\n",
       "         -3.0103e-01,  6.2860e-02,  2.0742e-01,  2.3073e-01,  1.6553e-01,\n",
       "         -2.4709e-01, -1.6934e-01, -1.9813e-02,  9.9731e-02, -1.7392e-01,\n",
       "         -9.7246e-02, -5.1582e-01,  1.1947e-01,  3.8226e-01, -3.8289e-01,\n",
       "          2.1008e-01, -7.8696e-02,  4.8807e-02,  2.7913e-01, -5.8375e-01,\n",
       "          3.8366e-01,  2.6607e-02, -4.5617e-02, -2.2154e-02, -2.5961e-01,\n",
       "          3.8033e-01, -1.4428e-02,  4.0438e-01,  2.3968e-01,  1.9516e-01,\n",
       "         -3.8168e-01, -2.2369e-01,  1.4410e-02,  6.3725e-01, -8.8987e-03,\n",
       "          3.5368e-01, -1.5377e-01, -4.8193e-01,  8.2036e-02, -2.1574e-01,\n",
       "         -3.9606e-03,  3.6528e-01,  2.3433e-02,  5.0184e-01, -2.7811e-01,\n",
       "         -5.6152e-02,  3.1142e-02,  8.0397e-03, -2.4556e-01, -3.1736e-01,\n",
       "         -1.0868e-01,  3.0221e-01, -9.6464e-01, -3.4066e-01,  2.8623e-01,\n",
       "         -3.0791e-02,  4.3792e-01,  1.9969e-01,  3.5882e-01, -3.3689e-02,\n",
       "          1.2085e-01,  3.1833e-03, -2.5934e-01, -4.1386e-02, -5.1388e-01,\n",
       "         -9.1213e-02, -8.5893e-02,  5.5472e-02,  4.8634e-01,  4.9097e-01,\n",
       "          3.4548e-01,  2.3205e-01,  2.9065e-01,  9.8031e-02, -3.4001e-01,\n",
       "         -3.5633e-02, -3.9704e-01,  4.2852e-01,  1.7402e-01,  4.8823e-02,\n",
       "         -2.8342e-01, -5.0631e-01,  4.3850e-01,  2.4562e-01,  2.1804e-01,\n",
       "          2.7901e-01,  9.0338e-02,  2.7001e-01, -6.9490e-02, -3.0459e-01,\n",
       "         -2.9328e+00,  1.6000e-01, -7.4594e-02,  6.2551e-03,  2.7189e-01,\n",
       "         -1.6358e-01,  9.1131e-02, -4.7581e-01,  5.5133e-01, -2.1058e-01,\n",
       "         -3.6653e-01, -1.1600e-01, -2.8053e-01,  1.6574e-01,  2.4524e-01,\n",
       "         -2.9658e-01,  1.3273e-01, -3.2042e-01, -3.2904e-02,  2.5031e-01,\n",
       "          1.9829e-01, -1.4867e-01,  2.7169e-01,  4.2155e-01, -1.5105e-01,\n",
       "          1.0412e+00,  7.9105e-02, -1.4469e-01,  1.5980e-01, -7.1756e-02,\n",
       "         -5.8011e-01,  5.8731e-01,  6.3466e-02, -1.6633e-01,  2.9694e-01,\n",
       "         -2.9156e-01,  1.1378e-01, -2.5345e-01, -5.4520e-01,  7.1865e-03,\n",
       "          1.1529e-01,  2.6782e-02, -3.8925e-02,  7.7544e-02, -3.0890e-02,\n",
       "         -4.4703e-01,  6.3230e-02,  1.9152e-01,  1.5265e-01, -3.2514e-01,\n",
       "          1.6926e-01,  7.7721e-02, -3.5060e-02,  1.2001e-01, -4.9719e-01,\n",
       "          1.9430e-01,  2.1788e-01,  7.9847e-02, -4.1505e-02, -2.8195e-01,\n",
       "         -3.1106e-02,  7.2149e-02,  2.8612e-01,  1.3743e-01, -4.5492e-01,\n",
       "         -1.3126e-01,  4.2433e-01,  3.6423e-02,  5.8633e-01, -1.8761e-01,\n",
       "          2.4798e-01, -6.7989e-01, -2.1319e-01, -4.9218e-01, -2.2999e-01,\n",
       "          5.6608e-03,  6.0221e-02, -2.5087e-01,  1.5946e-01, -9.6153e-02,\n",
       "         -1.8882e-01,  3.3750e-01,  5.7556e-01, -3.2263e-02, -5.8699e-02,\n",
       "          5.0741e-01,  3.8544e-01,  8.6863e-02,  1.0908e-01, -1.3697e-01,\n",
       "         -2.0173e-01,  8.0930e-02, -7.0520e-02, -1.4067e+00, -2.4171e-01,\n",
       "         -3.3941e-01,  2.6558e-01,  2.2340e-01,  2.8159e-01,  2.1211e-01,\n",
       "         -3.5602e-01,  1.4119e-01, -2.9059e-01,  2.8630e-01,  2.8792e-01,\n",
       "         -3.3301e-02, -5.1286e-01, -6.6117e-01,  1.1902e-01, -2.6724e-01,\n",
       "         -4.2716e-01, -1.5570e-02,  1.2445e-01,  3.0750e-01,  3.1715e-01,\n",
       "         -2.1066e-01, -7.7106e-02,  2.1405e-01, -5.0836e-01, -3.0792e-01,\n",
       "         -2.2941e-01,  9.4481e-02, -3.2400e-01, -8.0958e-02,  1.3203e-02,\n",
       "          3.5357e-01, -1.5446e-01,  1.7910e-01, -1.9161e+00, -9.8501e-02,\n",
       "          7.1655e-02, -2.8920e-01,  2.1378e-01, -3.5976e-01,  1.6539e-01,\n",
       "          2.1486e-01,  1.2194e-01, -7.3562e-02,  2.8201e-02, -3.8129e-01,\n",
       "          1.1670e-01,  3.6040e-01, -4.1810e-02,  2.3905e-01, -4.9966e-05,\n",
       "         -4.8254e-01, -5.5226e-01,  3.2854e-01, -3.0434e-01,  1.4445e-01,\n",
       "          5.0446e-01, -8.9863e-02,  2.1399e-01,  2.9837e-01, -1.5062e-01,\n",
       "          2.5765e-01, -5.3320e-01, -5.2059e-02, -3.4207e-01, -3.9229e-01,\n",
       "         -1.9365e-01,  1.8233e-01,  2.4824e-01,  2.3922e-01, -6.0703e-02,\n",
       "         -1.3539e-01,  6.2937e-01,  2.1166e-01,  2.3620e-01,  2.6515e-01,\n",
       "          5.7907e-02, -6.5977e-02,  3.7542e-02,  1.2805e-01,  8.7100e-02,\n",
       "         -3.2356e-01,  6.5702e-02,  1.6752e-01,  1.7675e-01, -1.0383e-01,\n",
       "          2.3139e-01, -4.0629e-03, -1.7701e-01, -4.3622e-02,  1.0116e-01,\n",
       "          1.7436e-01,  1.5364e-01, -1.2147e-01,  3.3231e-01, -4.2554e-01,\n",
       "          7.9292e-02,  3.6654e-01, -2.8477e-01, -1.8640e-01, -6.9133e-02,\n",
       "         -3.4634e-01, -7.1604e-02, -2.5379e-01, -3.2085e-01, -2.9615e-01,\n",
       "         -1.7402e-01, -7.7939e-01, -4.6859e-01,  2.7476e-01, -2.8842e-01,\n",
       "          8.0173e-02,  4.0610e-01, -8.6777e-02,  1.9791e-01, -9.5532e-02,\n",
       "          5.4147e-02,  3.6366e-01, -7.4995e-02,  2.0679e-01,  2.6678e-01,\n",
       "         -2.5076e-01, -3.6332e-02,  5.7168e-03,  9.2155e-02,  1.7899e-01,\n",
       "          1.3653e-01, -1.2824e-01,  1.9515e-01,  7.6589e-02,  5.3285e-01,\n",
       "         -4.2090e-01,  2.4522e-02,  2.8838e-02, -4.3607e-01, -3.6093e-01,\n",
       "          1.0219e-01, -2.0553e-01, -3.6826e-01,  5.3870e-02, -4.8652e-01,\n",
       "          2.2101e-02, -5.5126e-01, -1.7897e-01,  1.8221e-01,  6.4792e-02,\n",
       "          1.1297e-01,  5.0954e-02,  2.3855e-01, -1.5287e-01, -1.2742e-01,\n",
       "          5.3831e-01,  9.2325e-02,  4.7820e-01, -2.8383e-02,  2.2139e-01,\n",
       "         -5.6357e-02,  2.5268e-01, -8.9854e-02,  6.4369e-03, -1.1580e-01,\n",
       "         -3.6442e-01, -4.8918e-01, -1.4075e-01,  2.7135e-01, -1.0976e-01,\n",
       "          1.0218e-01, -3.8942e-01, -2.7614e-01, -2.9103e-02,  6.3487e-02,\n",
       "          3.6728e-01,  5.5633e-02,  2.8052e-01,  7.4097e-01,  2.7539e-01,\n",
       "         -6.0540e-01,  1.7344e-01,  2.0604e-01,  3.1273e-01, -3.5989e-01,\n",
       "          1.8573e-01,  3.0723e-01,  3.9398e-01,  3.1309e-01, -2.4980e-01,\n",
       "          2.7969e-01, -2.0760e-01, -2.0504e-01, -3.3385e-01,  1.8085e-01,\n",
       "         -3.1915e-01, -2.9341e-01,  1.6180e-02, -1.5280e-01, -1.0530e-02,\n",
       "         -8.3955e-02, -9.9474e-02,  1.1072e-01, -1.6051e-01,  3.1394e-01,\n",
       "         -4.6763e-02, -5.5182e-01,  2.8101e-01,  4.6762e-01, -2.9119e-01,\n",
       "          3.2843e-02,  8.3776e-02, -4.9095e-02,  6.0667e-02,  9.1405e-02,\n",
       "         -3.3092e-01,  4.4926e-02,  8.7635e-02,  1.2932e-01, -5.7578e-01,\n",
       "         -1.3641e-01,  1.2144e-01,  2.7657e-01,  2.2608e-01, -4.0982e-01,\n",
       "         -2.5408e-01,  4.2765e-01,  4.2108e-01,  3.1134e-01, -2.8168e-01,\n",
       "         -2.9575e-01, -2.4937e-01, -2.8049e-01,  1.9578e-02,  1.7846e-01,\n",
       "          1.9888e-01,  4.6159e-01,  2.5319e-01,  5.3908e-01, -2.4541e-02,\n",
       "         -8.8707e-02,  2.7008e-01, -6.8138e-02,  9.4461e-02,  2.8673e-01,\n",
       "          6.2579e-01, -8.0851e-01, -2.6974e-01,  5.0808e-02, -3.3749e-01,\n",
       "         -3.6211e-01, -2.6320e-01,  6.0353e-02,  2.2261e-01,  9.0029e-02,\n",
       "         -8.5879e-02,  2.6119e-01, -2.5587e-01, -5.0537e-01, -2.3404e-01,\n",
       "          2.6480e-01, -6.5112e-02,  2.4349e-01, -1.9568e-01, -4.4276e-01,\n",
       "         -1.6300e-01, -8.4459e-02,  1.2126e-01,  1.8093e-01,  4.4630e-01,\n",
       "         -2.2696e-02,  3.0707e-01,  5.3017e-01,  4.7342e-01, -7.2124e-01,\n",
       "          2.2150e-01, -2.9049e-01, -1.1485e-01,  5.0769e-02, -5.1459e-01,\n",
       "         -4.3160e-01, -3.2469e-01,  1.2183e-01, -8.9298e-02,  2.0048e-01,\n",
       "          4.6111e-01,  1.3461e-01,  2.6530e-02, -5.9557e-02, -2.4906e-02,\n",
       "         -5.0297e-02, -2.9035e-01,  1.8199e-01, -6.9063e-01, -7.1839e-02,\n",
       "         -2.0750e-03,  1.1287e-01, -1.7267e-01, -2.5317e-01,  1.0678e-01,\n",
       "          5.2773e-01,  5.9217e-02, -5.3207e-02,  1.2773e-01, -9.3292e-02,\n",
       "          8.8962e-02,  4.2416e-01,  2.7685e-01, -1.3364e-01,  2.4015e-01,\n",
       "         -1.4276e-02,  1.2548e-01, -2.9737e-01, -9.7947e-02,  2.1280e-01,\n",
       "         -4.1931e-01, -4.0944e-01, -1.7310e-01,  8.5243e-01,  6.6675e-01,\n",
       "         -3.1573e-02, -1.2431e-01,  1.7833e-01, -2.5319e-01, -2.1831e-01,\n",
       "         -1.7351e-01, -2.8973e-01, -4.1044e-01,  4.2843e-01,  1.3754e-01,\n",
       "         -1.0293e-01,  2.0709e-01, -8.8253e-02,  1.2922e-01, -4.3439e-01,\n",
       "          3.5739e-01, -4.6385e-01, -5.5761e-02, -5.1233e-02,  4.0289e-01,\n",
       "          1.0400e-01, -2.9710e-01, -2.8265e-03,  7.6578e-02,  2.9749e-01,\n",
       "         -4.5155e-01, -4.1680e-04, -9.3719e-02, -5.5347e-01, -1.4037e-01,\n",
       "         -1.9211e-01,  5.5962e-01, -3.6663e-01,  2.7697e-01,  1.9926e-01,\n",
       "         -4.8247e-01,  1.4242e-01,  2.0429e-01,  1.9455e-01,  6.3591e-03,\n",
       "          2.4142e-01,  9.4478e-02,  2.3910e-01,  3.8529e-01, -4.7825e-01,\n",
       "         -4.6240e-02,  2.1030e-01,  1.6094e-01,  1.8452e-01,  1.2209e-01,\n",
       "         -1.4733e-01,  4.5241e-01,  2.7698e-02, -2.6517e-01,  3.2128e-01,\n",
       "          8.2877e-02, -1.6144e-01, -2.3545e-01,  9.6497e-02,  3.2798e-01,\n",
       "          2.3675e-01, -2.2912e-01, -1.1641e-01,  3.0669e-01, -2.1977e-01,\n",
       "         -3.7945e-01,  1.7389e-01,  1.5031e-01,  2.1685e-01, -6.7974e-03,\n",
       "          2.7142e-02,  1.3046e-01, -2.0475e-01,  1.2269e-01,  2.7659e-01,\n",
       "          1.0372e-01, -3.2096e-01, -1.4594e+00, -1.6508e-01, -5.0738e-02,\n",
       "         -2.1407e-02, -2.5883e-01, -6.3108e-02,  3.1288e-01,  1.1008e-01,\n",
       "         -1.6120e-01, -5.4222e-01, -2.8640e-02,  3.2673e-02,  1.7875e-01,\n",
       "          2.3282e-01, -1.2824e-01,  1.6886e-01,  2.9167e-01, -1.1944e-01,\n",
       "          2.7882e-01, -3.9545e-01,  5.6198e-02,  1.2831e-02, -2.3663e-01,\n",
       "         -2.5625e-01, -2.4678e-01,  3.1865e-01, -6.0961e-01, -2.6219e-01,\n",
       "         -2.0798e-01,  3.4889e-01, -2.1750e-01,  2.5316e-01, -2.9977e-01,\n",
       "         -1.0798e-02, -2.5486e-01, -1.3545e-01, -2.8649e-02,  1.6271e-01,\n",
       "          1.2684e-01,  9.0374e-02,  3.3999e-01,  5.7435e-01,  1.4127e-01,\n",
       "         -1.9182e-01,  2.2587e-01, -2.0091e-01, -1.0641e-02,  4.9793e-01,\n",
       "         -4.7175e-02, -1.8986e-02, -5.5410e-01, -2.2937e-01,  1.8419e-01,\n",
       "         -1.1726e+00,  2.9346e-01, -1.2331e-01, -3.2347e-01, -2.3277e-02,\n",
       "          2.7962e-01,  2.3835e-01, -1.0668e-01, -1.6090e-01, -2.6450e-01,\n",
       "          1.0141e-01,  7.8425e-02, -1.2928e-01,  1.7666e-01, -2.2339e-01,\n",
       "          2.9383e-01,  1.4656e-02,  2.2820e-01,  5.1517e-02,  1.9882e-01,\n",
       "         -1.9324e-01, -9.8186e-03,  2.4150e-02, -6.0924e-02,  1.3861e-02,\n",
       "         -4.6342e-04, -2.4242e-01, -2.5423e-01, -1.4933e-01,  1.5831e-01,\n",
       "          2.5775e-01, -1.0368e-01, -2.7482e+00, -2.7073e-02, -1.5737e-01,\n",
       "          7.4561e-02,  2.0461e-01, -6.9690e-02,  4.2004e-01, -1.6307e-01,\n",
       "         -1.1930e-01, -1.3138e-02,  3.2705e-01, -4.2854e-01,  1.2412e-01,\n",
       "          1.3010e-01, -1.0651e-01,  5.7460e-02]),\n",
       " tensor([ 4.0070e-02,  9.0764e-02, -3.2941e-01, -1.7589e-02, -2.5886e-01,\n",
       "         -1.3861e-02,  2.5964e-01, -1.9867e-01, -1.7993e-02, -1.6950e-01,\n",
       "          1.1305e-01,  2.1880e-02,  2.1295e-01,  2.6560e-01, -1.2974e-01,\n",
       "         -3.0753e-01,  3.9365e-02,  2.5755e-01,  1.8774e-02,  1.0486e-01,\n",
       "          2.4309e-01, -2.0680e-01,  2.5214e-01, -2.0621e-01,  2.6308e-01,\n",
       "          1.7886e-01, -1.8678e-01, -6.1269e-02, -1.6898e-01, -2.8404e-02,\n",
       "          2.7155e-02, -2.2892e-01,  1.4210e-01,  4.2945e-01,  8.0865e-02,\n",
       "         -1.3263e-01,  1.5517e-01, -1.2016e-01, -2.2134e-01, -2.1966e-01,\n",
       "          7.6204e-02,  7.5196e-02, -4.5483e-02,  1.3221e-01,  2.1723e-01,\n",
       "         -1.0438e-02, -1.6303e-01, -2.8742e-01,  1.1487e-02,  2.3347e-01,\n",
       "         -1.9171e-01,  3.9704e-03, -1.1699e-01,  2.5243e-01,  1.2193e-01,\n",
       "          1.7229e-01,  2.5348e-01, -4.1115e-02, -1.0503e-01,  1.6982e-01,\n",
       "         -3.9780e-02,  1.4721e-01, -2.6209e-01,  1.4156e-01,  1.6994e-01,\n",
       "          3.8703e-01,  3.1095e-01,  1.9025e-02, -5.4359e-01,  3.3542e-01,\n",
       "         -1.7490e-01, -4.1118e-01,  3.1208e-01,  8.9439e-02,  3.5740e-01,\n",
       "         -6.8142e-02, -2.0968e-01,  3.9705e-01,  3.2133e-02, -1.3276e-01,\n",
       "          4.2807e-01,  3.2014e-02,  5.0432e-02,  3.1317e-01,  5.8859e-02,\n",
       "          7.0351e-02, -1.3009e-01, -2.9761e-01, -3.3534e-01,  1.9310e-01,\n",
       "          1.0631e-01,  9.3694e-02, -1.0556e-01,  1.7108e-01, -6.7254e-02,\n",
       "          3.7724e-02, -2.4951e-01,  1.7435e-04,  1.3174e-01, -3.4991e-01,\n",
       "          1.0907e-02, -5.7621e-02,  1.3020e-02,  2.1759e-01, -2.1637e-01,\n",
       "          8.7393e-02,  4.5881e-02, -3.2923e-02,  1.3103e-01, -4.7793e-01,\n",
       "          3.8364e-01,  1.4127e-01,  1.9789e-01, -2.2107e-01, -1.2106e-01,\n",
       "          2.3541e-01,  2.2996e-01,  1.6588e-01, -3.1130e-02,  1.5779e-01,\n",
       "         -2.9325e-01, -1.6023e-01,  2.2384e-02,  5.1770e-01, -1.1916e-01,\n",
       "          1.5750e-01, -1.5997e-01, -3.0084e-01,  3.0099e-01, -1.3923e-01,\n",
       "         -3.6242e-01,  2.7055e-01,  2.9588e-03,  4.3131e-01, -5.4060e-02,\n",
       "          1.5029e-01,  2.4987e-01,  7.9622e-02, -2.1647e-01, -1.6680e-01,\n",
       "         -2.4487e-01,  4.6122e-01, -9.8038e-01, -4.0270e-01,  2.2613e-01,\n",
       "         -7.9120e-03,  2.5202e-01,  2.0611e-01,  2.6071e-01,  5.1372e-03,\n",
       "         -1.3252e-02,  9.8118e-02, -2.3271e-01,  1.8411e-02, -4.4025e-01,\n",
       "         -3.6575e-01, -2.5433e-01, -1.4834e-01,  2.8540e-01,  5.8013e-01,\n",
       "          2.4980e-01,  7.9436e-02,  1.6591e-01,  2.4401e-01, -1.8492e-01,\n",
       "          1.3096e-01, -4.6381e-02,  2.7654e-01, -1.6605e-01, -1.0967e-01,\n",
       "         -3.6121e-01, -5.1384e-01,  3.8281e-01,  8.3544e-02, -2.9884e-01,\n",
       "          2.2643e-01,  1.0268e-01,  2.4021e-01,  4.6093e-02, -1.7235e-01,\n",
       "         -3.0164e+00,  3.1084e-01,  1.1124e-01, -1.1931e-01,  3.1149e-01,\n",
       "          1.0084e-01,  8.5503e-02, -2.6214e-01,  2.0944e-01, -5.9938e-01,\n",
       "         -1.0915e-01, -1.6125e-01, -3.7777e-01,  4.2456e-01,  4.6101e-01,\n",
       "         -1.3674e-01, -1.6395e-01, -1.2928e-01,  8.9679e-02,  1.3941e-01,\n",
       "          2.3011e-01, -4.1190e-01, -2.6957e-02,  1.6525e-01,  2.5026e-02,\n",
       "          9.4958e-01,  3.2112e-01, -8.2841e-02,  3.1701e-01,  1.2954e-01,\n",
       "         -4.7307e-01,  5.2940e-01,  9.9595e-02, -1.6398e-01,  1.8027e-01,\n",
       "         -1.2840e-01,  3.0660e-01, -3.4706e-01, -4.8438e-01,  4.7497e-02,\n",
       "          1.5196e-01, -4.8877e-03, -1.8932e-01,  1.2429e-01, -3.3459e-01,\n",
       "         -3.5123e-01,  3.2548e-01,  1.3750e-01,  1.6277e-01, -1.7748e-01,\n",
       "          8.7619e-02, -1.7556e-01, -9.5499e-03,  8.1758e-02, -2.2884e-01,\n",
       "          2.3930e-01,  1.6988e-01, -3.0125e-02,  1.3610e-01, -1.9913e-01,\n",
       "          8.6258e-03,  4.0716e-01,  1.5338e-01,  1.6783e-01, -4.0005e-01,\n",
       "         -1.4128e-01,  4.9622e-01,  1.7196e-01,  2.1534e-01, -2.9416e-01,\n",
       "          1.8757e-01, -6.9407e-01,  1.2962e-01, -2.7073e-01, -2.0782e-01,\n",
       "          5.2412e-03,  7.5786e-02, -2.3065e-01,  3.0113e-01, -3.7798e-02,\n",
       "          4.3970e-02,  3.0962e-01,  4.8877e-01, -1.6947e-01, -8.1067e-02,\n",
       "          1.3878e-01,  1.1581e-01, -1.5337e-01, -1.3680e-01,  1.2697e-01,\n",
       "          1.0041e-01,  2.7640e-02, -1.9765e-01, -1.3503e+00, -3.5352e-02,\n",
       "          2.3659e-03,  2.2616e-01,  1.5645e-01,  1.3210e-01, -1.9144e-01,\n",
       "         -4.7549e-02,  2.5962e-01,  1.0863e-01,  2.4154e-01,  3.0717e-01,\n",
       "         -3.8386e-01, -4.0020e-01, -3.3896e-01,  1.4523e-01, -1.0380e-01,\n",
       "         -1.4653e-01, -4.9684e-03,  3.2143e-02,  1.6274e-01,  4.2123e-01,\n",
       "         -6.1400e-02,  1.4329e-01,  2.1312e-01, -2.1938e-01, -1.1503e-01,\n",
       "         -1.9865e-01,  5.1311e-02, -8.6853e-02, -3.7210e-02, -2.0730e-01,\n",
       "          2.2226e-01,  2.1706e-03,  9.8386e-03, -2.2330e+00, -7.2642e-02,\n",
       "          1.4858e-01, -4.3092e-01,  4.4222e-01, -4.3782e-01,  7.9034e-02,\n",
       "         -3.3687e-02, -1.0134e-01,  2.4820e-04,  8.8356e-02, -4.1580e-01,\n",
       "          2.9561e-01,  2.5880e-01,  1.7786e-01,  2.4863e-01,  1.5672e-01,\n",
       "         -1.6330e-01, -5.1427e-01,  1.8726e-01, -1.2364e-01,  1.3568e-01,\n",
       "          2.8239e-01, -9.6855e-02,  1.4191e-01,  1.6468e-01, -1.4267e-01,\n",
       "         -9.0747e-02, -5.8863e-01,  1.0066e-01, -2.3745e-01, -3.0622e-01,\n",
       "         -3.0550e-01, -1.6988e-02,  1.4478e-01, -9.2347e-02, -8.1027e-02,\n",
       "          8.8460e-03,  7.1704e-01, -2.4697e-01,  2.9130e-02,  1.1178e-01,\n",
       "          2.2024e-01,  1.1047e-02, -2.6829e-01,  5.5740e-02, -1.3042e-01,\n",
       "         -4.3445e-01,  8.1497e-02,  3.9387e-01,  2.1309e-01, -1.1883e-01,\n",
       "          3.0336e-01, -1.2507e-01,  2.7093e-02, -2.3479e-01,  4.3523e-01,\n",
       "          1.3990e-01,  4.0619e-02, -5.7668e-02,  1.4904e-01, -4.4245e-01,\n",
       "          6.6851e-02,  3.8754e-02, -3.0640e-01, -2.7557e-01,  7.6930e-02,\n",
       "         -1.9839e-01, -1.1087e-01,  8.6210e-02, -3.0529e-02, -1.7331e-01,\n",
       "         -1.2623e-01, -7.5369e-01, -3.9759e-01,  1.5615e-01, -1.3766e-01,\n",
       "         -1.5990e-02,  2.1829e-01, -2.4079e-02,  1.7288e-01, -7.3714e-02,\n",
       "         -9.9169e-03, -1.4137e-02,  3.5601e-02,  4.0312e-02,  1.2609e-01,\n",
       "         -3.8530e-01, -2.6004e-01, -1.4814e-01,  2.0651e-01,  1.1473e-01,\n",
       "          2.7361e-01,  2.1518e-02,  1.3678e-02,  1.1330e-01,  4.6735e-01,\n",
       "         -2.5990e-01, -4.4987e-02, -2.0588e-01, -3.3570e-01, -1.0441e-01,\n",
       "          3.9802e-01, -3.2119e-01, -1.8176e-01, -1.5925e-01, -5.4795e-01,\n",
       "          4.6554e-02, -1.3053e-01, -2.7111e-01,  2.4318e-01, -2.9538e-01,\n",
       "          1.5986e-01, -2.1448e-01, -1.2136e-02, -1.1010e-01, -3.3175e-02,\n",
       "          5.6127e-01, -2.1173e-02,  2.9739e-01,  2.4480e-01,  1.0204e-01,\n",
       "          2.4647e-02, -1.2075e-01,  4.4810e-03,  1.4320e-01, -9.6853e-02,\n",
       "         -6.3573e-01, -1.4445e-01, -1.9053e-01, -4.2949e-02,  8.5063e-02,\n",
       "         -1.5640e-01, -1.8303e-01, -1.6565e-01,  2.1688e-01,  3.4244e-01,\n",
       "          4.4489e-01,  1.5113e-01,  3.9151e-01,  3.0504e-01,  1.3398e-01,\n",
       "         -5.6041e-01,  6.7127e-02,  2.2423e-01,  2.7023e-01, -3.5602e-01,\n",
       "          1.6833e-03,  3.8680e-01,  5.3427e-01,  2.6384e-01, -3.5807e-01,\n",
       "          3.6774e-01, -2.4172e-01,  2.3532e-02, -1.8723e-01, -3.5013e-01,\n",
       "         -1.7202e-01, -3.2458e-01,  4.7805e-02, -2.6307e-01,  1.5934e-01,\n",
       "         -7.0928e-02,  1.9534e-01,  7.3376e-02, -3.5315e-02,  5.6439e-01,\n",
       "         -3.6368e-01, -3.4057e-01,  1.3893e-01,  4.2944e-01, -3.0476e-01,\n",
       "          2.2612e-01, -2.0044e-02, -1.2384e-01,  1.5415e-01,  7.9503e-02,\n",
       "         -2.7819e-01,  8.6811e-02, -2.4576e-02,  7.1077e-02, -1.9487e-01,\n",
       "         -9.8697e-02,  8.8792e-02,  2.6376e-01,  1.8873e-01, -2.0494e-01,\n",
       "         -1.2129e-01,  2.9449e-01,  5.2844e-01,  9.8265e-02, -1.0576e-01,\n",
       "         -2.0800e-01, -1.1134e-01, -3.7688e-01,  4.9081e-01,  3.1877e-01,\n",
       "          1.1725e-01,  3.4819e-01,  2.7259e-01,  1.2763e-01, -1.6690e-01,\n",
       "         -2.3423e-01,  5.2154e-02,  3.0849e-01,  1.5541e-01,  6.9111e-02,\n",
       "          9.1343e-02, -3.1330e-01, -9.1423e-02,  2.1590e-01, -4.3313e-01,\n",
       "         -2.9305e-01, -2.2536e-01,  2.0325e-01,  1.3604e-01,  1.2593e-01,\n",
       "          1.1085e-01,  9.8633e-02, -2.3102e-01, -5.1228e-01, -3.7014e-01,\n",
       "          2.1939e-03, -1.3344e-01,  2.0163e-01,  1.3526e-01, -6.2341e-01,\n",
       "         -1.6440e-01, -9.7479e-02, -7.4619e-03,  1.3297e-01,  1.0136e-01,\n",
       "         -2.4144e-01,  9.9223e-02,  8.0235e-01,  2.8133e-01, -2.3477e-01,\n",
       "         -1.3028e-01, -2.6669e-01, -7.4928e-02,  6.8213e-02, -2.2382e-01,\n",
       "         -2.2597e-01, -2.8308e-01, -6.7931e-02,  2.7946e-01, -1.4586e-01,\n",
       "          3.3931e-01,  4.2035e-01, -1.1288e-01,  9.4783e-02, -1.2116e-02,\n",
       "          5.6052e-02, -1.5074e-01,  2.3670e-01, -7.9515e-01, -2.3878e-02,\n",
       "          2.3593e-01,  1.8205e-01,  1.0795e-01, -1.6655e-01, -1.9880e-02,\n",
       "          1.7180e-01,  1.5469e-01, -1.0761e-01,  5.3922e-02, -8.4027e-02,\n",
       "          8.7363e-02,  1.5233e-01,  2.5262e-01, -2.9036e-01,  4.2243e-01,\n",
       "         -9.5746e-02,  1.8552e-01, -3.1670e-01, -5.8544e-02,  2.1988e-01,\n",
       "         -3.8350e-01, -3.7302e-01,  1.6824e-01,  8.1778e-01,  3.4151e-01,\n",
       "         -1.6337e-01, -8.8462e-02,  3.0587e-02,  8.2536e-03, -7.5488e-03,\n",
       "         -2.4036e-02, -2.0340e-01, -3.2563e-01,  2.9108e-01, -1.2189e-01,\n",
       "         -1.2094e-01,  7.6154e-02, -1.8361e-01,  3.0288e-01, -6.7884e-02,\n",
       "          1.3624e-01, -4.1824e-01,  5.7416e-02, -3.8247e-01,  7.4152e-01,\n",
       "          3.1232e-02, -8.6059e-02, -3.4849e-01,  1.7537e-01,  1.2715e-01,\n",
       "         -4.4380e-01,  1.7787e-01, -6.3170e-02, -3.2626e-01, -2.1507e-02,\n",
       "          2.7658e-01,  4.6290e-01, -3.9423e-01, -2.7653e-01,  1.0287e-01,\n",
       "         -4.3499e-01, -7.7721e-02,  5.8370e-01,  7.1015e-03, -2.0430e-01,\n",
       "          3.4265e-01,  4.0965e-02,  7.4600e-02,  3.3532e-01, -3.7873e-01,\n",
       "         -1.9826e-01,  1.9372e-01,  2.0627e-01,  9.0219e-02, -1.6334e-01,\n",
       "         -2.7896e-02,  3.4124e-01,  8.8485e-02, -2.6342e-01,  2.1733e-01,\n",
       "          1.6563e-01,  3.0486e-02, -3.7806e-01,  8.1897e-02,  1.5635e-02,\n",
       "          1.2002e-01, -2.3517e-01,  2.6441e-01, -9.9877e-03, -8.4532e-04,\n",
       "         -2.2608e-01,  2.6942e-02,  2.1709e-01, -5.6134e-03, -2.4429e-01,\n",
       "          1.1162e-01, -5.4033e-02, -4.4171e-01,  6.7635e-02,  3.2352e-01,\n",
       "         -2.2839e-01, -3.4394e-01, -9.8587e-01, -1.5182e-02, -3.8059e-01,\n",
       "         -1.2182e-01, -2.7520e-01,  1.7057e-01,  4.7847e-01,  1.0393e-01,\n",
       "         -1.6334e-01, -4.1433e-01,  2.6029e-02,  1.7928e-01,  6.9641e-02,\n",
       "          1.7182e-01,  4.8389e-02,  1.6703e-02,  2.2241e-01, -1.9455e-01,\n",
       "          9.0940e-02, -5.3041e-01,  3.3878e-02,  1.7145e-01, -3.0113e-01,\n",
       "          1.5449e-02, -2.3427e-01,  1.5178e-01, -4.1446e-01, -2.7816e-01,\n",
       "         -4.3858e-01,  1.0853e-01,  4.7206e-02,  2.1396e-01, -2.8584e-01,\n",
       "          5.3692e-02, -2.4947e-02,  2.1839e-01,  1.8763e-01,  3.3845e-01,\n",
       "          4.8983e-02,  1.1074e-01,  5.1241e-01,  4.2516e-01, -5.3033e-02,\n",
       "         -1.5314e-01,  3.9836e-01, -2.8234e-02, -2.2900e-02,  5.2418e-01,\n",
       "         -2.8109e-03,  5.7058e-02, -4.6010e-01, -2.3328e-01, -2.7551e-03,\n",
       "         -1.0308e+00,  3.5337e-01,  2.1115e-03, -1.3862e-01, -1.7291e-02,\n",
       "          2.3436e-01, -2.3492e-01, -2.7154e-01, -1.2631e-01, -9.5227e-02,\n",
       "          2.5602e-01,  1.9693e-01, -1.9496e-01, -1.3283e-01, -3.6696e-01,\n",
       "          2.0888e-01, -1.6287e-01, -6.3669e-03,  6.2257e-02,  1.0292e-01,\n",
       "         -2.4417e-01, -5.7883e-02,  9.9654e-02, -7.4011e-02,  1.9080e-02,\n",
       "          8.4315e-02, -1.6754e-01, -9.1826e-02, -3.4926e-02,  1.7320e-01,\n",
       "          3.9495e-01,  1.9005e-01, -2.9300e+00,  3.6765e-02,  1.8841e-01,\n",
       "          1.0055e-01,  1.5466e-02, -2.5347e-02,  4.6808e-01, -1.8397e-01,\n",
       "         -1.0391e-02, -2.9664e-01,  2.8520e-01, -5.3385e-01,  8.5324e-02,\n",
       "         -1.1568e-01, -3.3042e-01, -1.2417e-01]),\n",
       " tensor([ 3.0712e-01,  1.9788e-02, -4.4498e-02, -9.3193e-02, -1.3493e-01,\n",
       "         -3.2566e-01,  3.7286e-01, -1.6146e-01,  2.6038e-01, -2.2410e-01,\n",
       "         -2.9240e-02, -5.9075e-03,  1.5485e-01,  1.8303e-02, -4.5669e-01,\n",
       "         -2.0743e-01, -5.6675e-02, -6.4270e-02,  3.2801e-01,  2.0448e-01,\n",
       "         -6.8704e-02,  3.9399e-02,  6.4510e-02, -2.8980e-02,  1.7674e-01,\n",
       "          2.2859e-01, -1.5361e-01, -8.5513e-02, -2.3765e-01,  6.0898e-02,\n",
       "          9.8267e-02,  1.0747e-03,  2.4771e-02,  2.2342e-01, -8.5645e-02,\n",
       "         -9.4912e-02, -9.1449e-02,  8.6776e-04, -5.2210e-01, -1.6442e-01,\n",
       "         -1.6235e-02, -3.7359e-02,  6.3629e-02, -9.2813e-02,  5.1018e-02,\n",
       "         -3.3838e-01, -2.6992e-01,  1.0360e-01, -9.3360e-02,  2.3744e-01,\n",
       "         -3.4374e-01,  4.1546e-02, -4.0158e-03,  1.8414e-01,  1.3726e-01,\n",
       "          1.8506e-01,  1.3408e-01,  1.5182e-01, -5.8495e-02, -6.3993e-02,\n",
       "         -2.2595e-02,  1.6159e-01,  1.5110e-01,  8.8369e-02,  1.2110e-01,\n",
       "          2.8381e-01,  3.5874e-01, -2.0969e-01, -2.4704e-01,  1.3502e-01,\n",
       "         -4.2692e-02, -2.8389e-01,  1.3118e-01,  1.8178e-02, -3.1500e-02,\n",
       "          1.8456e-02, -1.9434e-01,  2.0310e-01,  3.1709e-01,  7.1892e-02,\n",
       "          2.4683e-01,  1.7129e-01, -1.4828e-01,  1.4517e-01,  1.9300e-01,\n",
       "         -2.1523e-02, -8.2540e-02, -5.6441e-03, -5.7621e-02,  1.7092e-01,\n",
       "          2.6548e-02, -9.8355e-02,  4.9609e-02,  1.1471e-01,  7.9520e-02,\n",
       "         -1.2819e-01, -1.8353e-01,  5.3480e-02, -5.1993e-02, -6.3216e-02,\n",
       "         -5.0824e-02, -2.1673e-01, -1.4993e-01,  1.0793e-01, -3.1816e-01,\n",
       "         -9.5458e-02, -1.7068e-01,  2.7659e-02,  2.3952e-01, -6.1069e-01,\n",
       "          2.9323e-01,  2.9507e-02, -5.9373e-02, -1.3327e-02, -1.7462e-01,\n",
       "          8.0331e-02,  1.5345e-01,  1.9448e-01,  1.9352e-01,  2.2856e-02,\n",
       "         -1.2265e-01,  1.9306e-02,  2.3386e-01,  5.8046e-01,  2.9491e-01,\n",
       "         -1.0679e-01, -1.9817e-01, -2.5866e-01, -3.7843e-01, -3.2323e-01,\n",
       "         -2.1032e-01,  3.6195e-01,  2.4417e-01,  3.3087e-02,  6.3183e-02,\n",
       "          1.2183e-01,  2.5173e-02,  1.3332e-01, -2.1157e-01, -4.2647e-02,\n",
       "         -2.7293e-03,  6.3265e-01, -8.4796e-01, -1.2879e-01,  2.9629e-01,\n",
       "         -5.8900e-02,  4.9493e-01, -2.2077e-01,  4.2822e-02, -4.1908e-02,\n",
       "          3.4753e-01,  1.1217e-01, -1.8492e-01, -3.7917e-01, -2.6739e-01,\n",
       "         -1.2497e-01,  1.9400e-02,  1.0356e-01,  2.1053e-01,  4.2663e-01,\n",
       "          1.5527e-01,  3.0708e-01,  1.3879e-01,  2.7373e-02, -1.6553e-01,\n",
       "          1.4193e-01, -2.1190e-01,  3.1217e-01,  3.9466e-01,  2.6507e-01,\n",
       "         -1.7768e-01, -3.7800e-01,  1.9580e-01,  3.3202e-01, -3.4983e-01,\n",
       "          1.1627e-01,  1.8871e-01,  1.1760e-01, -4.1986e-02, -2.0846e-01,\n",
       "         -2.8028e+00,  1.9122e-01, -6.2822e-02, -3.2876e-01,  5.5593e-02,\n",
       "         -7.5759e-02, -2.1717e-02, -2.8812e-01,  9.8777e-02, -2.6013e-01,\n",
       "         -1.6690e-01, -5.7076e-03, -1.0562e-01,  8.0814e-02,  1.9599e-01,\n",
       "         -3.5709e-01, -3.6197e-03,  1.1280e-01, -8.4995e-02,  1.3803e-01,\n",
       "          2.2065e-01, -5.6586e-02, -9.2842e-04,  6.1253e-02,  6.9796e-03,\n",
       "          9.5742e-01,  2.9638e-01, -3.2834e-01,  5.7896e-02,  8.1462e-03,\n",
       "         -6.6657e-01,  4.2046e-02,  1.7187e-01, -2.8621e-01,  2.0521e-01,\n",
       "         -3.1315e-01,  2.0094e-01, -2.2615e-01, -3.9994e-01, -4.7571e-02,\n",
       "         -7.0127e-02, -2.0460e-02, -3.0781e-01,  5.3239e-02,  3.3602e-02,\n",
       "         -5.6223e-01,  3.1231e-01, -5.4404e-02,  1.8190e-01, -3.0679e-02,\n",
       "         -1.3309e-01, -3.6612e-01,  2.1529e-01,  1.7620e-01,  1.4956e-01,\n",
       "          6.6092e-02,  2.4625e-02, -3.0374e-02, -1.7409e-01, -1.4718e-01,\n",
       "          2.1531e-02, -1.4972e-01,  3.4505e-01,  3.5537e-01, -2.5024e-01,\n",
       "          1.1290e-01,  1.8479e-01,  3.2957e-02,  4.7112e-01, -2.1861e-01,\n",
       "         -1.1317e-01, -5.2505e-01,  7.2330e-02, -2.0516e-01,  6.7006e-02,\n",
       "         -2.0775e-01, -2.3184e-01, -2.1815e-01,  3.2281e-01,  2.1416e-01,\n",
       "          6.7886e-04,  2.1953e-01,  6.1405e-01, -1.9180e-01, -1.6854e-01,\n",
       "          2.4120e-01,  1.4855e-01,  1.0518e-01, -9.5808e-02,  1.1677e-02,\n",
       "          1.3523e-02,  4.9783e-02, -9.0152e-02, -1.2985e+00, -1.3327e-01,\n",
       "         -9.6917e-02,  4.5915e-01,  8.5969e-02,  8.6468e-02, -1.5515e-02,\n",
       "         -9.7253e-02,  1.8883e-01, -2.4762e-01,  1.5214e-01,  3.5926e-01,\n",
       "         -2.9327e-01, -2.5226e-01, -4.0019e-01,  5.7496e-02, -3.6707e-01,\n",
       "         -2.2820e-01,  1.2446e-01,  1.5574e-01, -1.7459e-01,  3.2238e-01,\n",
       "          8.2525e-02,  2.4438e-01,  1.7701e-01, -2.6793e-01,  5.0405e-02,\n",
       "         -6.5563e-02, -1.8696e-01,  6.8687e-02, -1.0493e-01,  1.2214e-03,\n",
       "          3.1017e-02,  1.2684e-01,  1.2577e-01, -2.1795e+00, -7.5396e-02,\n",
       "          1.8432e-01, -5.4381e-01,  1.1125e-01, -1.4612e-01,  3.7116e-02,\n",
       "          1.0790e-01, -1.5680e-01,  7.8327e-02,  2.5819e-01, -2.7607e-01,\n",
       "          1.3031e-01,  2.4523e-01,  4.2334e-02, -2.2143e-03,  4.3363e-02,\n",
       "         -7.7735e-02, -4.8177e-01, -6.2244e-02, -5.5011e-02, -8.1801e-02,\n",
       "          3.6653e-01, -3.2595e-01,  6.6760e-02,  3.1875e-01, -3.1156e-01,\n",
       "          1.5837e-01, -3.4417e-01,  9.5137e-02, -9.6344e-02, -3.3448e-01,\n",
       "         -2.0096e-01,  7.1575e-02,  5.5638e-02,  2.2396e-02,  2.9154e-01,\n",
       "         -1.3057e-02,  8.5354e-01, -1.8492e-02,  1.2234e-01,  2.0966e-01,\n",
       "          1.2473e-01, -4.8940e-03, -2.3691e-01, -8.3079e-02,  4.7552e-02,\n",
       "         -3.9052e-01, -2.6036e-02,  3.4196e-01,  2.1178e-01,  7.2508e-02,\n",
       "          1.2946e-01, -6.7482e-02, -2.1991e-01, -6.3216e-02, -3.6496e-02,\n",
       "          1.4950e-01,  8.6665e-03, -9.9972e-02,  1.1176e-01, -2.8027e-01,\n",
       "          3.7755e-03,  1.1444e-01, -4.9148e-01,  1.9556e-01, -9.5217e-02,\n",
       "         -1.2788e-01,  1.5826e-02,  2.7600e-01, -6.0688e-02, -3.9894e-02,\n",
       "          1.2181e-01, -8.1592e-01, -2.9697e-01,  3.5591e-01, -2.7424e-01,\n",
       "         -9.4481e-02,  4.1648e-01, -3.6093e-01, -3.8355e-03, -1.3534e-01,\n",
       "          2.8646e-02,  3.9283e-01,  6.7411e-02,  1.3835e-01,  2.7085e-01,\n",
       "         -2.6592e-01,  7.2689e-02, -3.3649e-01, -8.7817e-02,  9.4617e-02,\n",
       "          1.9143e-01, -2.3558e-02,  2.9735e-01,  2.4737e-01,  3.6877e-01,\n",
       "         -2.9689e-01,  1.6730e-01, -2.8586e-02, -1.7876e-01,  2.6887e-02,\n",
       "          9.6005e-02,  3.3482e-02,  6.3171e-02,  4.6338e-02, -7.8082e-01,\n",
       "         -1.0425e-01, -1.8333e-01, -1.6607e-01,  2.9869e-01, -7.2614e-02,\n",
       "          3.8462e-01,  1.7573e-01, -1.5275e-01, -4.0766e-01, -1.4669e-01,\n",
       "          2.9580e-01, -1.3544e-01,  2.9256e-01,  2.5341e-01,  3.6288e-01,\n",
       "          1.3688e-01, -1.4149e-01, -1.3853e-01, -1.1911e-01,  2.4878e-02,\n",
       "         -1.7513e-01, -3.1377e-01, -1.3400e-01,  7.2411e-03, -1.3192e-02,\n",
       "          1.2590e-01, -4.4758e-01, -2.4089e-01,  3.3684e-02,  2.8390e-01,\n",
       "          2.8317e-01,  1.7563e-01,  4.0271e-01,  2.9157e-01, -4.5046e-02,\n",
       "         -4.4241e-01,  8.2443e-02,  5.9889e-02,  5.6674e-01, -1.5334e-01,\n",
       "          2.0936e-01,  2.4062e-01,  3.3910e-01,  2.3003e-01, -9.5404e-02,\n",
       "          3.4224e-01, -3.1934e-01, -4.8561e-02, -2.5858e-01,  2.6487e-01,\n",
       "         -8.4027e-02, -8.5984e-02,  2.0902e-01, -1.6355e-01,  1.6738e-01,\n",
       "         -7.9772e-02,  3.1395e-01, -3.7081e-03,  1.3830e-01,  4.1803e-02,\n",
       "         -1.0586e-02, -4.3691e-01,  1.2684e-01,  3.1536e-01, -2.8202e-01,\n",
       "          2.7098e-02, -6.1761e-02, -1.3118e-02,  3.4103e-01, -2.7492e-02,\n",
       "         -3.3210e-01,  8.3385e-02, -2.1176e-03,  1.6056e-01, -4.5138e-01,\n",
       "          3.2046e-02, -1.3392e-01,  4.5908e-01,  7.3193e-02, -3.2174e-01,\n",
       "         -3.0251e-01,  2.0207e-01,  2.6936e-01,  1.5373e-01, -1.3371e-01,\n",
       "         -2.2086e-01, -3.6102e-01, -2.2652e-01,  6.0436e-02,  2.6397e-01,\n",
       "          5.6464e-02,  3.9212e-01,  2.8207e-01,  2.7142e-02, -2.6618e-01,\n",
       "         -2.0689e-01, -6.8485e-02,  1.1603e-01, -1.1868e-01,  1.8313e-01,\n",
       "          2.6788e-01, -5.7617e-01, -1.8857e-01, -3.0472e-01, -3.4169e-01,\n",
       "         -3.4408e-01, -1.2890e-01,  1.4765e-01,  2.3960e-01,  1.6222e-01,\n",
       "          6.4669e-02,  4.4015e-01, -3.8541e-01, -2.1806e-01, -4.2904e-01,\n",
       "          5.4415e-02, -2.8047e-02,  1.4074e-01, -9.4311e-02, -5.6996e-01,\n",
       "         -2.2734e-01,  1.9386e-01,  5.3970e-02,  7.3151e-02,  2.5218e-01,\n",
       "         -4.0559e-01,  6.2593e-02,  3.8084e-01,  3.4841e-02, -2.4797e-01,\n",
       "          7.0257e-02, -2.0249e-01, -2.5288e-01, -1.3323e-02, -2.8342e-01,\n",
       "         -3.9124e-01, -6.3932e-02, -5.4704e-02,  1.3348e-01, -5.7497e-02,\n",
       "          5.2849e-01,  2.0945e-01,  1.0306e-01, -8.9488e-02, -1.4059e-01,\n",
       "          3.0177e-01, -1.5960e-01,  9.8198e-03, -3.9965e-01, -9.6539e-02,\n",
       "          1.2458e-01,  1.7318e-01,  1.4087e-02, -5.1392e-02,  1.2362e-01,\n",
       "          2.4893e-01, -1.7123e-01,  4.9481e-02,  1.9710e-01,  1.9610e-01,\n",
       "         -3.1379e-02,  3.1352e-01,  2.0171e-01, -8.1959e-02,  9.3478e-02,\n",
       "         -1.8127e-01,  1.3994e-01, -4.5135e-01,  1.7148e-01,  3.5662e-01,\n",
       "         -1.8820e-01, -3.1262e-01, -1.2490e-01,  1.0041e+00,  6.7420e-01,\n",
       "         -1.5737e-01, -6.2441e-02,  3.6326e-02, -1.7937e-01,  4.9139e-02,\n",
       "          3.2090e-02, -2.5588e-01, -2.7502e-01,  2.8802e-01,  1.2156e-01,\n",
       "          2.1878e-02,  1.5352e-02,  4.5835e-02,  2.7540e-01, -4.4944e-01,\n",
       "          1.9665e-01, -3.2587e-01,  8.8193e-02,  1.5765e-01,  2.2407e-01,\n",
       "          3.0034e-02, -9.8411e-02, -1.1399e-01,  3.5459e-01,  2.8699e-01,\n",
       "         -1.3911e-02,  4.0382e-02, -1.4545e-01, -3.1834e-01, -3.8069e-02,\n",
       "          2.2887e-01,  4.2346e-01, -5.5149e-01,  9.5916e-03, -1.1379e-01,\n",
       "         -6.0323e-01, -3.3411e-02,  5.0654e-01, -1.6463e-01, -2.8604e-02,\n",
       "          2.9499e-01,  1.5432e-01,  1.3346e-01,  2.8638e-01, -4.8732e-01,\n",
       "         -4.5242e-02, -4.6373e-02,  8.9917e-02,  3.5916e-01,  3.3567e-01,\n",
       "          4.9582e-03,  2.4183e-01,  4.3107e-02, -2.5387e-01,  6.8911e-01,\n",
       "          1.4524e-02, -1.8831e-01, -7.7928e-03,  9.9079e-02, -1.3267e-01,\n",
       "          2.1040e-01,  2.4451e-02, -1.2868e-01,  7.6771e-02,  2.2358e-01,\n",
       "          2.1363e-02,  1.5505e-01,  1.6259e-01, -1.8357e-01, -7.3623e-02,\n",
       "         -3.5069e-01,  1.7177e-01, -1.5180e-01, -7.1047e-02,  9.9853e-02,\n",
       "          1.8973e-01, -2.1482e-01, -1.1957e+00, -6.4386e-02, -1.0183e-01,\n",
       "         -2.8866e-01, -2.3579e-01,  5.7804e-02,  3.9434e-01,  1.4309e-01,\n",
       "         -2.9197e-01, -2.7622e-01,  1.8227e-02,  3.5610e-01,  3.6737e-01,\n",
       "         -3.6526e-02,  1.5294e-02,  6.3930e-02,  1.3529e-01, -2.0981e-01,\n",
       "          3.1625e-01, -2.9475e-01, -4.5289e-01, -4.4635e-02, -2.5913e-01,\n",
       "         -1.0506e-01, -6.0628e-02,  4.8415e-01, -2.0168e-01, -1.9157e-01,\n",
       "         -2.6061e-01,  1.4406e-01,  8.8023e-02,  2.1032e-01, -3.5765e-01,\n",
       "         -1.2280e-01, -1.7285e-01,  3.1093e-01,  1.0568e-01,  3.2211e-01,\n",
       "         -1.2516e-02,  2.7192e-01,  1.8065e-01,  5.3520e-01, -2.6240e-01,\n",
       "         -1.9043e-01,  3.2592e-02, -1.3585e-01,  3.0144e-01,  4.2537e-01,\n",
       "         -1.0657e-01, -2.7766e-01, -4.2115e-01, -2.4864e-01,  8.9156e-02,\n",
       "         -1.0591e+00,  2.0945e-01,  7.2522e-02, -9.3397e-02, -5.2589e-02,\n",
       "          5.0095e-03,  5.0006e-02, -3.8323e-01, -1.8903e-02,  9.8762e-02,\n",
       "          1.3598e-01,  2.4347e-01, -2.5929e-01, -1.7952e-01, -3.1586e-01,\n",
       "          3.1337e-01, -9.6990e-02,  1.4818e-01,  1.6314e-01,  8.5111e-02,\n",
       "         -5.2210e-02,  4.1340e-02,  1.0499e-01, -6.7748e-02, -2.0251e-02,\n",
       "         -3.7914e-01, -1.1590e-01, -6.1487e-02, -3.1782e-02,  1.2754e-01,\n",
       "          1.5155e-01, -2.2810e-01, -3.1059e+00, -1.5301e-01,  1.1388e-01,\n",
       "         -8.3143e-02,  3.1305e-02,  3.9980e-02,  4.0847e-01, -9.9847e-02,\n",
       "          8.9949e-02, -1.4907e-01, -3.8149e-02, -2.4376e-01,  1.4823e-01,\n",
       "         -1.4942e-02, -2.6645e-01, -1.3315e-02]),\n",
       " tensor([ 4.0671e-01,  1.2627e-01,  3.9745e-02, -1.4173e-02, -3.8395e-02,\n",
       "         -7.9595e-02,  1.9563e-01,  2.1706e-01,  1.1774e-01, -3.1288e-01,\n",
       "         -2.1280e-01, -3.5979e-02,  8.9854e-02,  2.5487e-01, -3.2113e-01,\n",
       "         -3.6172e-01, -9.0375e-02,  7.0483e-02,  9.8730e-02, -7.5684e-02,\n",
       "          4.9851e-01,  6.5216e-02,  3.8619e-01,  7.5372e-02,  2.5967e-01,\n",
       "          2.4186e-01, -3.4215e-01, -3.0940e-01, -3.4881e-01, -1.1700e-01,\n",
       "         -1.6226e-01,  8.4748e-02, -2.3650e-01,  2.7353e-01, -3.0424e-02,\n",
       "         -2.8942e-01,  1.5108e-01,  1.2020e-01, -3.2490e-01, -1.0047e-02,\n",
       "         -1.4599e-01, -4.8156e-02, -7.6857e-02, -2.0781e-02,  1.3324e-01,\n",
       "         -7.6177e-02,  1.1853e-01,  2.4444e-01, -4.1215e-01,  2.5102e-01,\n",
       "         -6.7232e-02, -1.3689e-01,  2.4767e-01,  1.2657e-01, -1.1423e-01,\n",
       "          2.3071e-01,  3.1274e-01,  9.5313e-02, -4.8463e-02, -1.2408e-01,\n",
       "          2.8373e-01, -4.8179e-02, -1.2094e-01,  3.7641e-01,  1.4285e-01,\n",
       "          3.7777e-01,  4.6777e-01,  7.8876e-02, -4.6505e-01, -7.5643e-02,\n",
       "         -4.2589e-01, -2.8185e-01,  4.1024e-01,  2.8058e-02,  2.7728e-01,\n",
       "          1.6230e-02, -2.9548e-01,  3.4139e-01,  2.2926e-01,  1.1281e-01,\n",
       "          2.2633e-01,  6.1367e-02,  4.3897e-02,  3.4734e-01,  4.6171e-02,\n",
       "          5.6083e-02, -1.5982e-01, -1.9832e-01, -1.4944e-01,  1.5054e-01,\n",
       "         -3.2367e-01, -4.0418e-02,  2.4812e-01,  1.3766e-01,  2.8567e-02,\n",
       "         -2.1155e-02,  3.2543e-02,  5.5690e-03,  2.6577e-01,  9.6448e-02,\n",
       "         -2.7350e-01, -4.0304e-01,  7.8649e-02,  3.0928e-01, -3.7892e-01,\n",
       "         -9.8258e-02,  7.2001e-02, -1.0410e-01,  6.4779e-02, -8.4824e-01,\n",
       "          7.4821e-02,  1.2316e-01, -2.6899e-01, -6.8223e-02, -1.8873e-01,\n",
       "          2.2274e-01,  3.2221e-02, -1.7207e-01,  2.2374e-01,  9.4567e-02,\n",
       "         -3.3094e-01, -3.3758e-02,  1.4308e-01,  6.2095e-01,  1.2703e-01,\n",
       "          1.3257e-01, -2.0996e-01, -3.8138e-01, -4.3843e-02, -3.0859e-01,\n",
       "         -3.4402e-02,  4.8675e-01,  2.8967e-01,  3.3775e-01, -7.3752e-02,\n",
       "         -5.3511e-02,  1.3929e-01,  2.8264e-01, -1.7266e-01, -5.6072e-02,\n",
       "          2.1102e-01,  3.6924e-01, -9.5515e-01, -2.5841e-01,  5.0395e-01,\n",
       "         -1.8121e-01,  2.4873e-01,  6.7970e-03, -1.3983e-01, -6.9705e-02,\n",
       "          3.6464e-01,  1.0036e-01, -2.8625e-01, -4.3543e-01, -4.9238e-01,\n",
       "         -3.1076e-01, -1.8008e-01, -5.6363e-02,  3.8655e-01,  5.1730e-01,\n",
       "          2.0374e-01,  2.4973e-01,  3.2616e-01,  2.4793e-01, -3.4705e-01,\n",
       "         -2.2552e-01, -4.1477e-01,  5.9647e-01,  1.1663e-01,  3.1517e-01,\n",
       "         -4.1001e-01, -9.7695e-02,  5.0291e-01,  1.1487e-01, -1.4610e-01,\n",
       "          1.5835e-01,  2.3121e-01, -7.3730e-02, -2.3729e-02, -1.0515e-01,\n",
       "         -2.9919e+00,  5.3655e-02,  1.8021e-01, -1.6901e-01,  4.1549e-03,\n",
       "         -1.9660e-01,  2.1628e-01, -2.7547e-01,  1.9858e-01,  2.5040e-01,\n",
       "         -1.9071e-01, -1.5905e-01, -3.3964e-01,  7.3137e-02,  1.2756e-01,\n",
       "         -2.5424e-01,  2.1822e-01, -5.2775e-02,  7.1247e-03,  1.6486e-01,\n",
       "          4.2382e-02, -2.3952e-01,  3.3620e-01,  1.9368e-01, -5.6311e-02,\n",
       "          9.5920e-01, -1.2492e-02, -2.3788e-01,  4.3681e-01,  1.5941e-01,\n",
       "         -7.3006e-01,  6.1934e-01, -2.0571e-01, -3.2861e-01,  4.8840e-02,\n",
       "         -1.8797e-01,  6.1734e-02, -3.5387e-01, -3.5295e-01,  2.9918e-01,\n",
       "         -9.4208e-02, -4.5437e-02,  2.3904e-02,  2.6369e-03, -2.3147e-01,\n",
       "         -4.0484e-01,  5.2308e-01, -1.9530e-01, -8.6014e-02, -2.2455e-01,\n",
       "         -2.4230e-01, -1.9724e-01,  3.3306e-01,  1.4905e-01, -2.2456e-01,\n",
       "          3.3293e-01,  9.7007e-02, -1.9542e-01, -2.9307e-01, -4.2753e-01,\n",
       "          2.4152e-01,  9.7454e-02,  7.7475e-01,  3.9043e-01, -2.5903e-01,\n",
       "          1.3622e-01,  4.9369e-01,  2.0109e-01,  3.4812e-01, -1.3104e-01,\n",
       "          1.6682e-02, -9.3139e-01, -4.1414e-02, -2.6252e-01,  6.6500e-03,\n",
       "          7.4489e-02,  2.3087e-01, -2.1519e-01,  3.7523e-01, -1.2505e-01,\n",
       "          1.0532e-01,  1.7307e-01,  5.3270e-01, -1.2634e-01, -4.3856e-02,\n",
       "          9.2262e-02,  1.8472e-01, -4.1810e-02,  1.8058e-01, -8.0854e-02,\n",
       "          2.8962e-01,  9.3413e-02, -7.7771e-03, -1.2581e+00,  1.2411e-01,\n",
       "         -3.3523e-01,  3.3998e-01,  5.2303e-02,  1.0392e-01, -2.1363e-01,\n",
       "         -1.5680e-01,  1.2705e-01, -1.4267e-01,  1.5705e-01,  5.5586e-01,\n",
       "         -4.8625e-01, -2.5283e-01, -1.8483e-01,  2.1467e-01, -4.8731e-01,\n",
       "         -4.7506e-02, -1.3043e-01, -2.1141e-02,  1.2352e-01,  1.6634e-01,\n",
       "         -8.9860e-03, -1.2153e-02,  6.4183e-02, -2.9551e-01,  1.5076e-01,\n",
       "         -5.9627e-02, -2.9818e-01, -1.7834e-01, -1.7580e-01, -1.2627e-01,\n",
       "         -1.7853e-01, -5.1433e-02,  1.8515e-01, -2.0464e+00, -1.5486e-02,\n",
       "          1.5788e-01, -5.8698e-01,  5.2008e-02, -2.1698e-01, -8.9955e-02,\n",
       "          2.6853e-01, -2.4707e-01,  9.9636e-02,  5.6900e-01, -3.0297e-01,\n",
       "          2.2199e-01,  4.6221e-01,  1.1606e-01,  2.2402e-01,  1.1397e-02,\n",
       "         -3.9882e-02, -4.7500e-01,  1.3749e-01, -1.1967e-01, -3.1283e-01,\n",
       "          2.4170e-01, -1.8523e-01,  3.1099e-01,  3.2346e-01, -3.6412e-01,\n",
       "          1.2145e-01, -2.7890e-01, -1.0121e-01, -1.6983e-01, -1.4571e-01,\n",
       "         -8.3765e-02, -5.1049e-02,  3.1937e-01,  1.0952e-01,  2.1210e-01,\n",
       "         -9.2881e-02,  7.3336e-01, -1.3578e-02,  3.1060e-02, -3.1273e-02,\n",
       "          7.5674e-02,  1.8364e-01, -3.8506e-02,  6.0161e-02, -1.5951e-01,\n",
       "         -4.2515e-01, -2.8582e-01, -5.8891e-02,  2.7847e-02, -1.9250e-01,\n",
       "         -3.4311e-02, -1.5714e-01, -1.4848e-01, -2.5328e-01, -1.2058e-01,\n",
       "         -2.6039e-01, -5.8675e-02, -2.4007e-01,  2.8522e-01, -1.8465e-01,\n",
       "          1.9613e-03,  5.5816e-01, -2.7955e-01, -2.2542e-01, -5.9774e-02,\n",
       "         -1.4082e-01, -2.2284e-01,  3.5859e-01, -1.4638e-01,  1.7522e-02,\n",
       "          6.5668e-02, -7.2109e-01, -3.5343e-01,  3.3170e-01, -2.0963e-01,\n",
       "         -2.6794e-01,  2.9293e-01, -4.8465e-01,  1.2520e-01,  2.7806e-01,\n",
       "          1.5801e-02,  4.4655e-01, -2.4850e-03, -8.5466e-02,  4.3475e-01,\n",
       "         -7.1826e-01,  1.0742e-01, -1.0910e-02,  1.0601e-01,  1.3561e-01,\n",
       "          1.0497e-01,  8.1135e-02,  2.4320e-01,  3.2340e-01,  2.7077e-01,\n",
       "         -4.1726e-01,  9.0446e-02, -1.4240e-01, -2.3685e-01, -3.8827e-01,\n",
       "         -1.7926e-02,  2.8429e-01,  6.8166e-02,  3.9660e-02, -6.8718e-01,\n",
       "         -2.0915e-01, -5.8211e-01, -1.1832e-01,  8.0541e-02, -9.9917e-05,\n",
       "          2.7452e-01,  2.5892e-01,  3.7805e-02, -3.1167e-01, -6.4310e-03,\n",
       "          4.2293e-01, -2.6959e-01,  2.7114e-01,  2.0874e-01,  2.5996e-01,\n",
       "          1.7896e-01,  1.2247e-02, -1.0996e-01, -1.0006e-01, -2.4319e-02,\n",
       "         -3.5089e-01, -4.9228e-01,  8.1864e-03,  2.5738e-01,  1.4141e-01,\n",
       "          1.1940e-01, -3.2069e-01, -1.6701e-01, -1.9281e-02,  1.1107e-01,\n",
       "          2.5872e-01,  9.9216e-02,  5.3110e-01,  3.9123e-01, -1.1272e-01,\n",
       "         -5.5340e-01,  1.4662e-01,  4.4500e-02,  3.6894e-01,  5.3768e-02,\n",
       "          1.9137e-01,  1.7440e-01,  3.7443e-01,  1.4748e-01, -2.8576e-01,\n",
       "          3.0395e-01, -1.9375e-01,  4.4869e-02, -7.6105e-02,  1.7879e-01,\n",
       "         -1.2324e-01, -4.0318e-01,  2.5635e-02, -2.2467e-02,  1.6659e-01,\n",
       "         -8.0040e-02,  1.6137e-01,  1.2848e-02,  1.0967e-01,  2.5945e-01,\n",
       "         -3.3115e-02, -3.9968e-01,  2.5985e-01,  4.0794e-01, -3.0238e-01,\n",
       "          9.7801e-02,  1.2640e-01, -2.4615e-01,  2.9763e-01,  7.7337e-02,\n",
       "         -5.2367e-01, -5.7211e-02, -9.3995e-02,  2.4452e-01, -5.7051e-02,\n",
       "         -1.1812e-02,  1.8879e-01,  3.7398e-01,  7.6282e-02, -6.3337e-01,\n",
       "         -1.2915e-02, -3.0972e-02,  3.0977e-01,  2.5144e-01, -2.9486e-01,\n",
       "         -6.5806e-01, -3.3055e-01, -3.5118e-01,  1.4749e-02,  2.0229e-01,\n",
       "          1.9502e-01,  3.2330e-01,  2.6093e-01,  2.3849e-01, -1.3624e-01,\n",
       "         -2.0091e-01, -8.1894e-02,  1.3058e-01,  7.8027e-02,  2.0467e-01,\n",
       "          1.8471e-01, -2.8885e-01, -2.4637e-02,  3.3076e-01, -3.0043e-01,\n",
       "         -2.1679e-01, -2.4324e-01,  2.2938e-01,  3.3729e-01,  4.0154e-01,\n",
       "         -1.8830e-02,  4.3958e-01, -3.1988e-01, -2.9977e-01, -4.1113e-01,\n",
       "         -1.4368e-01, -5.6987e-02, -1.1635e-01, -2.2472e-01, -5.4985e-01,\n",
       "         -1.6766e-02,  8.7208e-02,  6.0721e-02, -3.0726e-02,  5.3550e-02,\n",
       "          3.5639e-02,  1.2908e-01,  5.4473e-01,  4.6044e-03, -5.5091e-01,\n",
       "          1.4753e-01, -2.8857e-01, -5.5792e-02,  1.7206e-04, -4.2056e-01,\n",
       "         -4.6986e-01,  1.0445e-01, -8.2009e-02,  2.7824e-01,  1.1397e-01,\n",
       "          4.1926e-01,  4.6348e-01,  1.9817e-01, -2.3289e-01, -1.2190e-01,\n",
       "          2.4413e-01,  5.2050e-02,  1.5359e-01, -4.3760e-01, -6.8894e-03,\n",
       "          4.3126e-01,  3.4411e-01, -2.5156e-01, -1.7658e-01,  3.6604e-01,\n",
       "          2.3266e-01,  7.5036e-03, -4.1487e-02,  2.5871e-01, -1.8972e-02,\n",
       "          1.3352e-02,  4.3524e-01,  3.6778e-01, -2.1407e-01,  2.9531e-01,\n",
       "         -3.9939e-01,  2.8629e-01, -3.1987e-01,  2.5404e-01,  1.4324e-01,\n",
       "         -3.0496e-01, -6.4852e-02, -9.6860e-02,  1.0242e+00,  6.5001e-01,\n",
       "          1.0029e-01, -1.4514e-01,  2.7344e-01, -1.9750e-01, -4.3191e-02,\n",
       "         -9.8263e-02, -1.8994e-01, -3.0826e-01,  8.0924e-02, -2.5279e-01,\n",
       "          1.7256e-01,  4.4479e-01, -2.6983e-01,  2.0068e-01, -4.3314e-01,\n",
       "          1.0872e-01, -3.0517e-01,  3.8937e-02,  5.6782e-02,  3.0923e-01,\n",
       "          1.2548e-01, -2.1847e-01, -1.4793e-01,  4.0825e-01,  3.7053e-01,\n",
       "         -1.7427e-01, -1.5545e-01,  1.7196e-01, -4.4583e-01, -3.8482e-02,\n",
       "          5.7845e-03,  3.7938e-01, -5.2303e-01,  1.8204e-01,  9.5759e-02,\n",
       "         -6.7569e-01, -2.9871e-01,  2.8233e-01,  1.7945e-01,  2.5337e-01,\n",
       "          4.3874e-01,  1.4356e-01,  2.6622e-01,  3.4618e-01, -4.9774e-01,\n",
       "          1.4283e-01,  2.5510e-02,  4.8613e-01,  2.7687e-01,  3.0719e-01,\n",
       "         -3.3163e-01,  9.0935e-02, -4.6723e-02, -1.8511e-01,  4.8557e-01,\n",
       "          5.0578e-01, -7.8146e-03, -3.5880e-01,  2.3992e-01,  2.6860e-01,\n",
       "          2.5618e-01, -6.5480e-02, -1.2551e-01,  2.7544e-01,  2.0315e-01,\n",
       "         -4.0598e-01,  1.9561e-01,  1.7122e-01, -6.2165e-02, -1.7322e-01,\n",
       "         -2.0476e-01, -3.8937e-02,  7.4615e-02, -2.2420e-01, -2.7741e-02,\n",
       "          4.4249e-02, -2.2879e-01, -1.2607e+00, -1.2303e-01, -5.1390e-02,\n",
       "         -1.8827e-02, -4.8558e-01, -8.8480e-02,  2.0222e-01,  9.9587e-02,\n",
       "         -4.1016e-01, -3.5365e-01, -2.1712e-01,  3.3654e-01,  5.6702e-01,\n",
       "          1.2017e-01, -2.5481e-01, -1.4803e-01,  1.6958e-01, -2.3965e-01,\n",
       "          3.7202e-02, -6.2420e-01, -2.5611e-01,  3.7075e-01, -1.9465e-01,\n",
       "         -2.6927e-01, -1.1237e-01,  5.9804e-01, -4.1407e-01, -1.1044e-01,\n",
       "         -6.9356e-02,  8.0290e-02,  2.4150e-02,  3.2992e-01, -6.9294e-01,\n",
       "         -1.1836e-01, -2.2444e-01,  1.3145e-02,  1.1722e-01,  1.2314e-01,\n",
       "         -1.2799e-01,  1.5984e-01,  3.2423e-01,  7.1281e-01,  8.7272e-02,\n",
       "         -3.3658e-01,  6.1675e-02, -1.1603e-01,  1.7232e-01,  3.8234e-01,\n",
       "         -1.5431e-01, -3.6544e-02, -7.3700e-02, -2.4345e-01,  4.0514e-02,\n",
       "         -1.2205e+00,  3.8984e-01, -2.1411e-01, -2.7918e-01, -3.1732e-01,\n",
       "          1.6179e-02,  1.1050e-01, -3.6862e-01, -3.1469e-01, -1.6314e-01,\n",
       "         -1.3878e-01,  3.9279e-01, -3.8652e-01, -4.7735e-01, -5.5843e-01,\n",
       "          8.7031e-02,  3.1343e-01,  6.2318e-02, -4.7068e-02,  2.2324e-01,\n",
       "          2.0530e-01, -2.1676e-01,  2.3316e-01,  8.0025e-02,  4.4640e-02,\n",
       "         -2.2946e-01, -6.9905e-02, -2.7956e-01, -2.1730e-01,  2.4044e-01,\n",
       "          2.7339e-01,  1.2787e-02, -2.8824e+00, -2.7392e-01, -1.9121e-01,\n",
       "         -1.5718e-01,  3.5480e-01, -4.9164e-02,  3.5465e-01, -1.7456e-01,\n",
       "          2.7740e-02, -1.8620e-01,  6.1098e-02, -4.5587e-01,  1.9815e-01,\n",
       "         -7.4560e-02, -1.1253e-01, -2.2794e-01]),\n",
       " tensor([ 2.2028e-01, -4.8702e-02,  9.9772e-02, -4.9296e-02, -3.1421e-01,\n",
       "         -6.6486e-02,  2.9340e-01,  1.2861e-02,  4.1380e-01, -4.7059e-01,\n",
       "         -1.6186e-01, -3.5094e-01,  3.0729e-02,  8.7700e-02, -3.3046e-01,\n",
       "         -5.2333e-02,  9.3150e-02,  1.3227e-01, -8.4715e-02,  1.9537e-01,\n",
       "         -3.0598e-02, -1.4150e-01,  2.3131e-01,  7.6244e-02,  1.4546e-01,\n",
       "          1.6151e-01, -1.2474e-01, -2.9697e-01, -2.4942e-01,  2.0243e-01,\n",
       "          1.3057e-02, -8.6327e-02, -2.6093e-01,  2.7540e-01, -6.4531e-01,\n",
       "         -1.9806e-01, -1.4807e-01,  6.4956e-03, -3.2594e-01, -2.7931e-02,\n",
       "          3.4338e-02, -2.6061e-02,  3.6161e-02,  2.2832e-01, -2.7056e-01,\n",
       "         -1.2216e-01, -5.2446e-01,  2.0963e-02, -9.8366e-02,  1.2080e-01,\n",
       "         -2.8228e-01,  2.0986e-02, -7.2432e-02,  2.3025e-01,  5.8684e-02,\n",
       "          7.1835e-02,  1.9086e-01, -6.7667e-02, -2.2977e-01,  5.8121e-02,\n",
       "         -1.9382e-02,  3.4060e-01, -7.1416e-02, -1.1509e-01,  2.7196e-01,\n",
       "          1.8570e-01,  3.7872e-01, -2.3889e-01, -4.8150e-01,  2.6324e-01,\n",
       "         -3.5846e-01, -4.4451e-01,  3.2381e-01, -1.1825e-01,  5.6349e-01,\n",
       "         -1.6991e-01, -1.5211e-01,  4.2931e-01, -1.3300e-01, -8.2589e-03,\n",
       "          4.2756e-01,  3.4373e-01,  1.0601e-01,  3.5466e-01,  1.3538e-01,\n",
       "          1.4419e-01, -5.0601e-02, -4.1886e-03, -1.5881e-01,  2.7493e-01,\n",
       "          2.3462e-01,  4.3924e-02,  1.4984e-01, -1.5977e-01,  3.3983e-02,\n",
       "         -2.7299e-01,  1.3279e-01, -1.3562e-02, -7.5510e-02, -2.4212e-01,\n",
       "         -5.0039e-02, -5.2599e-01, -1.8820e-01,  3.1312e-01, -3.5165e-01,\n",
       "          1.3649e-02,  4.4362e-02,  1.0240e-01,  1.3386e-01, -9.0893e-01,\n",
       "          3.3406e-01,  2.7606e-01,  2.1083e-01, -3.9187e-02, -7.7714e-02,\n",
       "          4.8357e-01,  2.6959e-01, -8.8405e-02,  2.2247e-01,  3.6275e-01,\n",
       "         -4.3484e-01, -1.1395e-02,  4.6385e-01,  4.8213e-01,  2.7739e-01,\n",
       "          3.8773e-01, -9.1554e-02, -4.3218e-01, -3.4101e-01, -1.6319e-01,\n",
       "         -2.3258e-01,  5.2539e-01,  4.1906e-01,  2.0827e-01, -8.7911e-02,\n",
       "         -2.8278e-02,  1.5612e-03, -4.4673e-01, -1.3304e-01, -6.3728e-02,\n",
       "         -5.6371e-02,  2.8796e-01, -9.7605e-01, -2.4681e-01,  3.3294e-01,\n",
       "         -1.0272e-01,  3.1400e-01, -1.6690e-01,  8.2670e-02, -1.5790e-01,\n",
       "          4.7908e-01, -7.0235e-03,  6.7408e-02, -4.1086e-01, -4.0695e-01,\n",
       "         -2.4507e-01, -5.2190e-02,  6.6499e-02,  2.6222e-01,  4.5228e-01,\n",
       "          4.1073e-01,  2.1507e-01,  8.2951e-02,  3.1090e-02,  1.8930e-01,\n",
       "         -1.8799e-01, -2.3421e-01,  7.3895e-01,  4.0186e-01, -4.4102e-02,\n",
       "         -2.1522e-01, -7.4579e-01,  5.4692e-01,  4.8979e-01, -1.7377e-01,\n",
       "          1.7222e-01,  5.9055e-01, -2.9459e-03,  1.7365e-03, -1.2978e-01,\n",
       "         -2.6433e+00,  1.4459e-01, -2.5136e-01, -8.6369e-02,  1.8725e-01,\n",
       "          1.2088e-01, -5.0138e-02, -5.9447e-01,  3.7087e-01, -2.5661e-01,\n",
       "         -1.9876e-01, -1.8068e-01, -3.0573e-01, -9.0193e-02,  2.4682e-01,\n",
       "         -3.3160e-01, -1.2425e-01, -2.4229e-01,  3.7540e-01,  4.6265e-02,\n",
       "          1.7175e-01, -1.8451e-01,  3.6161e-01,  1.3759e-01, -3.4315e-02,\n",
       "          1.1457e+00,  1.8425e-01, -3.5582e-01, -1.4730e-01,  1.9349e-01,\n",
       "         -7.1154e-01,  7.5368e-01,  2.1484e-01, -4.2632e-01,  2.9495e-01,\n",
       "         -3.0029e-01,  4.7658e-01, -3.4235e-01, -3.7283e-01,  1.0645e-01,\n",
       "          2.3302e-01, -3.7453e-01, -1.5881e-01,  2.8368e-01, -4.7772e-01,\n",
       "         -6.2155e-01,  1.0228e-01, -5.1316e-02,  1.5112e-01, -2.3090e-01,\n",
       "         -2.2993e-01, -1.3773e-01,  3.1078e-01,  1.6845e-01, -7.7465e-02,\n",
       "          5.2060e-01,  7.9434e-02, -2.1128e-01, -2.2126e-01,  7.0338e-02,\n",
       "         -1.7410e-01,  5.3974e-01,  5.2361e-01,  1.0323e-01, -4.8326e-01,\n",
       "          1.0133e-01,  6.5627e-01, -2.9864e-04,  1.5758e-01,  6.9021e-02,\n",
       "         -3.0908e-01, -4.5022e-01, -2.3221e-01, -2.6593e-01,  4.6344e-02,\n",
       "         -1.8377e-01, -5.8359e-02, -1.7563e-01,  2.9892e-01, -1.6763e-01,\n",
       "         -7.5137e-02, -1.3349e-01,  6.0603e-01, -2.0659e-01, -4.8243e-01,\n",
       "          3.8199e-01,  2.6780e-01, -1.2044e-01,  1.0368e-01,  2.8229e-01,\n",
       "          1.1329e-01, -2.2055e-01,  1.2027e-02, -8.0980e-01, -1.3895e-01,\n",
       "          1.2158e-01,  3.4794e-01, -1.2617e-01,  3.0144e-01,  5.8900e-02,\n",
       "          6.9504e-02,  3.7887e-01, -1.8556e-01, -6.9575e-02,  3.5423e-01,\n",
       "         -6.6954e-01, -3.0709e-01, -6.3393e-01,  4.7858e-01, -5.7796e-01,\n",
       "          6.6025e-02,  2.6828e-01,  4.6737e-01,  1.2064e-01,  1.6772e-01,\n",
       "          1.6260e-02,  1.8768e-02,  3.0428e-01, -4.8309e-01,  4.8458e-02,\n",
       "         -3.3081e-01, -3.2223e-01, -1.6983e-01, -1.3454e-01, -1.1693e-01,\n",
       "          7.0886e-02,  3.3037e-02,  8.7714e-02, -1.7182e+00, -3.1220e-01,\n",
       "          3.3256e-01, -3.1213e-01,  2.2555e-01,  1.4514e-01,  1.5166e-01,\n",
       "         -1.6108e-01, -3.2112e-01,  2.5111e-02,  3.3858e-01, -2.6513e-01,\n",
       "          1.5918e-01,  5.0920e-01, -4.2760e-02, -2.8456e-01, -1.2310e-01,\n",
       "          4.0018e-02, -4.4574e-01,  1.7411e-01, -3.3155e-01, -1.2400e-01,\n",
       "          5.1731e-01, -3.1016e-01,  5.0817e-01,  3.7294e-01, -2.8188e-01,\n",
       "          1.0825e-01, -1.7044e-01, -6.7517e-02, -2.3645e-01, -1.9753e-01,\n",
       "         -2.1330e-02,  4.3628e-02,  3.0830e-01,  3.0291e-01,  3.6273e-01,\n",
       "          2.6015e-01,  6.0782e-01, -3.2247e-01,  1.5836e-01,  4.5134e-01,\n",
       "          3.2716e-01, -2.3575e-01,  1.0880e-01, -1.1406e-01,  1.1716e-01,\n",
       "         -2.9632e-01,  2.8845e-01,  1.2092e-01,  2.2335e-01, -3.2843e-01,\n",
       "         -1.8396e-01,  3.5423e-02, -1.2045e-01, -4.3011e-01, -2.3162e-01,\n",
       "          2.9921e-01,  1.9577e-03, -3.0128e-01,  3.7552e-01, -2.6281e-01,\n",
       "          1.2651e-01,  4.0722e-01, -5.7356e-01,  1.8804e-01, -2.5925e-02,\n",
       "         -1.7422e-01,  4.8220e-02,  1.4446e-01, -1.8990e-02, -3.5520e-01,\n",
       "         -2.2058e-01, -8.1828e-01, -4.8567e-01,  1.3966e-01, -3.3391e-01,\n",
       "         -2.1329e-01,  1.8236e-01, -2.9098e-01, -1.3726e-01, -7.9880e-02,\n",
       "          2.4242e-01,  5.6002e-02, -3.3422e-02,  3.2581e-01,  2.5515e-01,\n",
       "         -4.0170e-01, -1.5052e-01, -3.9782e-01, -2.2912e-03, -7.2831e-02,\n",
       "          4.4325e-01,  4.6818e-01, -1.3462e-01,  3.6060e-01,  5.1997e-01,\n",
       "         -6.3072e-01,  2.0749e-01, -6.9704e-02, -9.6512e-02, -1.0099e-01,\n",
       "          2.5661e-01,  1.5737e-01, -1.6909e-01,  2.6763e-01, -8.5522e-01,\n",
       "         -2.6868e-01, -5.3263e-02, -4.4598e-02,  8.4205e-02, -4.3484e-02,\n",
       "          2.4881e-01,  2.1286e-01,  1.1130e-01, -1.5057e-01, -3.6702e-01,\n",
       "          1.2034e-01,  6.0808e-02,  3.2216e-01,  3.1731e-01,  4.7788e-01,\n",
       "         -1.1937e-01,  2.7191e-02, -3.3852e-01,  2.8115e-02,  2.4836e-01,\n",
       "         -4.1807e-01, -4.7511e-01, -1.9571e-01,  1.2904e-01, -4.2936e-02,\n",
       "          2.1564e-01, -1.8195e-01, -1.0546e-01,  2.1824e-01,  2.7475e-01,\n",
       "          3.5053e-01,  4.0041e-02,  5.8378e-01,  4.6971e-01,  5.3622e-02,\n",
       "         -6.5577e-01,  1.2172e-01,  4.6586e-02,  3.4033e-01,  3.6501e-02,\n",
       "         -5.8892e-02,  2.3122e-01,  3.1300e-01,  4.4863e-01, -3.1383e-01,\n",
       "          4.5334e-01,  4.9262e-02, -3.3629e-02, -5.4121e-01,  2.5624e-01,\n",
       "         -4.2399e-01, -4.7882e-01, -9.6839e-03, -6.8853e-03,  1.0780e-01,\n",
       "          3.5374e-02,  3.2183e-01, -1.3832e-02, -1.7076e-02,  1.5512e-01,\n",
       "          8.9138e-02, -6.4691e-01,  1.2549e-01,  5.8684e-01,  9.0252e-02,\n",
       "          1.7119e-01,  1.1137e-01, -4.0935e-01,  1.6609e-01,  1.7884e-02,\n",
       "         -2.1146e-01,  3.2690e-02, -1.6260e-01, -3.7430e-02,  1.3562e-01,\n",
       "          1.8691e-01,  1.6509e-03,  2.1921e-01, -2.0446e-01, -5.3708e-01,\n",
       "         -2.1829e-01,  2.8363e-01,  5.0787e-01, -3.7155e-02, -3.4471e-01,\n",
       "         -4.7112e-01, -3.5090e-01, -1.7235e-01,  1.4726e-01,  1.2553e-01,\n",
       "         -2.8821e-01, -5.7117e-02,  4.0504e-01,  4.1675e-01,  5.2867e-01,\n",
       "         -3.3765e-01,  1.5388e-01, -4.2250e-01, -2.9559e-01,  1.5909e-01,\n",
       "          1.5018e-01, -3.1298e-01, -2.1631e-01,  4.4784e-01, -1.5947e-01,\n",
       "         -3.9362e-01, -1.4031e-01, -1.5128e-01,  4.0673e-01,  3.3989e-01,\n",
       "         -7.4822e-02,  5.4203e-01, -3.9581e-01, -2.4196e-01, -4.2194e-01,\n",
       "          6.0973e-02, -3.3476e-02,  4.7894e-02, -4.5327e-02, -3.2647e-01,\n",
       "         -5.2105e-01,  1.0994e-01, -2.3329e-01,  2.7570e-01,  1.9513e-01,\n",
       "         -2.4019e-02,  9.9097e-02,  3.7938e-01, -3.1985e-01, -4.1726e-01,\n",
       "          1.9208e-01, -1.9193e-01, -3.2469e-01, -1.6733e-01, -3.4055e-01,\n",
       "         -7.1447e-01, -1.2838e-01,  1.6078e-01,  3.9626e-01,  2.7485e-01,\n",
       "          4.9268e-01,  2.4010e-01,  1.2215e-01, -1.6302e-01, -2.2567e-01,\n",
       "          1.2820e-01, -2.7617e-02, -1.0121e-01, -6.2157e-01, -1.2460e-01,\n",
       "          3.8554e-02, -1.0091e-02, -2.9103e-01, -2.1235e-01,  1.9589e-01,\n",
       "         -5.5201e-03, -1.4615e-01,  1.1009e-01,  4.9366e-01,  1.7585e-01,\n",
       "          6.2179e-02,  1.5579e-01,  4.8178e-01, -1.4477e-01,  1.2105e-01,\n",
       "          1.7707e-01,  1.7451e-01, -2.7906e-02,  1.2107e-01,  9.4413e-02,\n",
       "         -1.9504e-01, -1.9912e-01, -1.2772e-02,  1.0542e+00,  7.2621e-01,\n",
       "         -4.9775e-02, -9.4377e-02, -4.4436e-02, -4.6439e-01, -8.0312e-02,\n",
       "          2.3998e-01,  9.2445e-02, -3.3739e-01,  9.8938e-02,  9.4390e-02,\n",
       "         -1.6242e-01,  3.3618e-01,  1.7158e-01,  1.8206e-01, -3.7945e-01,\n",
       "          2.4995e-01, -8.3855e-01, -6.8595e-02, -3.9267e-01, -1.6675e-01,\n",
       "         -9.6476e-02,  5.0375e-02, -3.0718e-01,  2.7567e-01,  1.3358e-01,\n",
       "         -4.0574e-01,  6.7140e-02, -3.0682e-02, -6.4069e-01, -2.6111e-02,\n",
       "          1.9156e-01,  2.1606e-01, -8.0548e-01, -2.5850e-01, -1.1484e-01,\n",
       "         -7.5677e-01,  5.7060e-02,  6.2631e-01, -6.7207e-02, -4.4646e-01,\n",
       "          4.6199e-01,  2.1348e-01,  3.0401e-01,  2.7849e-01, -4.7992e-01,\n",
       "          1.5746e-01, -1.4301e-01,  6.9032e-01,  4.3726e-01,  1.1093e-01,\n",
       "         -4.7998e-01,  7.6462e-01, -1.2894e-01, -5.9950e-01,  1.4845e-01,\n",
       "          2.5513e-02, -4.2234e-01, -3.7783e-01,  3.1211e-02,  2.8665e-01,\n",
       "          1.9778e-01,  1.5670e-01, -1.7331e-04, -1.5855e-01,  2.3198e-01,\n",
       "         -2.2871e-01,  1.0768e-02,  1.1639e-01,  7.6593e-02, -3.1947e-01,\n",
       "         -4.1749e-01,  9.3626e-02, -9.8536e-02, -2.5150e-01,  7.6102e-02,\n",
       "          1.4642e-01, -4.7543e-01, -6.9717e-01, -4.8904e-02, -9.9028e-02,\n",
       "          7.6189e-03, -3.5977e-01, -7.2402e-02,  3.3325e-01,  3.4316e-02,\n",
       "         -3.7956e-01,  1.7399e-01,  1.3190e-01,  1.1346e-01,  4.3872e-02,\n",
       "          1.3540e-01,  1.2645e-01,  4.5498e-03,  2.8841e-01, -2.9191e-01,\n",
       "          4.2671e-01, -5.9284e-01, -2.4535e-01,  8.7547e-02, -7.1941e-02,\n",
       "          4.4340e-02, -1.8894e-01,  7.4726e-01, -5.1038e-01, -1.4188e-01,\n",
       "         -1.7090e-01,  1.6305e-01, -2.9450e-02,  2.0860e-01, -1.0218e-03,\n",
       "          1.2040e-01, -2.8338e-01,  2.1759e-01, -8.8770e-02,  3.0045e-01,\n",
       "          6.5306e-02,  2.2774e-01,  2.5601e-01,  7.2401e-01, -2.2477e-01,\n",
       "         -1.3094e-01, -1.2474e-01, -1.9997e-01,  1.5395e-01,  2.3237e-01,\n",
       "         -1.3670e-01,  9.2687e-02, -5.6258e-01, -1.8657e-01,  2.2676e-01,\n",
       "         -1.1452e+00,  5.4448e-01, -5.7529e-02, -1.5169e-01, -1.5630e-01,\n",
       "         -5.6274e-02, -2.1940e-01,  2.5109e-02, -3.6681e-01, -7.0561e-03,\n",
       "          7.5967e-02,  2.8279e-02,  6.0590e-02,  1.6751e-02, -4.6262e-01,\n",
       "          1.9255e-01,  1.4582e-01,  1.9293e-02, -5.4057e-02,  5.1615e-01,\n",
       "          1.0585e-01, -8.1699e-02,  1.2260e-01, -2.8709e-01,  2.0622e-01,\n",
       "         -1.1439e-01, -4.9058e-02, -2.4096e-01,  4.0414e-02,  2.0068e-01,\n",
       "          2.2447e-01, -1.6990e-01, -2.6749e+00,  9.3260e-02, -2.5713e-02,\n",
       "         -2.3199e-01, -6.5084e-03, -4.6567e-01,  5.8286e-01, -1.3019e-01,\n",
       "         -6.2771e-02, -2.6986e-02, -7.0026e-02, -6.0112e-01,  1.6494e-01,\n",
       "          3.2669e-01,  2.0181e-03,  4.4387e-01]),\n",
       " tensor([-4.8776e-02, -3.3290e-01, -2.6735e-01, -4.5234e-02, -8.8816e-02,\n",
       "         -2.5886e-01,  2.0824e-01,  3.8631e-02, -2.8895e-02, -2.8731e-01,\n",
       "         -6.3817e-02,  1.4354e-01, -1.2707e-01,  1.2567e-01, -4.4783e-01,\n",
       "         -4.5807e-02,  2.8672e-01,  1.8058e-01, -5.4584e-02,  2.4871e-01,\n",
       "          1.3806e-01,  2.1090e-02, -1.8368e-01, -2.7310e-01,  3.3344e-01,\n",
       "          2.5974e-01, -3.4950e-01, -1.8504e-01, -2.7783e-01,  4.2127e-01,\n",
       "         -1.1038e-01,  9.0061e-02, -1.6857e-01,  4.5708e-01, -2.9533e-01,\n",
       "         -5.1966e-01,  2.9620e-01,  1.1566e-01, -2.2160e-01, -3.0792e-01,\n",
       "         -2.3753e-01,  2.1062e-02,  2.7765e-01, -2.5626e-01, -1.9453e-01,\n",
       "         -4.3370e-01,  7.8010e-02,  1.1544e-01, -3.6997e-01,  7.3380e-02,\n",
       "         -5.5104e-01,  9.9895e-02, -2.8591e-01,  3.5039e-01,  1.2811e-01,\n",
       "          1.5162e-01,  4.0411e-01,  2.3945e-01, -2.6008e-01, -3.4190e-01,\n",
       "          1.2458e-01,  1.7882e-02,  6.4213e-02,  1.4914e-01,  1.5164e-01,\n",
       "          2.9663e-01,  1.1223e-01, -1.1896e-01, -5.7446e-01,  5.4704e-01,\n",
       "         -2.6906e-01, -3.8009e-01,  6.5116e-01, -6.1238e-03,  3.1336e-01,\n",
       "          7.9157e-02, -3.0240e-01,  2.4469e-01,  2.1538e-01, -2.9608e-01,\n",
       "          1.5688e-01,  1.0724e-01, -2.2356e-01,  1.1093e-01,  1.0827e-01,\n",
       "          1.2902e-01, -4.9123e-01, -7.4783e-02, -2.1522e-01,  4.4829e-01,\n",
       "         -1.1067e-01,  9.2791e-03,  4.9472e-02,  3.1526e-01,  8.3591e-02,\n",
       "         -2.5180e-01,  1.9811e-01, -4.4969e-02,  3.1625e-01, -4.4489e-01,\n",
       "         -1.3952e-01, -3.6428e-01,  1.8457e-01,  3.1392e-01, -3.4731e-01,\n",
       "          6.0205e-02, -3.4035e-01, -1.6039e-01,  8.5926e-02, -4.9837e-02,\n",
       "         -9.2888e-02, -2.8594e-01,  3.2642e-01,  9.5619e-02, -1.2025e-01,\n",
       "          5.2881e-01, -5.5086e-04,  1.9233e-01,  2.9961e-02,  3.2294e-02,\n",
       "         -2.7309e-01, -1.2538e-01, -3.1224e-01,  8.5210e-01,  1.4900e-01,\n",
       "          1.4546e-01, -5.5672e-02, -1.9195e-02, -1.0916e-02, -2.3678e-01,\n",
       "          2.5879e-01,  7.1437e-01, -7.4126e-02,  1.5293e-01, -3.8973e-01,\n",
       "          2.3339e-01,  1.6373e-01, -4.2479e-02, -2.2558e-01, -1.1638e-01,\n",
       "         -4.3427e-01,  1.5469e-02, -2.6879e-01, -4.3571e-01,  4.0857e-01,\n",
       "          2.3586e-01,  2.1789e-01, -3.4828e-02,  9.9261e-02, -9.1283e-02,\n",
       "          1.9450e-01,  1.7649e-01,  5.1131e-02, -3.7056e-01, -3.4347e-01,\n",
       "         -5.2055e-02,  5.5211e-02, -4.8915e-02,  4.2174e-01,  4.8717e-01,\n",
       "          6.8901e-01,  1.3070e-01, -1.3349e-02,  2.2514e-01, -2.5109e-01,\n",
       "          1.3307e-01, -5.0521e-01,  5.8054e-01,  4.5336e-02,  2.8011e-01,\n",
       "         -4.1911e-02, -2.1849e-01,  4.9003e-01,  7.3688e-01, -1.0917e-01,\n",
       "          1.1843e-01, -1.2737e-01,  1.2113e-01,  7.3831e-02, -3.6381e-01,\n",
       "         -2.4067e+00,  4.7070e-01, -3.6725e-02, -3.9992e-01, -1.7710e-01,\n",
       "         -7.4460e-02,  7.9168e-02, -5.5685e-01,  2.5433e-01, -5.6192e-01,\n",
       "         -2.3258e-01, -5.0372e-01, -2.2458e-01, -2.6157e-01,  3.3955e-01,\n",
       "         -6.2374e-01,  4.0113e-01, -4.2036e-01,  1.1003e-02,  1.3034e-02,\n",
       "          2.8829e-01, -3.3681e-02,  3.5696e-01,  3.5724e-01, -1.4749e-01,\n",
       "          9.0772e-01,  9.8740e-03, -3.5656e-01,  2.8085e-01,  6.0008e-02,\n",
       "         -5.3486e-01,  2.9059e-01,  2.1925e-02, -1.8801e-01,  2.3688e-01,\n",
       "         -3.0580e-01,  3.4156e-01, -2.4952e-01, -1.8983e-01, -1.1962e-01,\n",
       "          1.9658e-01, -2.2622e-01, -3.5972e-01,  3.1373e-01, -3.7440e-01,\n",
       "          1.7094e-01,  2.6857e-01,  3.8420e-01, -7.2834e-02, -1.4493e-01,\n",
       "         -2.4569e-01, -1.3185e-01,  1.5550e-01,  4.5916e-01, -5.8649e-01,\n",
       "          2.9226e-01, -1.0715e-01, -1.8067e-01,  2.7136e-02, -2.9804e-01,\n",
       "         -2.5289e-01,  1.9431e-01,  5.4185e-01, -1.3672e-01, -8.6170e-02,\n",
       "         -2.4635e-01,  8.1788e-01,  3.0504e-01,  2.2772e-01, -1.8501e-01,\n",
       "          2.9530e-02, -2.3794e-01,  1.6114e-01, -7.8778e-01,  1.6631e-01,\n",
       "         -2.6112e-01, -9.9679e-03, -7.9942e-02,  9.0861e-02,  5.1709e-02,\n",
       "         -1.1188e-01,  1.7086e-01,  7.0285e-01, -1.1261e-01, -3.3871e-01,\n",
       "          3.2047e-02,  7.1701e-01,  1.5136e-01,  1.4419e-01, -2.5058e-01,\n",
       "          1.1189e-02, -3.3381e-01, -3.0666e-01, -5.6507e-01, -3.5444e-01,\n",
       "         -1.8137e-01,  4.9469e-01, -1.4640e-01,  3.0319e-02, -3.0166e-01,\n",
       "         -2.5481e-02,  1.5248e-01, -1.8967e-01,  2.6960e-01,  2.2452e-01,\n",
       "         -3.6131e-01, -8.4030e-02, -5.0742e-01,  6.3189e-02, -6.6207e-01,\n",
       "         -3.8520e-01, -7.2179e-02, -8.5942e-02,  1.0384e-01, -2.3301e-01,\n",
       "          3.8677e-02, -1.9465e-01,  1.1915e-01, -2.6234e-01, -4.4269e-01,\n",
       "         -1.0077e-01, -3.4157e-01,  3.4075e-02, -2.3954e-01,  8.2923e-02,\n",
       "          2.2693e-01, -6.8090e-02,  1.5752e-01, -2.5313e+00,  2.4798e-02,\n",
       "         -7.3408e-02, -3.0764e-01,  1.4411e-01, -9.2695e-02, -1.6468e-01,\n",
       "         -1.3559e-01, -2.7670e-01, -2.3060e-01,  1.4336e-01, -4.5689e-01,\n",
       "          3.4693e-01,  1.3728e-01,  5.2791e-03, -1.4402e-01, -2.5174e-01,\n",
       "         -2.9629e-01, -4.0049e-01,  5.2915e-01, -1.7559e-01,  4.7833e-02,\n",
       "          3.9705e-01, -3.9056e-01,  2.4637e-01,  2.5995e-01, -4.3076e-01,\n",
       "          9.8521e-02, -5.4977e-01, -3.9380e-01, -4.8859e-02, -3.7734e-01,\n",
       "         -2.0696e-01,  1.1892e-01,  1.4455e-01, -6.3667e-02,  9.5615e-02,\n",
       "          1.9988e-01,  8.0835e-01, -2.9556e-02,  8.3056e-02,  5.0057e-01,\n",
       "         -2.4658e-01,  4.1096e-02,  2.0112e-01, -8.8924e-02,  2.0832e-01,\n",
       "         -4.1349e-01, -1.8447e-01,  1.7601e-01,  2.8478e-01, -2.6699e-01,\n",
       "          5.5225e-02, -2.9343e-02,  2.0552e-01, -2.1081e-02,  2.4499e-01,\n",
       "          2.6092e-01, -1.6787e-01, -3.0282e-01,  4.5670e-01, -5.3795e-01,\n",
       "         -8.0431e-02,  1.3645e-01, -2.3566e-01, -1.3365e-01, -4.7755e-01,\n",
       "         -2.0824e-01, -1.7308e-01, -3.6049e-02,  2.3438e-01,  5.8389e-02,\n",
       "         -1.3294e-01, -7.7823e-01,  1.8519e-01, -4.9200e-02, -3.0306e-01,\n",
       "         -2.2099e-01,  2.3476e-01, -3.3022e-01,  2.8528e-01, -2.5392e-01,\n",
       "          1.0825e-01, -1.2233e-02, -1.4383e-01, -1.0909e-01,  3.1990e-01,\n",
       "         -4.1908e-02, -9.8022e-02, -1.2439e-01, -4.0194e-02,  1.9955e-01,\n",
       "          2.1576e-01,  8.3755e-02,  3.4526e-01,  2.2537e-01,  5.0685e-01,\n",
       "         -5.5400e-01,  2.3325e-01, -1.6601e-01, -2.5606e-01, -5.6051e-01,\n",
       "         -8.7513e-02,  1.4656e-01, -1.5246e-01, -2.8034e-01, -5.9730e-01,\n",
       "         -2.8122e-01, -1.1617e-01, -2.4550e-01,  5.8525e-01, -3.1906e-01,\n",
       "          5.7284e-01, -1.2736e-01,  1.3119e-01, -8.5695e-02, -5.4589e-02,\n",
       "          6.4849e-02, -6.4364e-02,  3.4318e-01,  1.2635e-01,  1.4750e-01,\n",
       "         -1.6331e-01, -2.4190e-01, -1.2893e-02, -8.2048e-02,  6.9880e-02,\n",
       "         -4.0061e-01, -3.8162e-01, -1.5938e-01,  2.0326e-02,  1.3706e-01,\n",
       "          7.3998e-02, -3.3262e-01, -1.3764e-01, -1.2924e-01,  1.9300e-01,\n",
       "          3.7744e-01,  2.6278e-01,  1.8664e-01,  1.5497e-01,  3.2496e-01,\n",
       "         -5.1136e-01,  4.1498e-01,  1.9206e-01,  6.2643e-01, -1.1094e-01,\n",
       "          7.2568e-02,  3.9790e-01,  7.0770e-01,  3.0507e-01, -5.8187e-01,\n",
       "          2.2880e-02, -2.7306e-01, -3.0707e-01, -6.7815e-01,  4.6496e-01,\n",
       "         -6.6628e-02, -3.8438e-01, -6.0857e-02, -3.1561e-01,  8.0681e-02,\n",
       "         -5.5833e-03,  3.1039e-01, -1.5986e-01,  2.9617e-01,  2.5979e-01,\n",
       "         -6.0736e-02, -5.1183e-01,  1.6146e-01,  2.9232e-01, -4.4351e-01,\n",
       "         -5.4358e-02,  3.9794e-01, -2.1243e-01,  1.8401e-01, -3.4755e-01,\n",
       "         -4.5123e-01,  1.4114e-01,  4.1085e-01,  6.5651e-02, -1.8651e-01,\n",
       "         -8.9618e-02,  2.2773e-02,  2.7653e-01, -2.4059e-01, -2.1662e-01,\n",
       "         -6.6054e-02,  1.0935e-01,  4.0110e-01, -1.4482e-01, -2.7321e-01,\n",
       "         -4.8823e-01, -8.4205e-02, -4.9449e-01, -2.5859e-02,  5.8762e-02,\n",
       "          3.9649e-01,  2.3948e-01, -3.1618e-02,  4.8915e-01, -3.7777e-01,\n",
       "          5.3480e-02,  6.3901e-02, -1.9772e-01,  3.2031e-01,  2.7639e-01,\n",
       "          7.6753e-02, -2.3764e-01,  7.5573e-02,  2.1582e-01, -5.4512e-01,\n",
       "         -5.7779e-01, -3.9247e-01, -8.2749e-02,  3.3536e-01,  9.6792e-02,\n",
       "          1.1880e-01,  1.0082e-01, -2.3863e-02, -3.4055e-01, -1.9094e-01,\n",
       "          4.2497e-02, -3.1667e-02, -2.5832e-01, -1.3537e-01, -2.3514e-01,\n",
       "         -2.6270e-01, -6.6045e-02, -7.9335e-02,  2.4939e-01,  2.5169e-01,\n",
       "         -3.7841e-01, -2.6402e-02,  7.9002e-01,  3.8690e-01, -7.5858e-01,\n",
       "         -3.1932e-01,  1.1762e-02, -3.0468e-01,  3.8027e-01, -2.7946e-01,\n",
       "         -3.8096e-02, -4.7202e-02, -2.4014e-01,  2.9827e-01,  1.3798e-01,\n",
       "          5.4581e-01,  9.0183e-02,  2.5022e-01, -1.8138e-01, -4.1923e-02,\n",
       "          6.7955e-02, -7.1386e-02,  1.8370e-01, -8.8090e-01, -4.3850e-01,\n",
       "          7.5507e-02,  2.6281e-01,  3.8344e-01, -2.5801e-02,  2.1797e-01,\n",
       "          2.0058e-02,  8.3802e-02, -3.2793e-03,  1.8024e-01, -4.2698e-02,\n",
       "          1.1169e-01,  3.5399e-01,  2.8349e-01,  6.6034e-02,  9.5537e-03,\n",
       "          1.9022e-01, -2.6727e-01, -3.7979e-01, -5.0998e-02,  4.7612e-01,\n",
       "         -2.3458e-01, -1.7113e-01, -2.8921e-01,  4.1983e-01,  5.2979e-01,\n",
       "          1.4008e-01,  1.0565e-01, -7.7814e-02,  6.2408e-02, -2.3250e-01,\n",
       "          7.7207e-02, -1.0905e-01, -3.8133e-01,  7.3821e-02, -2.7945e-02,\n",
       "         -8.3731e-02,  1.3340e-01,  4.6269e-02,  9.3621e-02, -5.3597e-01,\n",
       "          8.6743e-02, -1.1962e-01,  2.5868e-01, -9.1878e-02,  5.3398e-01,\n",
       "         -6.9576e-02, -2.7803e-01,  2.2167e-01,  2.5335e-01,  8.7627e-02,\n",
       "         -4.8975e-01,  2.8272e-01,  3.7119e-01, -1.5215e-01,  9.1343e-02,\n",
       "         -7.3744e-02,  5.9988e-01, -3.5492e-01,  3.3618e-01, -8.9318e-02,\n",
       "         -3.9444e-01,  1.8417e-01,  2.2330e-01,  2.6589e-01, -1.7624e-01,\n",
       "          4.3940e-01,  3.3034e-02,  3.8472e-01,  3.8671e-01, -5.6110e-01,\n",
       "         -1.0880e-01, -3.3810e-02,  2.3920e-01,  3.4081e-01,  1.2012e-01,\n",
       "         -6.7960e-02,  4.9115e-01, -4.3755e-02, -1.0134e-01,  4.6388e-01,\n",
       "          4.2748e-01, -2.0751e-01,  9.1622e-02,  3.7449e-01,  1.5755e-01,\n",
       "          2.5838e-01, -8.0126e-02,  1.0009e-01, -1.6457e-01, -1.0376e-01,\n",
       "         -3.3191e-01,  3.5481e-01,  2.0350e-01,  2.8088e-01, -1.5247e-01,\n",
       "          2.1611e-01, -1.7618e-01, -2.2469e-01, -7.6497e-03,  2.7570e-01,\n",
       "          1.4469e-01, -1.6910e-01, -1.9365e-01,  5.5099e-02,  7.0916e-02,\n",
       "         -1.5167e-01, -2.1786e-01, -1.3155e-01,  4.7644e-01,  1.2691e-01,\n",
       "         -3.3007e-01, -1.1885e-01,  1.5203e-01,  2.8700e-01,  3.2952e-01,\n",
       "          2.7566e-01, -2.1208e-01,  6.5862e-02,  4.3925e-01,  5.4572e-02,\n",
       "          5.8188e-01, -1.8321e-01, -2.6771e-01, -1.7914e-01, -1.7172e-01,\n",
       "         -4.2180e-01, -1.7775e-01,  6.1855e-01, -3.2424e-01, -3.5666e-01,\n",
       "         -3.0759e-01,  1.8380e-01, -2.0125e-01,  1.0115e-01,  3.5906e-02,\n",
       "          4.3759e-01, -6.3037e-01,  2.3559e-01, -5.6748e-02,  2.8767e-01,\n",
       "          6.2771e-02,  4.7978e-01,  3.2213e-01,  4.4050e-01,  3.1089e-01,\n",
       "         -1.0683e-01, -1.1631e-02,  1.2709e-01, -2.6481e-02,  4.8304e-01,\n",
       "          2.5171e-01, -6.9054e-02, -5.6499e-01,  4.1184e-02,  2.6684e-01,\n",
       "         -9.3713e-01,  1.9845e-01,  2.1960e-01, -6.7421e-02,  6.8608e-02,\n",
       "          1.8320e-01, -1.7463e-01, -8.7580e-02,  6.8542e-02, -3.7007e-01,\n",
       "          4.0291e-01, -1.3496e-01, -1.5976e-01, -1.9597e-01, -2.4820e-01,\n",
       "          5.6115e-02, -1.1462e-01,  1.7532e-01, -1.8513e-01,  6.0757e-01,\n",
       "          2.4542e-02, -1.9493e-01,  2.9749e-01, -2.5023e-01,  2.8200e-02,\n",
       "          2.2474e-01, -4.0095e-01, -9.8226e-02, -2.8216e-01, -1.3428e-01,\n",
       "          3.3620e-01,  3.6953e-01, -1.7108e+00, -1.8991e-01, -1.4668e-02,\n",
       "         -3.0933e-01, -4.4764e-02, -3.0209e-01,  5.0522e-01,  1.8181e-01,\n",
       "          8.8734e-03, -3.2998e-01, -5.8335e-04, -4.8780e-01,  4.7817e-02,\n",
       "          2.9018e-01, -8.8422e-02, -1.2571e-02])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_to_wordwise_embeddings([\"The red horse simply turned its tail.\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\elias\\OneDrive\\Dokumente\\Git\\MasterThesis\\notebooks\\friss-frameaxis-SPAN-LEVEL.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m predicates_embeddings \u001b[39m=\u001b[39m strings_to_wordwise_embeddings(predicates)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ARG0_embeddings \u001b[39m=\u001b[39m strings_to_wordwise_embeddings(arg0s)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ARG1_embeddings \u001b[39m=\u001b[39m strings_to_wordwise_embeddings(arg1s)\n",
      "\u001b[1;32mc:\\Users\\elias\\OneDrive\\Dokumente\\Git\\MasterThesis\\notebooks\\friss-frameaxis-SPAN-LEVEL.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X23sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m inputs \u001b[39m=\u001b[39m tokenizer(word, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, max_length\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X23sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X23sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X23sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m word_embedding \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mlast_hidden_state\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X23sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m word_embeddings\u001b[39m.\u001b[39mappend(word_embedding)\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1018\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1009\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1011\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m   1012\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   1013\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1016\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1017\u001b[0m )\n\u001b[1;32m-> 1018\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m   1019\u001b[0m     embedding_output,\n\u001b[0;32m   1020\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m   1021\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1022\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1023\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m   1024\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1025\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1026\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1027\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1028\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1029\u001b[0m )\n\u001b[0;32m   1030\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1031\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    598\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    599\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    600\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    606\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 607\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    608\u001b[0m         hidden_states,\n\u001b[0;32m    609\u001b[0m         attention_mask,\n\u001b[0;32m    610\u001b[0m         layer_head_mask,\n\u001b[0;32m    611\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    612\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    613\u001b[0m         past_key_value,\n\u001b[0;32m    614\u001b[0m         output_attentions,\n\u001b[0;32m    615\u001b[0m     )\n\u001b[0;32m    617\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    618\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:535\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    532\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    533\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 535\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    536\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[0;32m    537\u001b[0m )\n\u001b[0;32m    538\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[0;32m    540\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pytorch_utils.py:241\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 241\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:548\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m    547\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 548\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(intermediate_output, attention_output)\n\u001b[0;32m    549\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:460\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor, input_tensor: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m--> 460\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[0;32m    461\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    462\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Convert the lists of strings to lists of embeddings\n",
    "predicates_embeddings = strings_to_wordwise_embeddings(predicates)\n",
    "ARG0_embeddings = strings_to_wordwise_embeddings(arg0s)\n",
    "ARG1_embeddings = strings_to_wordwise_embeddings(arg1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ARG0_embeddings[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.9269e+00,  1.4873e+00,  9.0072e-01, -2.1055e+00,  6.7842e-01,\n",
       "        -1.2345e+00, -4.3067e-02, -1.6047e+00, -7.5214e-01,  1.6487e+00,\n",
       "        -3.9248e-01, -1.4036e+00, -7.2788e-01, -5.5943e-01, -7.6884e-01,\n",
       "         7.6245e-01,  1.6423e+00, -1.5960e-01, -4.9740e-01,  4.3959e-01,\n",
       "        -7.5813e-01,  1.0783e+00,  8.0080e-01,  1.6806e+00,  1.2791e+00,\n",
       "         1.2964e+00,  6.1047e-01,  1.3347e+00, -2.3162e-01,  4.1759e-02,\n",
       "        -2.5158e-01,  8.5986e-01, -1.3847e+00, -8.7124e-01, -2.2337e-01,\n",
       "         1.7174e+00,  3.1888e-01, -4.2452e-01,  3.0572e-01, -7.7459e-01,\n",
       "        -1.5576e+00,  9.9564e-01, -8.7979e-01, -6.0114e-01, -1.2742e+00,\n",
       "         2.1228e+00, -1.2347e+00, -4.8791e-01, -9.1382e-01, -6.5814e-01,\n",
       "         7.8024e-02,  5.2581e-01, -4.8799e-01,  1.1914e+00, -8.1401e-01,\n",
       "        -7.3599e-01, -1.4032e+00,  3.6004e-02, -6.3477e-02,  6.7561e-01,\n",
       "        -9.7807e-02,  1.8446e+00, -1.1845e+00,  1.3835e+00,  1.4451e+00,\n",
       "         8.5641e-01,  2.2181e+00,  5.2317e-01,  3.4665e-01, -1.9733e-01,\n",
       "        -1.0546e+00,  1.2780e+00, -1.7219e-01,  5.2379e-01,  5.6622e-02,\n",
       "         4.2630e-01,  5.7501e-01, -6.4172e-01, -2.2064e+00, -7.5080e-01,\n",
       "         1.0868e-02, -3.3874e-01, -1.3407e+00, -5.8537e-01,  6.4076e-01,\n",
       "         5.8325e-01,  1.0669e+00, -4.5015e-01, -6.7875e-01,  5.7432e-01,\n",
       "         1.8775e-01, -3.5762e-01,  2.6491e-01,  1.2732e+00, -1.3109e-03,\n",
       "        -3.0360e-01, -9.8644e-01,  1.2330e-01,  3.4987e-01,  6.1728e-01])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate random embeddings for each sentence (in practice, replace with SRL embeddings)\n",
    "embedding_dim = 100\n",
    "sentences_embeddings = [torch.randn(embedding_dim) for _ in X]\n",
    "\n",
    "sentences_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class MultiViewAutoencoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, encoded_dim):\n",
    "        super(MultiViewAutoencoder, self).__init__()\n",
    "        \n",
    "        # For predicates\n",
    "        self.encoder_p = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, encoded_dim)\n",
    "        )\n",
    "        self.decoder_p = nn.Linear(encoded_dim, embedding_dim)\n",
    "        \n",
    "        # For ARG0\n",
    "        self.encoder_a0 = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, encoded_dim)\n",
    "        )\n",
    "        self.decoder_a0 = nn.Linear(encoded_dim, embedding_dim)\n",
    "        \n",
    "        # For ARG1\n",
    "        self.encoder_a1 = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, encoded_dim)\n",
    "        )\n",
    "        self.decoder_a1 = nn.Linear(encoded_dim, embedding_dim)\n",
    "    \n",
    "    def forward(self, x_p, x_a0, x_a1):\n",
    "        # Encoding\n",
    "        x_p = self.encoder_p(x_p)\n",
    "        x_a0 = self.encoder_a0(x_a0)\n",
    "        x_a1 = self.encoder_a1(x_a1)\n",
    "        \n",
    "        # Decoding\n",
    "        x_p = self.decoder_p(x_p)\n",
    "        x_a0 = self.decoder_a0(x_a0)\n",
    "        x_a1 = self.decoder_a1(x_a1)\n",
    "        \n",
    "        return x_p, x_a0, x_a1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifier\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, encoded_dim, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = nn.Linear(encoded_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x.squeeze()  # Squeeze the tensor to remove singleton dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dimensions\n",
    "embedding_dim = 768  # This could be the size of your word embeddings, e.g., 768 for BERT\n",
    "hidden_dim = 150     # This is an intermediate dimension, can be chosen based on model complexity\n",
    "encoded_dim = 50     # This is the final encoded dimension\n",
    "\n",
    "# Initialize the autoencoder\n",
    "autoencoder = MultiViewAutoencoder(embedding_dim, hidden_dim, encoded_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(y.columns)\n",
    "\n",
    "classifier = Classifier(encoded_dim, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MultiViewAutoencoder(\n",
       "   (encoder_p): Sequential(\n",
       "     (0): Linear(in_features=768, out_features=150, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=150, out_features=50, bias=True)\n",
       "   )\n",
       "   (decoder_p): Linear(in_features=50, out_features=768, bias=True)\n",
       "   (encoder_a0): Sequential(\n",
       "     (0): Linear(in_features=768, out_features=150, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=150, out_features=50, bias=True)\n",
       "   )\n",
       "   (decoder_a0): Linear(in_features=50, out_features=768, bias=True)\n",
       "   (encoder_a1): Sequential(\n",
       "     (0): Linear(in_features=768, out_features=150, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=150, out_features=50, bias=True)\n",
       "   )\n",
       "   (decoder_a1): Linear(in_features=50, out_features=768, bias=True)\n",
       " ),\n",
       " Classifier(\n",
       "   (fc): Linear(in_features=50, out_features=19, bias=True)\n",
       " ))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "Epoch 1/10, Reconstruction Loss: 0.05973947048187256, Classification Loss: 0.0802110806107521\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "Epoch 2/10, Reconstruction Loss: 0.057978011667728424, Classification Loss: 0.13474246859550476\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "Epoch 3/10, Reconstruction Loss: 0.05853263661265373, Classification Loss: 0.037077516317367554\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "Epoch 4/10, Reconstruction Loss: 0.0592820830643177, Classification Loss: 0.08971809595823288\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "Epoch 5/10, Reconstruction Loss: 0.05858869105577469, Classification Loss: 0.05310332775115967\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\elias\\OneDrive\\Dokumente\\Git\\MasterThesis\\notebooks\\friss-frameaxis-SPAN-LEVEL.ipynb Cell 27\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X31sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     combined_loss \u001b[39m=\u001b[39m total_reconstruction_loss \u001b[39m+\u001b[39m classification_loss\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X31sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39m# Backward pass and optimization\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X31sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     combined_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X31sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X31sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m, Reconstruction Loss: \u001b[39m\u001b[39m{\u001b[39;00mtotal_reconstruction_loss\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m, Classification Loss: \u001b[39m\u001b[39m{\u001b[39;00mclassification_loss\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the loss functions\n",
    "reconstruction_loss_fn = nn.MSELoss()\n",
    "classification_loss_fn = nn.BCEWithLogitsLoss()  # Updated loss function\n",
    "\n",
    "# Define the optimizer (both models' parameters are optimized jointly)\n",
    "optimizer = optim.Adam(list(autoencoder.parameters()) + list(classifier.parameters()), lr=0.001)\n",
    "\n",
    "# Number of epochs\n",
    "epochs = 10\n",
    "\n",
    "# Convert y dataframe to a list of tensors\n",
    "targets = [torch.tensor(y.iloc[i].values).float() for i in range(len(y))]\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for embedding_p, embedding_a0, embedding_a1, target in zip(predicates_embeddings, ARG0_embeddings, ARG1_embeddings, targets):\n",
    "        \n",
    "        # Move tensors to the same device as the model\n",
    "        embedding_p = embedding_p.to(device)\n",
    "        embedding_a0 = embedding_a0.to(device)\n",
    "        embedding_a1 = embedding_a1.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through the autoencoder\n",
    "        reconstructed_p, reconstructed_a0, reconstructed_a1 = autoencoder(embedding_p, embedding_a0, embedding_a1)\n",
    "\n",
    "        # Compute the reconstruction loss for each view\n",
    "        reconstruction_loss_p = reconstruction_loss_fn(reconstructed_p, embedding_p)\n",
    "        reconstruction_loss_a0 = reconstruction_loss_fn(reconstructed_a0, embedding_a0)\n",
    "        reconstruction_loss_a1 = reconstruction_loss_fn(reconstructed_a1, embedding_a1)\n",
    "\n",
    "        # Total reconstruction loss\n",
    "        total_reconstruction_loss = reconstruction_loss_p + reconstruction_loss_a0 + reconstruction_loss_a1\n",
    "\n",
    "        # Forward pass through the classifier (using the encoded embeddings of each view)\n",
    "        encoded_p = autoencoder.encoder_p(embedding_p)\n",
    "        encoded_a0 = autoencoder.encoder_a0(embedding_a0)\n",
    "        encoded_a1 = autoencoder.encoder_a1(embedding_a1)\n",
    "\n",
    "        # Combine the encoded embeddings (e.g., by averaging) before passing to the classifier\n",
    "        combined_encoded_embedding = (encoded_p + encoded_a0 + encoded_a1) / 3.0\n",
    "        frame_predictions = classifier(combined_encoded_embedding)\n",
    "\n",
    "        # Compute the classification loss\n",
    "        classification_loss = classification_loss_fn(frame_predictions, target)\n",
    "\n",
    "        # Combine the losses\n",
    "        combined_loss = total_reconstruction_loss + classification_loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        combined_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Reconstruction Loss: {total_reconstruction_loss.item()}, Classification Loss: {classification_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_frames(article, autoencoder, classifier):\n",
    "    # Tokenize the article into sentences\n",
    "    sentences = article.split('.')\n",
    "    \n",
    "    # Extract SRL embeddings for the sentences (use random embeddings for this demo)\n",
    "    embeddings = [torch.randn(embedding_dim) for sentence in sentences]\n",
    "    \n",
    "    # List to store frame predictions for each sentence\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():  # Ensure no gradients are computed during inference\n",
    "        for embedding in embeddings:\n",
    "            # Pass the embedding through the trained encoder\n",
    "            encoded_embedding = autoencoder.encoder(embedding)\n",
    "            \n",
    "            # Pass the encoded embedding through the trained classifier\n",
    "            frame_predictions = classifier(encoded_embedding)\n",
    "            \n",
    "            # Convert frame predictions to binary (0 or 1) using a threshold (e.g., 0.5)\n",
    "            frame_predictions = (frame_predictions > 0.5).float()\n",
    "            \n",
    "            all_predictions.append(frame_predictions)\n",
    "    \n",
    "    # Aggregate sentence-level predictions to get document-level prediction (average in this case)\n",
    "    avg_prediction = torch.mean(torch.stack(all_predictions), dim=0)\n",
    "    document_prediction = (avg_prediction > 0.5).float()\n",
    "    \n",
    "    return document_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultiViewAutoencoder' object has no attribute 'encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\elias\\OneDrive\\Dokumente\\Git\\MasterThesis\\notebooks\\friss-frameaxis-SPAN-LEVEL.ipynb Cell 25\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     article \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Predict frames for the article\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m predicted_frames \u001b[39m=\u001b[39m predict_frames(article, autoencoder, classifier)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Convert the predicted frames to a list of frames\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m predicted_frames \u001b[39m=\u001b[39m [y\u001b[39m.\u001b[39mcolumns[i] \u001b[39mfor\u001b[39;00m i, frame \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(predicted_frames) \u001b[39mif\u001b[39;00m frame \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m]\n",
      "\u001b[1;32mc:\\Users\\elias\\OneDrive\\Dokumente\\Git\\MasterThesis\\notebooks\\friss-frameaxis-SPAN-LEVEL.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():  \u001b[39m# Ensure no gradients are computed during inference\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mfor\u001b[39;00m embedding \u001b[39min\u001b[39;00m embeddings:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39m# Pass the embedding through the trained encoder\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         encoded_embedding \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39;49mencoder(embedding)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X33sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         \u001b[39m# Pass the encoded embedding through the trained classifier\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X33sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         frame_predictions \u001b[39m=\u001b[39m classifier(encoded_embedding)\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MultiViewAutoencoder' object has no attribute 'encoder'"
     ]
    }
   ],
   "source": [
    "# read article from data\\en\\dev-articles-subtask-2\\article813452859.txt\n",
    "with open(\"data/en/dev-articles-subtask-2/article813452859.txt\", \"r\") as f:\n",
    "    article = f.read()\n",
    "\n",
    "# Predict frames for the article\n",
    "predicted_frames = predict_frames(article, autoencoder, classifier)\n",
    "\n",
    "# Convert the predicted frames to a list of frames\n",
    "predicted_frames = [y.columns[i] for i, frame in enumerate(predicted_frames) if frame == 1]\n",
    "\n",
    "\n",
    "# read the true frames from data\\en\\dev-labels-subtask-2.txt\n",
    "with open(\"data/en/dev-labels-subtask-2.txt\", \"r\") as f:\n",
    "    true_frames = f.readlines()[0].split(\"\\t\")[1].split(\",\")\n",
    "\n",
    "true_frames, predicted_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3636363636363636"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the F1 score\n",
    "def f1_score(predicted_frames, true_frames):\n",
    "    tp = len(set(predicted_frames) & set(true_frames))\n",
    "    fp = len(set(predicted_frames) - set(true_frames))\n",
    "    fn = len(set(true_frames) - set(predicted_frames))\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "f1_score(predicted_frames, true_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
