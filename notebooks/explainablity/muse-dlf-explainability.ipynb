{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elianderlohr/muse-dlf/blob/main/notebooks/explainablity/slmuse-dlf-explainability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb-1nYP5Zbn1"
      },
      "source": [
        "# SLMuSE-DLF Explainability\n",
        "\n",
        "Plot the explainability of the SLMuSE-DLF model. By using the dictionary learning approach it is (1.) possible to extract how different words in a certaim semantic role predict the presence of a document level frame and (2.) identify how the FrameAxis constallations are predicting the document level frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qPPchm1JZbn6"
      },
      "outputs": [],
      "source": [
        "# auto reload imports\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-98jWIlKb3l5",
        "outputId": "8ecf0489-1f44-4a67-9681-345d775ff93c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Git/muse-dlf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6VYr37vcCyg",
        "outputId": "77db3dea-7b32-4c6d-fdc5-1985fde8a08e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets\tdata  notebooks  README.md  research-notebooks\trun  src  tests  ToDo.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb==0.17.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H66rA8fgKkNa",
        "outputId": "241149ed-979b-4466-c9e4-9173f9f94aee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb==0.17.4 in /usr/local/lib/python3.10/dist-packages (0.17.4)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (2.31.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (2.9.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb==0.17.4) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb==0.17.4) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.17.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.17.4) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.17.4) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.17.4) (2024.6.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb==0.17.4) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb==0.17.4 allennlp allennlp-models spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iQxpBC70c7mj",
        "outputId": "ea9ea6c1-1937-4f60-e0d7-d0933948e7c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb==0.17.4 in /usr/local/lib/python3.10/dist-packages (0.17.4)\n",
            "Requirement already satisfied: allennlp in /usr/local/lib/python3.10/dist-packages (2.10.1)\n",
            "Requirement already satisfied: allennlp-models in /usr/local/lib/python3.10/dist-packages (2.10.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.3.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (2.31.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (2.9.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb==0.17.4) (67.7.2)\n",
            "Collecting torch<1.13.0,>=1.10.0 (from allennlp)\n",
            "  Using cached torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
            "Requirement already satisfied: torchvision<0.14.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.13.1)\n",
            "Requirement already satisfied: cached-path<1.2.0,>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.1.6)\n",
            "Requirement already satisfied: fairscale==0.4.6 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.4.6)\n",
            "Requirement already satisfied: nltk>=3.6.5 in /usr/local/lib/python3.10/dist-packages (from allennlp) (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.21.4 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.25.2)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.10/dist-packages (from allennlp) (2.6.2.2)\n",
            "Requirement already satisfied: tqdm>=4.62 in /usr/local/lib/python3.10/dist-packages (from allennlp) (4.66.4)\n",
            "Requirement already satisfied: h5py>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (3.9.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.11.4)\n",
            "Requirement already satisfied: pytest>=6.2.5 in /usr/local/lib/python3.10/dist-packages (from allennlp) (7.4.4)\n",
            "Requirement already satisfied: transformers<4.21,>=4.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (4.20.1)\n",
            "Requirement already satisfied: sentencepiece>=0.1.96 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.1.99)\n",
            "Requirement already satisfied: filelock<3.8,>=3.3 in /usr/local/lib/python3.10/dist-packages (from allennlp) (3.7.1)\n",
            "Requirement already satisfied: lmdb>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.5.1)\n",
            "Requirement already satisfied: more-itertools>=8.12.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (10.1.0)\n",
            "Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.1.0)\n",
            "INFO: pip is looking at multiple versions of allennlp to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting allennlp\n",
            "  Using cached allennlp-2.10.0-py3-none-any.whl (729 kB)\n",
            "Collecting torch<1.12.0,>=1.10.0 (from allennlp)\n",
            "  Using cached torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n",
            "Collecting torchvision<0.13.0,>=0.8.1 (from allennlp)\n",
            "  Using cached torchvision-0.12.0-cp310-cp310-manylinux1_x86_64.whl (21.0 MB)\n",
            "Collecting allennlp\n",
            "  Using cached allennlp-2.9.3-py3-none-any.whl (719 kB)\n",
            "Collecting spacy\n",
            "  Using cached spacy-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.1 MB)\n",
            "Collecting transformers<4.19,>=4.1 (from allennlp)\n",
            "  Using cached transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "Collecting filelock<3.7,>=3.3 (from allennlp)\n",
            "  Using cached filelock-3.6.0-py3-none-any.whl (10.0 kB)\n",
            "Collecting allennlp\n",
            "  Using cached allennlp-2.9.2-py3-none-any.whl (719 kB)\n",
            "Collecting transformers<4.18,>=4.1 (from allennlp)\n",
            "  Using cached transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "Collecting allennlp\n",
            "  Using cached allennlp-2.9.1-py3-none-any.whl (718 kB)\n",
            "  Using cached allennlp-2.9.0-py3-none-any.whl (716 kB)\n",
            "  Using cached allennlp-2.8.0-py3-none-any.whl (738 kB)\n",
            "  Using cached allennlp-2.7.0-py3-none-any.whl (738 kB)\n",
            "INFO: pip is looking at multiple versions of allennlp to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached allennlp-2.6.0-py3-none-any.whl (689 kB)\n",
            "  Using cached allennlp-2.5.0-py3-none-any.whl (681 kB)\n",
            "  Using cached allennlp-2.4.0-py3-none-any.whl (625 kB)\n",
            "  Using cached allennlp-2.3.1-py3-none-any.whl (607 kB)\n",
            "  Using cached allennlp-2.3.0-py3-none-any.whl (598 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached allennlp-2.2.0-py3-none-any.whl (595 kB)\n",
            "  Using cached allennlp-2.1.0-py3-none-any.whl (585 kB)\n",
            "  Using cached allennlp-2.0.1-py3-none-any.whl (580 kB)\n",
            "  Using cached allennlp-2.0.0-py3-none-any.whl (579 kB)\n",
            "  Using cached allennlp-1.5.0-py3-none-any.whl (517 kB)\n",
            "  Using cached allennlp-1.4.1-py3-none-any.whl (516 kB)\n",
            "  Using cached allennlp-1.4.0-py3-none-any.whl (516 kB)\n",
            "  Using cached allennlp-1.3.0-py3-none-any.whl (506 kB)\n",
            "  Using cached allennlp-1.2.2-py3-none-any.whl (505 kB)\n",
            "  Using cached allennlp-1.2.1-py3-none-any.whl (504 kB)\n",
            "  Using cached allennlp-1.2.0-py3-none-any.whl (498 kB)\n",
            "  Using cached allennlp-1.1.0-py3-none-any.whl (485 kB)\n",
            "  Using cached allennlp-1.0.0-py3-none-any.whl (473 kB)\n",
            "  Using cached allennlp-0.9.0-py3-none-any.whl (7.6 MB)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (2.3.1)\n",
            "Collecting overrides (from allennlp)\n",
            "  Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Collecting spacy\n",
            "  Using cached spacy-2.1.9.tar.gz (30.7 MB)\n",
            "  Installing build dependencies ... \u001b[?25lcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.3.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "By4mCrs_Iive",
        "outputId": "b7725bdd-0db8-4354-a73a-da3222d68e31"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.3.1 in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1i-XuGcu-Q1",
        "outputId": "3d216dbe-3c46-4a45-ba54-87472f62dfab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-12 09:03:50.389729: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-07-12 09:03:50.441851: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-12 09:03:50.441906: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-12 09:03:50.443458: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-12 09:03:50.451338: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-12 09:03:51.591006: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.3.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.3.0) (3.3.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.11)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.66.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.25.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (24.1)\n",
            "Collecting typing-extensions<4.6.0,>=3.7.4.1 (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0)\n",
            "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.4.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.2.0)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2024.6.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.2.0)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sqlalchemy 2.0.31 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "inflect 7.0.0 requires pydantic>=1.9.1, but you have pydantic 1.8.2 which is incompatible.\n",
            "pydantic-core 2.20.0 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "torch 2.3.1 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.3.1 which is incompatible.\n",
            "torchvision 0.13.1 requires torch==1.12.1, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typing-extensions-4.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "64O6jFzvZbn8"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Git/muse-dlf/src')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "chTflGnAZbn9",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from preprocessing.pre_processor import PreProcessor\n",
        "from preprocessing.datasets.article_dataset import custom_collate_fn\n",
        "from model.slmuse_dlf.muse import SLMUSEDLF\n",
        "\n",
        "# import tokenizer for roberta fast\n",
        "from transformers import RobertaTokenizerFast\n",
        "import wandb\n",
        "import inspect\n",
        "import torch\n",
        "import spacy\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.require(\"core\")"
      ],
      "metadata": {
        "id": "LN0JtdjfIqiI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "vPubufhVrw5j"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjfKD_SdryLM",
        "outputId": "266b3960-a7b3-40e8-a3f7-38fee5dc07e4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QmA0w5cEZbn9"
      },
      "outputs": [],
      "source": [
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"drive/MyDrive/Git/\""
      ],
      "metadata": {
        "id": "-_A9sYmz4PbB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup wandb"
      ],
      "metadata": {
        "id": "Y3A9PIWoFoTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(project=\"slmuse-dlf\", job_type=\"inference\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "-z7tRE5LFqvi",
        "outputId": "a5d3078b-39ea-4a70-e7c5-9e51d3bc4608"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33melias-anderlohr\u001b[0m (\u001b[33melianderlohr\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240712_090416-7dako9eu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/elianderlohr/slmuse-dlf/runs/7dako9eu' target=\"_blank\">vivid-galaxy-3206</a></strong> to <a href='https://wandb.ai/elianderlohr/slmuse-dlf' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/elianderlohr/slmuse-dlf' target=\"_blank\">https://wandb.ai/elianderlohr/slmuse-dlf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/elianderlohr/slmuse-dlf/runs/7dako9eu' target=\"_blank\">https://wandb.ai/elianderlohr/slmuse-dlf/runs/7dako9eu</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean"
      ],
      "metadata": {
        "id": "vdl6Bx1i8Xbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_gpu_memory():\n",
        "    # Clear cache\n",
        "    torch.cuda.empty_cache()\n",
        "    # Reset peak memory stats\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "    # Perform garbage collection\n",
        "    import gc\n",
        "    gc.collect()\n",
        "\n",
        "clean_gpu_memory()"
      ],
      "metadata": {
        "id": "dZgxK7JD7uCY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load SLMuSE-DLF"
      ],
      "metadata": {
        "id": "F1BsPcRQoj7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_artifact = run.use_artifact('elianderlohr/slmuse-dlf/crashing_backpack_5645_model:v1', type='model')\n",
        "model_dir = model_artifact.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sfwUVe3dDfj",
        "outputId": "9f359b1b-877c-473d-f95b-bffe51f079bd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact crashing_backpack_5645_model:v1, 5168.22MB. 2 files... \n",
            "Done. 0:0:0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Roberta Model"
      ],
      "metadata": {
        "id": "LW3yoja8oBGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roberta_artifact = run.use_artifact('elianderlohr-org/wandb-registry-model/mfc-roberta-finetune:v1', type='model')\n",
        "roberta_dir = roberta_artifact.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiTKrAGqnY2K",
        "outputId": "620719f8-6bc3-4ac8-cdd3-674fc4e1b86e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact mfc-roberta-finetune:v1, 1427.32MB. 7 files... \n",
            "Done. 0:0:0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "CNPg-eDhFyGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_artifact = run.use_artifact('elianderlohr-org/wandb-registry-dataset/slmuse-dlf:v3', type='dataset')\n",
        "dataset_dir = dataset_artifact.download()"
      ],
      "metadata": {
        "id": "pCKg4MndFxl2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Config"
      ],
      "metadata": {
        "id": "XaTUyqwdonWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the run that created the artifactelianderlohr/slmuse-dlf/qa9dh6px\n",
        "run_id = 'elianderlohr/slmuse-dlf/rl2pr1nz'  # Replace with your run ID if known, otherwise see below for how to get it\n",
        "run_ref = wandb.Api().run(run_id)"
      ],
      "metadata": {
        "id": "r5nlzlGEfzKH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the configuration\n",
        "config = run_ref.config"
      ],
      "metadata": {
        "id": "CpKpHhgfgI_e"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the parameters of the SLMUSEDLF class constructor\n",
        "params = inspect.signature(SLMUSEDLF.__init__).parameters\n",
        "\n",
        "# Extract the relevant parameters from the config dictionary\n",
        "model_params = {key: config[key] for key in params if key in config}"
      ],
      "metadata": {
        "id": "t-WmUCAAhEG3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_params[\"bert_model_name\"] = \"roberta-base\"\n",
        "model_params[\"bert_model_name_or_path\"] = roberta_dir"
      ],
      "metadata": {
        "id": "Ss1fhAHpkbrY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ],
      "metadata": {
        "id": "jPmzpnlctnpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SLMUSEDLF(**model_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvAvo7stgr3e",
        "outputId": "6b3a006a-2f55-40af-ca79-6b934eec86cc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/artifacts/roberta-base-finetune-checkpoint-16482:v0 were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at /content/artifacts/roberta-base-finetune-checkpoint-16482:v0 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def strip_prefix_from_state_dict(state_dict, prefix):\n",
        "    \"\"\"Strip a prefix from the keys in state_dict.\"\"\"\n",
        "    return {key[len(prefix):]: value for key, value in state_dict.items() if key.startswith(prefix)}\n",
        "\n",
        "# Assuming you load the state_dict as follows\n",
        "state_dict = torch.load(f\"{model_dir}/model.pth\", map_location=\"cuda\")"
      ],
      "metadata": {
        "id": "SrGimvG3q8Sr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stripped_state_dict = strip_prefix_from_state_dict(state_dict, 'module.module.')\n",
        "model_state_dict = model.state_dict()\n",
        "model_state_dict.update(stripped_state_dict)"
      ],
      "metadata": {
        "id": "kuBFhY8jq-KN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(model_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAqL19m7plBQ",
        "outputId": "18e3f373-b6cf-4759-9eef-58a1d0dd2efc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Dataset"
      ],
      "metadata": {
        "id": "PlsQtGDIrHvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/Git/muse-dlf/data/axis"
      ],
      "metadata": {
        "id": "dVecDmv4reH4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e862e99-0603-4d1d-9c4a-245ecea15435"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "732_semaxis_axes.tsv  mft_experiment.json  mft_raw.csv\n",
            "custom.tsv\t      mft_filtered.csv\t   plutchik_wheel_of_emotions.tsv\n",
            "frames.json\t      mft.json\t\t   wordnet_antonyms.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "nC8n3yHSZbn-"
      },
      "outputs": [],
      "source": [
        "class_column_names = \"Capacity and Resources;Crime and Punishment;Cultural Identity;Economic;External Regulation and Reputation;Fairness and Equality;Health and Safety;Legality, Constitutionality, Jurisdiction;Morality;Other;Policy Prescription and Evaluation;Political;Public Sentiment;Quality of Life;Security and Defense\".split(\";\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Full Dataset"
      ],
      "metadata": {
        "id": "TR-m4v9k4Gte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths to the dataset files within the downloaded directory\n",
        "train_artifact_filepath = Path(dataset_dir) / 'train_dataset_artifact.pkl'\n",
        "test_artifact_filepath = Path(dataset_dir) / 'test_dataset_artifact.pkl'\n",
        "\n",
        "# Load the datasets from the artifact files\n",
        "with train_artifact_filepath.open(\"rb\") as f:\n",
        "    loaded_train_dataset = pickle.load(f)\n",
        "\n",
        "with test_artifact_filepath.open(\"rb\") as f:\n",
        "    loaded_test_dataset = pickle.load(f)"
      ],
      "metadata": {
        "id": "kJ3qF8qEJKCZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataloaders\n",
        "train_dataloader = DataLoader(\n",
        "    loaded_train_dataset,\n",
        "    batch_size=config[\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    collate_fn=custom_collate_fn,\n",
        "    drop_last=True,\n",
        "    pin_memory=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    loaded_test_dataset,\n",
        "    batch_size=config[\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    collate_fn=custom_collate_fn,\n",
        "    drop_last=True,\n",
        "    pin_memory=True,\n",
        "    num_workers=1,\n",
        ")"
      ],
      "metadata": {
        "id": "q_rT-GsMJKEr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Example Dataset"
      ],
      "metadata": {
        "id": "625C1WpM4Ai3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = PreProcessor(\n",
        "    tokenizer=tokenizer,\n",
        "    batch_size=config[\"batch_size\"],\n",
        "    max_sentences_per_article=config[\"num_sentences\"],\n",
        "    max_sentence_length=config[\"max_sentence_length\"],\n",
        "    max_args_per_sentence=config[\"max_args_per_sentence\"],\n",
        "    max_arg_length=config[\"max_arg_length\"],\n",
        "    frameaxis_dim=config[\"frameaxis_dim\"],\n",
        "    bert_model_name=\"roberta-base\",\n",
        "    name_tokenizer=\"roberta-base\",\n",
        "    path_name_bert_model=roberta_dir,\n",
        "    path_antonym_pairs=f\"{base_path}muse-dlf/data/axis/mft.json\",\n",
        "    dim_names=[\"virtue\", \"vice\"],\n",
        "    class_column_names=class_column_names,\n",
        "    )"
      ],
      "metadata": {
        "id": "dvSBNZP54ItA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "UuUUWwAQZbn_"
      },
      "outputs": [],
      "source": [
        "text = \"BILL ON IMMIGRANT WORKERS DIES. Legislation to allow nearly twice as many computer-savvy foreigners and other high-skilled immigrants into the country next year apparently has died in Congress. The House passed the compromise measure last month, 288-133, but Sen. Tom Harkin, D-Iowa, had blocked a vote when in the Senate. The proposal, backed by high-tech companies, would raise the limit of so- called H-1B visas granted each year to skilled workers from abroad. Only 65,000 visas are now granted each year; the bill would raise the annual cap to 115,500 for the next two years and to 107,500 in 2001. The ceiling would return to 65,000 in 2002.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "collapsed": true,
        "id": "hHp5NIXUZboA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d4a0f50-6313-4879-bb4d-f0c717f3d058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:431.)\n",
            "  _C._set_default_tensor_type(t)\n",
            "Processing SRL Batches: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "Some weights of the model checkpoint at /content/artifacts/roberta-base-finetune-checkpoint-16482:v0 were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at /content/artifacts/roberta-base-finetune-checkpoint-16482:v0 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Generating antonym embeddings: 100%|██████████| 6/6 [00:02<00:00,  2.88it/s]\n",
            "Generating average embeddings:   0%|          | 0/5 [00:00<?, ?it/s]\n",
            "Processing dimension:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Processing word:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                       \u001b[A\u001b[A\n",
            "\n",
            "Processing word:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                       \u001b[A\u001b[A\n",
            "                                                           \u001b[A\n",
            "Processing dimension:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Processing word:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                       \u001b[A\u001b[A\n",
            "\n",
            "Processing word:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                       \u001b[A\u001b[A\n",
            "                                                           \u001b[A\n",
            "Processing dimension:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Processing word:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                       \u001b[A\u001b[A\n",
            "\n",
            "Processing word:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                       \u001b[A\u001b[A\n",
            "                                                           \u001b[A\n",
            "Processing dimension:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Processing word:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                       \u001b[A\u001b[A\n",
            "\n",
            "Processing word:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                       \u001b[A\u001b[A\n",
            "Generating average embeddings:  80%|████████  | 4/5 [00:00<00:00, 35.06it/s]\n",
            "Processing dimension:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Processing word:   0%|          | 0/37 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                       \u001b[A\u001b[A\n",
            "\n",
            "Processing word:   0%|          | 0/31 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                       \u001b[A\u001b[A\n",
            "Generating average embeddings: 100%|██████████| 5/5 [00:00<00:00, 33.93it/s]\n",
            "Generating microframes: 100%|██████████| 5/5 [00:00<00:00, 4897.60it/s]\n",
            "Calculating Word Contributions: 100%|██████████| 6/6 [00:00<00:00, 32.36it/s]\n"
          ]
        }
      ],
      "source": [
        "example_dataset, example_dataloader = preprocessor.preprocess_single_article(\n",
        "    text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run model with data"
      ],
      "metadata": {
        "id": "KtQxvG8QuS_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.current_device())\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9bz25LMISv-",
        "outputId": "d5af2d3c-8f01-41d2-96ac-9ee6003c0bf8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "0\n",
            "NVIDIA L4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n"
      ],
      "metadata": {
        "id": "TyQRRFCNIYxR"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "2Km9loHdZboB"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def inspect(model, dataloader, device='cuda'):\n",
        "    \"\"\"\n",
        "    Make predictions with the given model and dataloader.\n",
        "\n",
        "    Args:\n",
        "    - model (torch.nn.Module): The model to make predictions with.\n",
        "    - dataloader (DataLoader): DataLoader for the dataset to predict on.\n",
        "    - device (str): Device to make predictions on ('cpu' or 'cuda').\n",
        "\n",
        "    Returns:\n",
        "    - predicted_labels (list of lists): List containing the predicted labels for each instance.\n",
        "    \"\"\"\n",
        "    model = model.to(\"cuda\")\n",
        "    model.eval()\n",
        "\n",
        "    # dim\n",
        "    batch_size = dataloader.batch_size\n",
        "    num_sentences = dataloader.dataset.max_sentences_per_article\n",
        "    max_args_per_sentence = dataloader.dataset.max_args_per_sentence\n",
        "    K = 15\n",
        "\n",
        "    print(\"num_batches\", len(dataloader))\n",
        "    print(\"batch_size\", batch_size)\n",
        "    print(\"num_sentences\", num_sentences)\n",
        "    print(\"max_args_per_sentence\", max_args_per_sentence)\n",
        "    print(\"K\", K)\n",
        "\n",
        "    all_preds_span = []\n",
        "\n",
        "    # Initialize usage lists for each label\n",
        "    all_used_labels_p = []\n",
        "    all_used_labels_a0 = []\n",
        "    all_used_labels_a1 = []\n",
        "\n",
        "    all_used_fx = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Wrap the dataloader with tqdm for batch progress\n",
        "        for batch in tqdm(dataloader, desc=\"Processing Batches\"):\n",
        "            sentence_ids = batch['sentence_ids'].to(device)\n",
        "            sentence_attention_masks = batch['sentence_attention_masks'].to(device)\n",
        "\n",
        "            predicate_ids = batch['predicate_ids'].to(device)\n",
        "            arg0_ids = batch['arg0_ids'].to(device)\n",
        "            arg1_ids = batch['arg1_ids'].to(device)\n",
        "\n",
        "            frameaxis_data = batch['frameaxis'].to(device)\n",
        "\n",
        "            sentence_embeddings, predicate_embeddings, arg0_embeddings, arg1_embeddings = model.aggregation(sentence_ids, sentence_attention_masks, predicate_ids, arg0_ids, arg1_ids)\n",
        "\n",
        "            # Process each span\n",
        "            for sentence_idx in range(sentence_embeddings.size(1)):\n",
        "                s_sentence_span = sentence_embeddings[:, sentence_idx, :]\n",
        "                v_fx = frameaxis_data[:, sentence_idx, :]\n",
        "\n",
        "                for span_idx in range(predicate_embeddings.size(2)):\n",
        "                    v_p_span = predicate_embeddings[:, sentence_idx, span_idx, :]\n",
        "                    v_a0_span = arg0_embeddings[:, sentence_idx, span_idx, :]\n",
        "                    v_a1_span = arg1_embeddings[:, sentence_idx, span_idx, :]\n",
        "\n",
        "                    mask_p = (v_p_span.abs().sum(dim=-1) != 0).float().bool()\n",
        "                    mask_a0 = (v_a0_span.abs().sum(dim=-1) != 0).float().bool()\n",
        "                    mask_a1 = (v_a1_span.abs().sum(dim=-1) != 0).float().bool()\n",
        "\n",
        "                    output = model.unsupervised.combined_autoencoder(\n",
        "                        v_p_span, v_a0_span, v_a1_span, mask_p, mask_a0, mask_a1, s_sentence_span, 0.6\n",
        "                    )\n",
        "\n",
        "                    all_used_labels_p.append(output[\"p\"][\"d\"].cpu().numpy())\n",
        "                    all_used_labels_a0.append(output[\"a0\"][\"d\"].cpu().numpy())\n",
        "                    all_used_labels_a1.append(output[\"a1\"][\"d\"].cpu().numpy())\n",
        "\n",
        "                    del v_p_span, v_a0_span, v_a1_span, mask_p, mask_a0, mask_a1, output\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "                mask_fx = (v_fx.abs().sum(dim=-1) != 0).float().bool()\n",
        "\n",
        "                frameaxis_output = model.unsupervised_fx.frameaxis_autoencoder(v_fx, mask_fx, s_sentence_span, 0.6)\n",
        "\n",
        "                all_used_fx.append(frameaxis_output[\"d\"].cpu().numpy())\n",
        "\n",
        "                del v_fx, mask_fx, frameaxis_output\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            # Forward pass\n",
        "            _, span_logits, sentence_logits, combined_logits, _ = model(\n",
        "                sentence_ids, sentence_attention_masks, predicate_ids, arg0_ids, arg1_ids, frameaxis_data, 0.5\n",
        "            )\n",
        "            combined_pred = (torch.softmax(combined_logits, dim=-1) > 0.5).float()\n",
        "\n",
        "            all_preds_span.append(combined_pred.cpu().numpy())\n",
        "\n",
        "            del sentence_ids, sentence_attention_masks, predicate_ids, arg0_ids, arg1_ids, frameaxis_data\n",
        "            del sentence_embeddings, predicate_embeddings, arg0_embeddings, arg1_embeddings\n",
        "            del span_logits, sentence_logits, combined_logits, combined_pred\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    predictions = np.vstack(all_preds_span)\n",
        "\n",
        "    all_used_labels_p = np.vstack(all_used_labels_p)\n",
        "    all_used_labels_a0 = np.vstack(all_used_labels_a0)\n",
        "    all_used_labels_a1 = np.vstack(all_used_labels_a1)\n",
        "\n",
        "    all_used_fx = np.vstack(all_used_fx)\n",
        "\n",
        "    # reshape from (iterator (1), num sentences 24, num spans 10, batch size 64, classes 15) to (batch size 64, num sentences 24, num spans 10, classes 15)\n",
        "    all_used_labels_p = all_used_labels_p.reshape(-1, num_sentences, max_args_per_sentence, K)\n",
        "    all_used_labels_a0 = all_used_labels_a0.reshape(-1, num_sentences, max_args_per_sentence, K)\n",
        "    all_used_labels_a1 = all_used_labels_a1.reshape(-1, num_sentences, max_args_per_sentence, K)\n",
        "\n",
        "    all_used_fx = all_used_fx.reshape(-1, num_sentences, K)\n",
        "\n",
        "    return predictions, all_used_labels_p, all_used_labels_a0, all_used_labels_a1, all_used_fx\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_gpu_memory()"
      ],
      "metadata": {
        "id": "h2NgbgcEIbnK"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "G4OVaC3KZboC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "57319373240947b48e64095a14495f41",
            "715a00bafaa749aab045c54d5c11772b",
            "ee2a77d4c6664397a29cc4c901b92d48",
            "755f2fa8852b4756802c9993532f835c",
            "859ae0646e8649729655c2d7e600ed3f",
            "31bfffe96891441d84ac433d2531e8f6",
            "4549d1f405ef463e9d1618aa48a353b3",
            "bf9c9eac52c648b0b5bf39a90f1771a3",
            "402add9ba800450faae78649223b3ffc",
            "65e17965ee964061b5b980c30be294e9",
            "37d21480b55b46578eeb78eba151646c"
          ]
        },
        "cellView": "code",
        "outputId": "0efd8964-16c2-4f45-b631-65cc5856701d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_batches 37\n",
            "batch_size 32\n",
            "num_sentences 32\n",
            "max_args_per_sentence 10\n",
            "K 15\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing Batches:   0%|          | 0/37 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57319373240947b48e64095a14495f41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        }
      ],
      "source": [
        "output = inspect(model, test_dataloader, device=\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "LMBq0Zh-ZboC"
      },
      "outputs": [],
      "source": [
        "predicted_labels, used_labels_p, used_labels_a0, used_labels_a1, used_fx = output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving numpy arrays to file\n",
        "np.savez(base_path + '/labels_data.npz',\n",
        "         predicted_labels=predicted_labels,\n",
        "         used_labels_p=used_labels_p,\n",
        "         used_labels_a0=used_labels_a0,\n",
        "         used_labels_a1=used_labels_a1,\n",
        "         used_fx=used_fx)"
      ],
      "metadata": {
        "id": "QKQXr8WERo6v"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_lists_p = {category: [] for category in class_column_names}\n",
        "category_lists_a1 = {category: [] for category in class_column_names}\n",
        "category_lists_a0 = {category: [] for category in class_column_names}\n",
        "\n",
        "category_lists_fx = {category: [] for category in class_column_names}\n",
        "\n",
        "boundary = 0.4\n",
        "\n",
        "elem_len = len(test_dataloader.dataset)\n",
        "for elem_idx in range(elem_len):\n",
        "    ds = test_dataloader.dataset[elem_idx]\n",
        "\n",
        "    sent_len = len(ds[\"predicate_ids\"])\n",
        "    for sentence_idx in range(sent_len):\n",
        "        span_len = len(ds[\"predicate_ids\"][sentence_idx])\n",
        "        for span_idx in range(span_len):\n",
        "\n",
        "          for cat_idx, category in enumerate(class_column_names):\n",
        "              if used_labels_p[elem_idx][sentence_idx][span_idx][cat_idx] > boundary:\n",
        "                category_lists_p[category].append(ds[\"predicate_ids\"][sentence_idx][span_idx].int().numpy())\n",
        "\n",
        "              if used_labels_a0[elem_idx][sentence_idx][span_idx][cat_idx] > boundary:\n",
        "                category_lists_a0[category].append(ds[\"arg0_ids\"][sentence_idx][span_idx].int().numpy())\n",
        "\n",
        "              if used_labels_a1[elem_idx][sentence_idx][span_idx][cat_idx] > boundary:\n",
        "                category_lists_a1[category].append(ds[\"arg1_ids\"][sentence_idx][span_idx].int().numpy())\n",
        "\n",
        "        if used_fx[elem_idx][sentence_idx][cat_idx] > boundary:\n",
        "          category_lists_fx[category].append(ds[\"frameaxis\"][sentence_idx].float().numpy())"
      ],
      "metadata": {
        "id": "xamzs85qyYcr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "02b8e2df-cc2f-4726-a645-bb6e23ac5b02"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 1184 is out of bounds for axis 0 with size 1184",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-11bac693a3bb>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mcat_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_column_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m               \u001b[0;32mif\u001b[0m \u001b[0mused_labels_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspan_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mboundary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mcategory_lists_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predicate_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspan_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1184 is out of bounds for axis 0 with size 1184"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Ensure you have downloaded the necessary NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def decode_tokens(token_dict, tokenizer, remove_stopwords=False, lemmatize=False):\n",
        "    decoded_data = {}\n",
        "    stop_words = set(stopwords.words('english')) if remove_stopwords else set()\n",
        "    lemmatizer = WordNetLemmatizer() if lemmatize else None\n",
        "\n",
        "    for category, token_lists in token_dict.items():\n",
        "        decoded_data[category] = []\n",
        "        for tokens in token_lists:\n",
        "            if np.any(tokens > 0):\n",
        "                # Convert tokens to a list if it's a tensor or numpy array\n",
        "                if isinstance(tokens, torch.Tensor):\n",
        "                    tokens = tokens.tolist()\n",
        "                elif isinstance(tokens, np.ndarray):\n",
        "                    tokens = tokens.tolist()\n",
        "\n",
        "                # Decode the tokens\n",
        "                decoded_text = tokenizer.decode(tokens, skip_special_tokens=True).strip()\n",
        "\n",
        "                # Remove non-alphabetic characters (but keep spaces)\n",
        "                decoded_text = re.sub(r'[^A-Za-z ]', '', decoded_text)\n",
        "\n",
        "                # Tokenize, optionally lemmatize, and remove stop words\n",
        "                words = word_tokenize(decoded_text)\n",
        "                processed_words = [lemmatizer.lemmatize(word.lower()) if lemmatizer else word.lower() for word in words if word.lower() not in stop_words]\n",
        "\n",
        "                # Join the words back into a string and ensure it's not empty\n",
        "                processed_text = ' '.join(processed_words)\n",
        "                if processed_text:\n",
        "                    decoded_data[category].append(processed_text)\n",
        "\n",
        "    return decoded_data\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Decode the token IDs for each ARG\n",
        "decoded_predicate = decode_tokens(category_lists_p, tokenizer, remove_stopwords=True, lemmatize=True)\n",
        "decoded_arg0 = decode_tokens(category_lists_a0, tokenizer, remove_stopwords=True, lemmatize=True)\n",
        "decoded_arg1 = decode_tokens(category_lists_a1, tokenizer, remove_stopwords=True, lemmatize=True)"
      ],
      "metadata": {
        "id": "YB7NDk8JypXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LWZUAVv7RVpF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "57319373240947b48e64095a14495f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_715a00bafaa749aab045c54d5c11772b",
              "IPY_MODEL_ee2a77d4c6664397a29cc4c901b92d48",
              "IPY_MODEL_755f2fa8852b4756802c9993532f835c"
            ],
            "layout": "IPY_MODEL_859ae0646e8649729655c2d7e600ed3f"
          }
        },
        "715a00bafaa749aab045c54d5c11772b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31bfffe96891441d84ac433d2531e8f6",
            "placeholder": "​",
            "style": "IPY_MODEL_4549d1f405ef463e9d1618aa48a353b3",
            "value": "Processing Batches: 100%"
          }
        },
        "ee2a77d4c6664397a29cc4c901b92d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf9c9eac52c648b0b5bf39a90f1771a3",
            "max": 37,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_402add9ba800450faae78649223b3ffc",
            "value": 37
          }
        },
        "755f2fa8852b4756802c9993532f835c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65e17965ee964061b5b980c30be294e9",
            "placeholder": "​",
            "style": "IPY_MODEL_37d21480b55b46578eeb78eba151646c",
            "value": " 37/37 [21:03&lt;00:00, 34.31s/it]"
          }
        },
        "859ae0646e8649729655c2d7e600ed3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31bfffe96891441d84ac433d2531e8f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4549d1f405ef463e9d1618aa48a353b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf9c9eac52c648b0b5bf39a90f1771a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "402add9ba800450faae78649223b3ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65e17965ee964061b5b980c30be294e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37d21480b55b46578eeb78eba151646c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}