{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../data/')\n",
    "\n",
    "labels_path = \"data/en/train-labels-subtask-2.txt\"\n",
    "articles_path = \"data/en/train-articles-subtask-2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>frames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>832959523</td>\n",
       "      <td>Morality,Security_and_defense,Policy_prescript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>833039623</td>\n",
       "      <td>Political,Crime_and_punishment,External_regula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>833032367</td>\n",
       "      <td>Political,Crime_and_punishment,Fairness_and_eq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>814777937</td>\n",
       "      <td>Political,Morality,Fairness_and_equality,Exter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>821744708</td>\n",
       "      <td>Policy_prescription_and_evaluation,Political,L...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                             frames\n",
       "0   832959523  Morality,Security_and_defense,Policy_prescript...\n",
       "1   833039623  Political,Crime_and_punishment,External_regula...\n",
       "2   833032367  Political,Crime_and_punishment,Fairness_and_eq...\n",
       "3   814777937  Political,Morality,Fairness_and_equality,Exter...\n",
       "4   821744708  Policy_prescription_and_evaluation,Political,L..."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dev-labels-subtask-2.txt file\n",
    "labels_df = pd.read_csv(labels_path, sep=\"\\t\")\n",
    "\n",
    "# Rename the columns for easier processing\n",
    "labels_df.columns = [\"article_id\", \"frames\"]\n",
    "\n",
    "\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>frames</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>832959523</td>\n",
       "      <td>Morality,Security_and_defense,Policy_prescript...</td>\n",
       "      <td>How Theresa May Botched\\n\\nThose were the time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>833039623</td>\n",
       "      <td>Political,Crime_and_punishment,External_regula...</td>\n",
       "      <td>Robert Mueller III Rests His Case—Dems NEVER W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>833032367</td>\n",
       "      <td>Political,Crime_and_punishment,Fairness_and_eq...</td>\n",
       "      <td>Robert Mueller Not Recommending Any More Indic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>814777937</td>\n",
       "      <td>Political,Morality,Fairness_and_equality,Exter...</td>\n",
       "      <td>The Far Right Is Trying to Co-opt the Yellow V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>821744708</td>\n",
       "      <td>Policy_prescription_and_evaluation,Political,L...</td>\n",
       "      <td>‘Special place in hell’ for those who promoted...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                             frames  \\\n",
       "0   832959523  Morality,Security_and_defense,Policy_prescript...   \n",
       "1   833039623  Political,Crime_and_punishment,External_regula...   \n",
       "2   833032367  Political,Crime_and_punishment,Fairness_and_eq...   \n",
       "3   814777937  Political,Morality,Fairness_and_equality,Exter...   \n",
       "4   821744708  Policy_prescription_and_evaluation,Political,L...   \n",
       "\n",
       "                                             content  \n",
       "0  How Theresa May Botched\\n\\nThose were the time...  \n",
       "1  Robert Mueller III Rests His Case—Dems NEVER W...  \n",
       "2  Robert Mueller Not Recommending Any More Indic...  \n",
       "3  The Far Right Is Trying to Co-opt the Yellow V...  \n",
       "4  ‘Special place in hell’ for those who promoted...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A function to read the article text given its ID\n",
    "def get_article_content(article_id):\n",
    "    try:\n",
    "        with open(f\"{articles_path}/article{article_id}.txt\", \"r\") as f:\n",
    "            return f.read()\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "\n",
    "df = labels_df\n",
    "\n",
    "# Apply the function to get the article content\n",
    "df[\"content\"] = df[\"article_id\"].apply(get_article_content)\n",
    "\n",
    "# Drop rows where content could not be found\n",
    "df.dropna(subset=[\"content\"], inplace=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>frames</th>\n",
       "      <th>content</th>\n",
       "      <th>frames_list</th>\n",
       "      <th>Morality</th>\n",
       "      <th>Security_and_defense</th>\n",
       "      <th>Policy_prescription_and_evaluation</th>\n",
       "      <th>Legality_Constitutionality_and_jurisprudence</th>\n",
       "      <th>Economic</th>\n",
       "      <th>Political</th>\n",
       "      <th>Crime_and_punishment</th>\n",
       "      <th>External_regulation_and_reputation</th>\n",
       "      <th>Public_opinion</th>\n",
       "      <th>Fairness_and_equality</th>\n",
       "      <th>Capacity_and_resources</th>\n",
       "      <th>Quality_of_life</th>\n",
       "      <th>Cultural_identity</th>\n",
       "      <th>Health_and_safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>832959523</td>\n",
       "      <td>Morality,Security_and_defense,Policy_prescript...</td>\n",
       "      <td>How Theresa May Botched\\n\\nThose were the time...</td>\n",
       "      <td>[Morality, Security_and_defense, Policy_prescr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>833039623</td>\n",
       "      <td>Political,Crime_and_punishment,External_regula...</td>\n",
       "      <td>Robert Mueller III Rests His Case—Dems NEVER W...</td>\n",
       "      <td>[Political, Crime_and_punishment, External_reg...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>833032367</td>\n",
       "      <td>Political,Crime_and_punishment,Fairness_and_eq...</td>\n",
       "      <td>Robert Mueller Not Recommending Any More Indic...</td>\n",
       "      <td>[Political, Crime_and_punishment, Fairness_and...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>814777937</td>\n",
       "      <td>Political,Morality,Fairness_and_equality,Exter...</td>\n",
       "      <td>The Far Right Is Trying to Co-opt the Yellow V...</td>\n",
       "      <td>[Political, Morality, Fairness_and_equality, E...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>821744708</td>\n",
       "      <td>Policy_prescription_and_evaluation,Political,L...</td>\n",
       "      <td>‘Special place in hell’ for those who promoted...</td>\n",
       "      <td>[Policy_prescription_and_evaluation, Political...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                             frames  \\\n",
       "0   832959523  Morality,Security_and_defense,Policy_prescript...   \n",
       "1   833039623  Political,Crime_and_punishment,External_regula...   \n",
       "2   833032367  Political,Crime_and_punishment,Fairness_and_eq...   \n",
       "3   814777937  Political,Morality,Fairness_and_equality,Exter...   \n",
       "4   821744708  Policy_prescription_and_evaluation,Political,L...   \n",
       "\n",
       "                                             content  \\\n",
       "0  How Theresa May Botched\\n\\nThose were the time...   \n",
       "1  Robert Mueller III Rests His Case—Dems NEVER W...   \n",
       "2  Robert Mueller Not Recommending Any More Indic...   \n",
       "3  The Far Right Is Trying to Co-opt the Yellow V...   \n",
       "4  ‘Special place in hell’ for those who promoted...   \n",
       "\n",
       "                                         frames_list  Morality  \\\n",
       "0  [Morality, Security_and_defense, Policy_prescr...         1   \n",
       "1  [Political, Crime_and_punishment, External_reg...         0   \n",
       "2  [Political, Crime_and_punishment, Fairness_and...         0   \n",
       "3  [Political, Morality, Fairness_and_equality, E...         1   \n",
       "4  [Policy_prescription_and_evaluation, Political...         0   \n",
       "\n",
       "   Security_and_defense  Policy_prescription_and_evaluation  \\\n",
       "0                     1                                   1   \n",
       "1                     0                                   1   \n",
       "2                     0                                   0   \n",
       "3                     1                                   0   \n",
       "4                     0                                   1   \n",
       "\n",
       "   Legality_Constitutionality_and_jurisprudence  Economic  Political  \\\n",
       "0                                             1         1          0   \n",
       "1                                             1         0          1   \n",
       "2                                             1         0          1   \n",
       "3                                             0         1          1   \n",
       "4                                             1         0          1   \n",
       "\n",
       "   Crime_and_punishment  External_regulation_and_reputation  Public_opinion  \\\n",
       "0                     0                                   0               0   \n",
       "1                     1                                   1               1   \n",
       "2                     1                                   1               0   \n",
       "3                     0                                   1               1   \n",
       "4                     0                                   1               0   \n",
       "\n",
       "   Fairness_and_equality  Capacity_and_resources  Quality_of_life  \\\n",
       "0                      0                       0                0   \n",
       "1                      0                       0                0   \n",
       "2                      1                       0                0   \n",
       "3                      1                       0                0   \n",
       "4                      0                       0                0   \n",
       "\n",
       "   Cultural_identity  Health_and_safety  \n",
       "0                  0                  0  \n",
       "1                  0                  0  \n",
       "2                  0                  0  \n",
       "3                  0                  0  \n",
       "4                  0                  0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the frames column into a list of frames\n",
    "df[\"frames_list\"] = df[\"frames\"].str.split(\",\")\n",
    "\n",
    "# create for each frame a new column with the frame as name and 1 if the frame is present in the article and 0 if not\n",
    "for frame in df[\"frames_list\"].explode().unique():\n",
    "    df[frame] = df[\"frames_list\"].apply(lambda x: 1 if frame in x else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"content\"]\n",
    "y = df.drop(columns=[\"article_id\", \"frames\", \"frames_list\", \"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    How Theresa May Botched\\n\\nThose were the time...\n",
       "1    Robert Mueller III Rests His Case—Dems NEVER W...\n",
       "2    Robert Mueller Not Recommending Any More Indic...\n",
       "3    The Far Right Is Trying to Co-opt the Yellow V...\n",
       "4    ‘Special place in hell’ for those who promoted...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Morality</th>\n",
       "      <th>Security_and_defense</th>\n",
       "      <th>Policy_prescription_and_evaluation</th>\n",
       "      <th>Legality_Constitutionality_and_jurisprudence</th>\n",
       "      <th>Economic</th>\n",
       "      <th>Political</th>\n",
       "      <th>Crime_and_punishment</th>\n",
       "      <th>External_regulation_and_reputation</th>\n",
       "      <th>Public_opinion</th>\n",
       "      <th>Fairness_and_equality</th>\n",
       "      <th>Capacity_and_resources</th>\n",
       "      <th>Quality_of_life</th>\n",
       "      <th>Cultural_identity</th>\n",
       "      <th>Health_and_safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Morality  Security_and_defense  Policy_prescription_and_evaluation  \\\n",
       "0         1                     1                                   1   \n",
       "1         0                     0                                   1   \n",
       "2         0                     0                                   0   \n",
       "3         1                     1                                   0   \n",
       "4         0                     0                                   1   \n",
       "\n",
       "   Legality_Constitutionality_and_jurisprudence  Economic  Political  \\\n",
       "0                                             1         1          0   \n",
       "1                                             1         0          1   \n",
       "2                                             1         0          1   \n",
       "3                                             0         1          1   \n",
       "4                                             1         0          1   \n",
       "\n",
       "   Crime_and_punishment  External_regulation_and_reputation  Public_opinion  \\\n",
       "0                     0                                   0               0   \n",
       "1                     1                                   1               1   \n",
       "2                     1                                   1               0   \n",
       "3                     0                                   1               1   \n",
       "4                     0                                   1               0   \n",
       "\n",
       "   Fairness_and_equality  Capacity_and_resources  Quality_of_life  \\\n",
       "0                      0                       0                0   \n",
       "1                      0                       0                0   \n",
       "2                      1                       0                0   \n",
       "3                      1                       0                0   \n",
       "4                      0                       0                0   \n",
       "\n",
       "   Cultural_identity  Health_and_safety  \n",
       "0                  0                  0  \n",
       "1                  0                  0  \n",
       "2                  0                  0  \n",
       "3                  0                  0  \n",
       "4                  0                  0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(432, 432)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "from allennlp_models.structured_prediction.models import srl_bert\n",
    "\n",
    "# Load the SRL predictor\n",
    "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract SRL embeddings\n",
    "def extract_srl_embeddings(article):\n",
    "    # Get SRL predictions\n",
    "    srl_output = predictor.predict(sentence=article)\n",
    "    \n",
    "    print(srl_output)\n",
    "    # Extract predicates, ARG0, and ARG1 embeddings\n",
    "    # Note: This is a simplification. In practice, you might want to use a pre-trained embedding model \n",
    "    # (like BERT, GloVe, etc.) to convert these tokens to embeddings.\n",
    "    #predicates = [verb['verb'] for verb in srl_output['verbs']]\n",
    "    #ARG0s = [verb['description'].split('[')[1].split(']')[0] if 'ARG0' in verb['description'] else '' for verb in srl_output['verbs']]\n",
    "    #ARG1s = [verb['description'].split('[')[2].split(']')[0] if 'ARG1' in verb['description'] else '' for verb in srl_output['verbs']]\n",
    "    \n",
    "    #return predicates, ARG0s, ARG1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbs': [{'verb': 'turned', 'description': '[ARG1: The red horse] [ARGM-ADV: simply] [V: turned] [ARGM-DIR: around] and fought off the fly with its tail .', 'tags': ['B-ARG1', 'I-ARG1', 'I-ARG1', 'B-ARGM-ADV', 'B-V', 'B-ARGM-DIR', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}, {'verb': 'fought', 'description': '[ARG0: The red horse] [ARGM-ADV: simply] turned around and [V: fought] off [ARG1: the fly] [ARG2: with its tail] .', 'tags': ['B-ARG0', 'I-ARG0', 'I-ARG0', 'B-ARGM-ADV', 'O', 'O', 'O', 'B-V', 'O', 'B-ARG1', 'I-ARG1', 'B-ARG2', 'I-ARG2', 'I-ARG2', 'O']}], 'words': ['The', 'red', 'horse', 'simply', 'turned', 'around', 'and', 'fought', 'off', 'the', 'fly', 'with', 'its', 'tail', '.']}\n"
     ]
    }
   ],
   "source": [
    "extract_srl_embeddings(\"The red horse simply turned around and fought off the fly with its tail.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1111) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\elias\\OneDrive\\Dokumente\\Git\\MasterThesis\\notebooks\\friss-frameaxis.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Extract SRL embeddings for each article\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m srl_embeddings \u001b[39m=\u001b[39m [extract_srl_embeddings(article) \u001b[39mfor\u001b[39;00m article \u001b[39min\u001b[39;00m X]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Unpack the embeddings\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X35sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m predicates_embeddings, ARG0_embeddings, ARG1_embeddings \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39msrl_embeddings)\n",
      "\u001b[1;32mc:\\Users\\elias\\OneDrive\\Dokumente\\Git\\MasterThesis\\notebooks\\friss-frameaxis.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Extract SRL embeddings for each article\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m srl_embeddings \u001b[39m=\u001b[39m [extract_srl_embeddings(article) \u001b[39mfor\u001b[39;00m article \u001b[39min\u001b[39;00m X]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Unpack the embeddings\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X35sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m predicates_embeddings, ARG0_embeddings, ARG1_embeddings \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39msrl_embeddings)\n",
      "\u001b[1;32mc:\\Users\\elias\\OneDrive\\Dokumente\\Git\\MasterThesis\\notebooks\\friss-frameaxis.ipynb Cell 11\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_srl_embeddings\u001b[39m(article):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X35sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# Get SRL predictions\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     srl_output \u001b[39m=\u001b[39m predictor\u001b[39m.\u001b[39;49mpredict(sentence\u001b[39m=\u001b[39;49marticle)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X35sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# Extract predicates, ARG0, and ARG1 embeddings\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X35sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# Note: This is a simplification. In practice, you might want to use a pre-trained embedding model \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X35sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# (like BERT, GloVe, etc.) to convert these tokens to embeddings.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X35sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     predicates \u001b[39m=\u001b[39m [verb[\u001b[39m'\u001b[39m\u001b[39mverb\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m verb \u001b[39min\u001b[39;00m srl_output[\u001b[39m'\u001b[39m\u001b[39mverbs\u001b[39m\u001b[39m'\u001b[39m]]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\allennlp_models\\structured_prediction\\predictors\\srl.py:50\u001b[0m, in \u001b[0;36mSemanticRoleLabelerPredictor.predict\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, sentence: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m JsonDict:\n\u001b[0;32m     28\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39m    Predicts the semantic roles of the supplied sentence and returns a dictionary\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m    with the results.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39m    A dictionary representation of the semantic roles in the sentence.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_json({\u001b[39m\"\u001b[39;49m\u001b[39msentence\u001b[39;49m\u001b[39m\"\u001b[39;49m: sentence})\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\allennlp_models\\structured_prediction\\predictors\\srl.py:251\u001b[0m, in \u001b[0;36mSemanticRoleLabelerPredictor.predict_json\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m instances:\n\u001b[0;32m    249\u001b[0m     \u001b[39mreturn\u001b[39;00m sanitize({\u001b[39m\"\u001b[39m\u001b[39mverbs\u001b[39m\u001b[39m\"\u001b[39m: [], \u001b[39m\"\u001b[39m\u001b[39mwords\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tokenizer\u001b[39m.\u001b[39mtokenize(inputs[\u001b[39m\"\u001b[39m\u001b[39msentence\u001b[39m\u001b[39m\"\u001b[39m])})\n\u001b[1;32m--> 251\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_instances(instances)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\allennlp_models\\structured_prediction\\predictors\\srl.py:220\u001b[0m, in \u001b[0;36mSemanticRoleLabelerPredictor.predict_instances\u001b[1;34m(self, instances)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_instances\u001b[39m(\u001b[39mself\u001b[39m, instances: List[Instance]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m JsonDict:\n\u001b[1;32m--> 220\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model\u001b[39m.\u001b[39;49mforward_on_instances(instances)\n\u001b[0;32m    222\u001b[0m     results \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mverbs\u001b[39m\u001b[39m\"\u001b[39m: [], \u001b[39m\"\u001b[39m\u001b[39mwords\u001b[39m\u001b[39m\"\u001b[39m: outputs[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mwords\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[0;32m    223\u001b[0m     \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m outputs:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\allennlp\\models\\model.py:217\u001b[0m, in \u001b[0;36mModel.forward_on_instances\u001b[1;34m(self, instances)\u001b[0m\n\u001b[0;32m    215\u001b[0m dataset\u001b[39m.\u001b[39mindex_instances(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab)\n\u001b[0;32m    216\u001b[0m model_input \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mmove_to_device(dataset\u001b[39m.\u001b[39mas_tensor_dict(), cuda_device)\n\u001b[1;32m--> 217\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_output_human_readable(\u001b[39mself\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_input))\n\u001b[0;32m    219\u001b[0m instance_separated_output: List[Dict[\u001b[39mstr\u001b[39m, numpy\u001b[39m.\u001b[39mndarray]] \u001b[39m=\u001b[39m [\n\u001b[0;32m    220\u001b[0m     {} \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m dataset\u001b[39m.\u001b[39minstances\n\u001b[0;32m    221\u001b[0m ]\n\u001b[0;32m    222\u001b[0m \u001b[39mfor\u001b[39;00m name, output \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(outputs\u001b[39m.\u001b[39mitems()):\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\allennlp_models\\structured_prediction\\models\\srl_bert.py:141\u001b[0m, in \u001b[0;36mSrlBert.forward\u001b[1;34m(self, tokens, verb_indicator, metadata, tags)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[39m# Parameters\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m    A scalar loss to be optimised.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    140\u001b[0m mask \u001b[39m=\u001b[39m get_text_field_mask(tokens)\n\u001b[1;32m--> 141\u001b[0m bert_embeddings, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert_model(\n\u001b[0;32m    142\u001b[0m     input_ids\u001b[39m=\u001b[39;49mutil\u001b[39m.\u001b[39;49mget_token_ids_from_text_field_tensors(tokens),\n\u001b[0;32m    143\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mverb_indicator,\n\u001b[0;32m    144\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mmask,\n\u001b[0;32m    145\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    146\u001b[0m )\n\u001b[0;32m    148\u001b[0m embedded_text_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_dropout(bert_embeddings)\n\u001b[0;32m    149\u001b[0m batch_size, sequence_length, _ \u001b[39m=\u001b[39m embedded_text_input\u001b[39m.\u001b[39msize()\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1011\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1011\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[0;32m   1012\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m   1013\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1014\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1015\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1016\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[0;32m   1017\u001b[0m )\n\u001b[0;32m   1018\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[0;32m   1019\u001b[0m     embedding_output,\n\u001b[0;32m   1020\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1028\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[0;32m   1029\u001b[0m )\n\u001b[0;32m   1030\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:241\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mabsolute\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    240\u001b[0m     position_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embeddings(position_ids)\n\u001b[1;32m--> 241\u001b[0m     embeddings \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m position_embeddings\n\u001b[0;32m    242\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(embeddings)\n\u001b[0;32m    243\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(embeddings)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (1111) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Extract SRL embeddings for each article\n",
    "srl_embeddings = [extract_srl_embeddings(article) for article in X]\n",
    "\n",
    "# Unpack the embeddings\n",
    "predicates_embeddings, ARG0_embeddings, ARG1_embeddings = zip(*srl_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize each article into sentences (split by \".\")\n",
    "sentences = [sentence for article in X for sentence in article.split('.') if sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random embeddings for each sentence (in practice, replace with SRL embeddings)\n",
    "embedding_dim = 100\n",
    "sentences_embeddings = [torch.randn(embedding_dim) for _ in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class MultiViewAutoencoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, encoded_dim):\n",
    "        super(MultiViewAutoencoder, self).__init__()\n",
    "        \n",
    "        # For predicates\n",
    "        self.encoder_p = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, encoded_dim)\n",
    "        )\n",
    "        self.decoder_p = nn.Linear(encoded_dim, embedding_dim)\n",
    "        \n",
    "        # For ARG0\n",
    "        self.encoder_a0 = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, encoded_dim)\n",
    "        )\n",
    "        self.decoder_a0 = nn.Linear(encoded_dim, embedding_dim)\n",
    "        \n",
    "        # For ARG1\n",
    "        self.encoder_a1 = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, encoded_dim)\n",
    "        )\n",
    "        self.decoder_a1 = nn.Linear(encoded_dim, embedding_dim)\n",
    "    \n",
    "    def forward(self, x_p, x_a0, x_a1):\n",
    "        # Encoding\n",
    "        x_p = self.encoder_p(x_p)\n",
    "        x_a0 = self.encoder_a0(x_a0)\n",
    "        x_a1 = self.encoder_a1(x_a1)\n",
    "        \n",
    "        # Decoding\n",
    "        x_p = self.decoder_p(x_p)\n",
    "        x_a0 = self.decoder_a0(x_a0)\n",
    "        x_a1 = self.decoder_a1(x_a1)\n",
    "        \n",
    "        return x_p, x_a0, x_a1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifier\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, encoded_dim, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = nn.Linear(encoded_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dimensions\n",
    "embedding_dim = 300  # This could be the size of your word embeddings, e.g., 300 for GloVe or Word2Vec\n",
    "hidden_dim = 150     # This is an intermediate dimension, can be chosen based on model complexity\n",
    "encoded_dim = 50     # This is the final encoded dimension\n",
    "\n",
    "# Initialize the autoencoder\n",
    "autoencoder = MultiViewAutoencoder(embedding_dim, hidden_dim, encoded_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(y.columns)\n",
    "\n",
    "classifier = Classifier(encoded_dim, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([ 1.9269e+00,  1.4873e+00,  9.0072e-01, -2.1055e+00,  6.7842e-01,\n",
       "          -1.2345e+00, -4.3067e-02, -1.6047e+00, -7.5214e-01,  1.6487e+00,\n",
       "          -3.9248e-01, -1.4036e+00, -7.2788e-01, -5.5943e-01, -7.6884e-01,\n",
       "           7.6245e-01,  1.6423e+00, -1.5960e-01, -4.9740e-01,  4.3959e-01,\n",
       "          -7.5813e-01,  1.0783e+00,  8.0080e-01,  1.6806e+00,  1.2791e+00,\n",
       "           1.2964e+00,  6.1047e-01,  1.3347e+00, -2.3162e-01,  4.1759e-02,\n",
       "          -2.5158e-01,  8.5986e-01, -1.3847e+00, -8.7124e-01, -2.2337e-01,\n",
       "           1.7174e+00,  3.1888e-01, -4.2452e-01,  3.0572e-01, -7.7459e-01,\n",
       "          -1.5576e+00,  9.9564e-01, -8.7979e-01, -6.0114e-01, -1.2742e+00,\n",
       "           2.1228e+00, -1.2347e+00, -4.8791e-01, -9.1382e-01, -6.5814e-01,\n",
       "           7.8024e-02,  5.2581e-01, -4.8799e-01,  1.1914e+00, -8.1401e-01,\n",
       "          -7.3599e-01, -1.4032e+00,  3.6004e-02, -6.3477e-02,  6.7561e-01,\n",
       "          -9.7807e-02,  1.8446e+00, -1.1845e+00,  1.3835e+00,  1.4451e+00,\n",
       "           8.5641e-01,  2.2181e+00,  5.2317e-01,  3.4665e-01, -1.9733e-01,\n",
       "          -1.0546e+00,  1.2780e+00, -1.7219e-01,  5.2379e-01,  5.6622e-02,\n",
       "           4.2630e-01,  5.7501e-01, -6.4172e-01, -2.2064e+00, -7.5080e-01,\n",
       "           1.0868e-02, -3.3874e-01, -1.3407e+00, -5.8537e-01,  6.4076e-01,\n",
       "           5.8325e-01,  1.0669e+00, -4.5015e-01, -6.7875e-01,  5.7432e-01,\n",
       "           1.8775e-01, -3.5762e-01,  2.6491e-01,  1.2732e+00, -1.3109e-03,\n",
       "          -3.0360e-01, -9.8644e-01,  1.2330e-01,  3.4987e-01,  6.1728e-01]),\n",
       "  tensor([ 0.7262,  0.0912, -0.3891,  0.5279,  1.0311, -0.7048,  1.0131, -0.3308,\n",
       "           1.0950,  0.3399,  0.7200,  0.4114, -0.5733,  0.5069, -0.4752, -0.4920,\n",
       "          -0.1360,  1.6354,  0.6547,  0.5760, -0.3609, -0.0606,  0.0733,  0.8187,\n",
       "          -0.3753,  1.0331, -0.6867,  0.6368,  0.2176, -0.0467, -1.4335, -0.5665,\n",
       "           0.2695, -0.2104, -0.7328,  0.1043,  1.0414, -0.3997, -2.2933,  0.4976,\n",
       "          -2.4801, -0.4175, -1.1955,  0.8123, -0.3063, -0.3302, -0.9808,  0.1947,\n",
       "           0.2868, -0.7308,  0.1748, -1.0939,  0.9633, -0.3095,  0.5712,  1.1179,\n",
       "          -1.5469,  0.7567,  0.7755,  2.0265,  0.9812, -0.6401, -0.4908,  0.2080,\n",
       "          -0.9319, -1.5910, -1.1360, -0.5226,  0.7165,  1.5335, -1.4510, -0.7861,\n",
       "           1.0229, -0.5558,  0.7043,  0.7099, -1.5326, -0.7251,  0.4664,  0.6667,\n",
       "          -1.1753,  0.3581,  0.4788,  1.3537,  1.3032,  0.4879,  1.1340, -0.3556,\n",
       "           0.3618,  1.9993,  0.6630,  0.7047,  0.0213, -0.8293, -1.0809, -0.7839,\n",
       "           0.5071,  0.0821,  0.4440, -0.7240])],\n",
       " MultiViewAutoencoder(\n",
       "   (encoder_p): Sequential(\n",
       "     (0): Linear(in_features=300, out_features=150, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=150, out_features=50, bias=True)\n",
       "   )\n",
       "   (decoder_p): Linear(in_features=50, out_features=300, bias=True)\n",
       "   (encoder_a0): Sequential(\n",
       "     (0): Linear(in_features=300, out_features=150, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=150, out_features=50, bias=True)\n",
       "   )\n",
       "   (decoder_a0): Linear(in_features=50, out_features=300, bias=True)\n",
       "   (encoder_a1): Sequential(\n",
       "     (0): Linear(in_features=300, out_features=150, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=150, out_features=50, bias=True)\n",
       "   )\n",
       "   (decoder_a1): Linear(in_features=50, out_features=300, bias=True)\n",
       " ),\n",
       " Classifier(\n",
       "   (fc): Linear(in_features=50, out_features=14, bias=True)\n",
       " ))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_embeddings[:2], autoencoder, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\elias\\OneDrive\\Dokumente\\Git\\MasterThesis\\notebooks\\friss-frameaxis.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m targets \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, (num_classes,))\u001b[39m.\u001b[39mfloat() \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(sentences_embeddings))]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X24sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Assuming sentences_embeddings is a tuple of (predicates_embeddings, ARG0_embeddings, ARG1_embeddings)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m predicates_embeddings, ARG0_embeddings, ARG1_embeddings \u001b[39m=\u001b[39m sentences_embeddings\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Training loop\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# Define the loss functions\n",
    "reconstruction_loss_fn = nn.MSELoss()\n",
    "classification_loss_fn = nn.BCELoss()\n",
    "\n",
    "# Define the optimizer (both models' parameters are optimized jointly)\n",
    "optimizer = optim.Adam(list(autoencoder.parameters()) + list(classifier.parameters()), lr=0.001)\n",
    "\n",
    "# Number of epochs\n",
    "epochs = 10\n",
    "\n",
    "# Dummy target frames for demonstration (replace with actual frame data)\n",
    "targets = [torch.randint(0, 2, (num_classes,)).float() for _ in range(len(sentences_embeddings))]\n",
    "\n",
    "# Assuming sentences_embeddings is a tuple of (predicates_embeddings, ARG0_embeddings, ARG1_embeddings)\n",
    "predicates_embeddings, ARG0_embeddings, ARG1_embeddings = sentences_embeddings\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for embedding_p, embedding_a0, embedding_a1, target in zip(predicates_embeddings, ARG0_embeddings, ARG1_embeddings, targets):\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through the autoencoder\n",
    "        reconstructed_p, reconstructed_a0, reconstructed_a1 = autoencoder(embedding_p, embedding_a0, embedding_a1)\n",
    "\n",
    "        # Compute the reconstruction loss for each view\n",
    "        reconstruction_loss_p = reconstruction_loss_fn(reconstructed_p, embedding_p)\n",
    "        reconstruction_loss_a0 = reconstruction_loss_fn(reconstructed_a0, embedding_a0)\n",
    "        reconstruction_loss_a1 = reconstruction_loss_fn(reconstructed_a1, embedding_a1)\n",
    "\n",
    "        # Total reconstruction loss\n",
    "        total_reconstruction_loss = reconstruction_loss_p + reconstruction_loss_a0 + reconstruction_loss_a1\n",
    "\n",
    "        # Forward pass through the classifier (using the encoded embeddings of each view)\n",
    "        encoded_p = autoencoder.encoder_p(embedding_p)\n",
    "        encoded_a0 = autoencoder.encoder_a0(embedding_a0)\n",
    "        encoded_a1 = autoencoder.encoder_a1(embedding_a1)\n",
    "\n",
    "        # Combine the encoded embeddings (e.g., by averaging) before passing to the classifier\n",
    "        combined_encoded_embedding = (encoded_p + encoded_a0 + encoded_a1) / 3.0\n",
    "        frame_predictions = classifier(combined_encoded_embedding)\n",
    "\n",
    "        # Compute the classification loss\n",
    "        classification_loss = classification_loss_fn(frame_predictions, target)\n",
    "\n",
    "        # Combine the losses\n",
    "        combined_loss = total_reconstruction_loss + classification_loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        combined_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Reconstruction Loss: {total_reconstruction_loss.item()}, Classification Loss: {classification_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_frames(article, autoencoder, classifier):\n",
    "    # Tokenize the article into sentences\n",
    "    sentences = article.split('.')\n",
    "    \n",
    "    # Extract SRL embeddings for the sentences (use random embeddings for this demo)\n",
    "    embeddings = [torch.randn(embedding_dim) for sentence in sentences]\n",
    "    \n",
    "    # List to store frame predictions for each sentence\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():  # Ensure no gradients are computed during inference\n",
    "        for embedding in embeddings:\n",
    "            # Pass the embedding through the trained encoder\n",
    "            encoded_embedding = autoencoder.encoder(embedding)\n",
    "            \n",
    "            # Pass the encoded embedding through the trained classifier\n",
    "            frame_predictions = classifier(encoded_embedding)\n",
    "            \n",
    "            # Convert frame predictions to binary (0 or 1) using a threshold (e.g., 0.5)\n",
    "            frame_predictions = (frame_predictions > 0.5).float()\n",
    "            \n",
    "            all_predictions.append(frame_predictions)\n",
    "    \n",
    "    # Aggregate sentence-level predictions to get document-level prediction (average in this case)\n",
    "    avg_prediction = torch.mean(torch.stack(all_predictions), dim=0)\n",
    "    document_prediction = (avg_prediction > 0.5).float()\n",
    "    \n",
    "    return document_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Political',\n",
       "  'Fairness_and_equality',\n",
       "  'Policy_prescription_and_evaluation',\n",
       "  'Security_and_defense',\n",
       "  'Economic',\n",
       "  'Public_opinion\\n'],\n",
       " ['Security_and_defense',\n",
       "  'Legality_Constitutionality_and_jurisprudence',\n",
       "  'Economic',\n",
       "  'Crime_and_punishment',\n",
       "  'Public_opinion',\n",
       "  'Fairness_and_equality'])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read article from data\\en\\dev-articles-subtask-2\\article813452859.txt\n",
    "with open(\"data/en/dev-articles-subtask-2/article813452859.txt\", \"r\") as f:\n",
    "    article = f.read()\n",
    "\n",
    "# Predict frames for the article\n",
    "predicted_frames = predict_frames(article, autoencoder, classifier)\n",
    "\n",
    "# Convert the predicted frames to a list of frames\n",
    "predicted_frames = [y.columns[i] for i, frame in enumerate(predicted_frames) if frame == 1]\n",
    "\n",
    "\n",
    "# read the true frames from data\\en\\dev-labels-subtask-2.txt\n",
    "with open(\"data/en/dev-labels-subtask-2.txt\", \"r\") as f:\n",
    "    true_frames = f.readlines()[0].split(\"\\t\")[1].split(\",\")\n",
    "\n",
    "true_frames, predicted_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3636363636363636"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the F1 score\n",
    "def f1_score(predicted_frames, true_frames):\n",
    "    tp = len(set(predicted_frames) & set(true_frames))\n",
    "    fp = len(set(predicted_frames) - set(true_frames))\n",
    "    fn = len(set(true_frames) - set(predicted_frames))\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "f1_score(predicted_frames, true_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
