<<<<<<< HEAD
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../data/')\n",
    "\n",
    "labels_path = \"data/en/dev-labels-subtask-3.txt\"\n",
    "articles_path = \"data/en/dev-articles-subtask-3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>persuasion_technique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>813452859</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>813452859</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>813452859</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>813452859</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>813452859</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  sentence_id persuasion_technique\n",
       "0   813452859            1                  NaN\n",
       "1   813452859            3                  NaN\n",
       "2   813452859            4                  NaN\n",
       "3   813452859            5                  NaN\n",
       "4   813452859            6                  NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dev-labels-subtask-2.txt file\n",
    "labels_df = pd.read_csv(labels_path, sep='\\t', header=None, names=[\"article_id\", \"sentence_id\", \"persuasion_technique\"])\n",
    "\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>persuasion_technique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>813452859</td>\n",
       "      <td>7</td>\n",
       "      <td>Michael Swadling: I guess her only chance is i...</td>\n",
       "      <td>False_Dilemma-No_Choice,Loaded_Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>813452859</td>\n",
       "      <td>9</td>\n",
       "      <td>There is a chance; as unfortunately there are ...</td>\n",
       "      <td>False_Dilemma-No_Choice,Loaded_Language,Name_C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>813452859</td>\n",
       "      <td>11</td>\n",
       "      <td>Michael Swadling: The EU withdrawal act is in ...</td>\n",
       "      <td>Conversation_Killer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>813452859</td>\n",
       "      <td>12</td>\n",
       "      <td>I often use the example of an iPhone to people...</td>\n",
       "      <td>Conversation_Killer,Red_Herring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>813452859</td>\n",
       "      <td>15</td>\n",
       "      <td>Michael Swadling: The EU makes a profit on its...</td>\n",
       "      <td>Obfuscation-Vagueness-Confusion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  sentence_id                                           sentence  \\\n",
       "0   813452859            7  Michael Swadling: I guess her only chance is i...   \n",
       "1   813452859            9  There is a chance; as unfortunately there are ...   \n",
       "2   813452859           11  Michael Swadling: The EU withdrawal act is in ...   \n",
       "3   813452859           12  I often use the example of an iPhone to people...   \n",
       "4   813452859           15  Michael Swadling: The EU makes a profit on its...   \n",
       "\n",
       "                                persuasion_technique  \n",
       "0            False_Dilemma-No_Choice,Loaded_Language  \n",
       "1  False_Dilemma-No_Choice,Loaded_Language,Name_C...  \n",
       "2                                Conversation_Killer  \n",
       "3                    Conversation_Killer,Red_Herring  \n",
       "4                    Obfuscation-Vagueness-Confusion  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique article IDs from the dev-labels data\n",
    "unique_article_ids = labels_df['article_id'].unique()\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "\n",
    "# For each unique article ID, read the corresponding article file and join with the dev-labels data\n",
    "for article_id in unique_article_ids:\n",
    "    # Construct the file path for the article\n",
    "    file_path = f\"{articles_path}/article{article_id}.txt\"\n",
    "    \n",
    "    try:\n",
    "        # Load the article file\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Read the article sentences into a list\n",
    "            sentences = file.readlines()\n",
    "\n",
    "        # Filter dev-labels data for the current article_id and where persuasion_technique is not NaN\n",
    "        relevant_rows = labels_df[(labels_df['article_id'] == article_id) & (~labels_df['persuasion_technique'].isna())]\n",
    "\n",
    "        # For each relevant row, get the corresponding sentence and persuasion technique and append to the results list\n",
    "        for _, row in relevant_rows.iterrows():\n",
    "            sentence = sentences[row['sentence_id'] - 1].strip()  # Subtracting 1 because list indexing starts from 0\n",
    "            technique = row['persuasion_technique']\n",
    "            results.append([article_id, row['sentence_id'], sentence, technique])\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        # If the file for an article_id doesn't exist, continue to the next one\n",
    "        continue\n",
    "\n",
    "# Convert the results list to a dataframe\n",
    "df = pd.DataFrame(results, columns=['article_id', 'sentence_id', 'sentence', 'persuasion_technique'])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>persuasion_technique</th>\n",
       "      <th>persuasion_technique_list</th>\n",
       "      <th>False_Dilemma-No_Choice</th>\n",
       "      <th>Loaded_Language</th>\n",
       "      <th>Name_Calling-Labeling</th>\n",
       "      <th>Conversation_Killer</th>\n",
       "      <th>Red_Herring</th>\n",
       "      <th>...</th>\n",
       "      <th>Flag_Waving</th>\n",
       "      <th>Doubt</th>\n",
       "      <th>Whataboutism</th>\n",
       "      <th>Appeal_to_Fear-Prejudice</th>\n",
       "      <th>Causal_Oversimplification</th>\n",
       "      <th>Appeal_to_Hypocrisy</th>\n",
       "      <th>Appeal_to_Popularity</th>\n",
       "      <th>Appeal_to_Authority</th>\n",
       "      <th>Straw_Man</th>\n",
       "      <th>Guilt_by_Association</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>813452859</td>\n",
       "      <td>7</td>\n",
       "      <td>Michael Swadling: I guess her only chance is i...</td>\n",
       "      <td>False_Dilemma-No_Choice,Loaded_Language</td>\n",
       "      <td>[False_Dilemma-No_Choice, Loaded_Language]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>813452859</td>\n",
       "      <td>9</td>\n",
       "      <td>There is a chance; as unfortunately there are ...</td>\n",
       "      <td>False_Dilemma-No_Choice,Loaded_Language,Name_C...</td>\n",
       "      <td>[False_Dilemma-No_Choice, Loaded_Language, Nam...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>813452859</td>\n",
       "      <td>11</td>\n",
       "      <td>Michael Swadling: The EU withdrawal act is in ...</td>\n",
       "      <td>Conversation_Killer</td>\n",
       "      <td>[Conversation_Killer]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>813452859</td>\n",
       "      <td>12</td>\n",
       "      <td>I often use the example of an iPhone to people...</td>\n",
       "      <td>Conversation_Killer,Red_Herring</td>\n",
       "      <td>[Conversation_Killer, Red_Herring]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>813452859</td>\n",
       "      <td>15</td>\n",
       "      <td>Michael Swadling: The EU makes a profit on its...</td>\n",
       "      <td>Obfuscation-Vagueness-Confusion</td>\n",
       "      <td>[Obfuscation-Vagueness-Confusion]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  sentence_id                                           sentence  \\\n",
       "0   813452859            7  Michael Swadling: I guess her only chance is i...   \n",
       "1   813452859            9  There is a chance; as unfortunately there are ...   \n",
       "2   813452859           11  Michael Swadling: The EU withdrawal act is in ...   \n",
       "3   813452859           12  I often use the example of an iPhone to people...   \n",
       "4   813452859           15  Michael Swadling: The EU makes a profit on its...   \n",
       "\n",
       "                                persuasion_technique  \\\n",
       "0            False_Dilemma-No_Choice,Loaded_Language   \n",
       "1  False_Dilemma-No_Choice,Loaded_Language,Name_C...   \n",
       "2                                Conversation_Killer   \n",
       "3                    Conversation_Killer,Red_Herring   \n",
       "4                    Obfuscation-Vagueness-Confusion   \n",
       "\n",
       "                           persuasion_technique_list  False_Dilemma-No_Choice  \\\n",
       "0         [False_Dilemma-No_Choice, Loaded_Language]                        1   \n",
       "1  [False_Dilemma-No_Choice, Loaded_Language, Nam...                        1   \n",
       "2                              [Conversation_Killer]                        0   \n",
       "3                 [Conversation_Killer, Red_Herring]                        0   \n",
       "4                  [Obfuscation-Vagueness-Confusion]                        0   \n",
       "\n",
       "   Loaded_Language  Name_Calling-Labeling  Conversation_Killer  Red_Herring  \\\n",
       "0                1                      0                    0            0   \n",
       "1                1                      1                    0            0   \n",
       "2                0                      0                    1            0   \n",
       "3                0                      0                    1            1   \n",
       "4                0                      0                    0            0   \n",
       "\n",
       "   ...  Flag_Waving  Doubt  Whataboutism  Appeal_to_Fear-Prejudice  \\\n",
       "0  ...            0      0             0                         0   \n",
       "1  ...            0      0             0                         0   \n",
       "2  ...            0      0             0                         0   \n",
       "3  ...            0      0             0                         0   \n",
       "4  ...            0      0             0                         0   \n",
       "\n",
       "   Causal_Oversimplification  Appeal_to_Hypocrisy  Appeal_to_Popularity  \\\n",
       "0                          0                    0                     0   \n",
       "1                          0                    0                     0   \n",
       "2                          0                    0                     0   \n",
       "3                          0                    0                     0   \n",
       "4                          0                    0                     0   \n",
       "\n",
       "   Appeal_to_Authority  Straw_Man  Guilt_by_Association  \n",
       "0                    0          0                     0  \n",
       "1                    0          0                     0  \n",
       "2                    0          0                     0  \n",
       "3                    0          0                     0  \n",
       "4                    0          0                     0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the frames column into a list of frames\n",
    "df[\"persuasion_technique_list\"] = df[\"persuasion_technique\"].str.split(\",\")\n",
    "\n",
    "# create for each frame a new column with the frame as name and 1 if the frame is present in the article and 0 if not\n",
    "for frame in df[\"persuasion_technique_list\"].explode().unique():\n",
    "    df[frame] = df[\"persuasion_technique_list\"].apply(lambda x: 1 if frame in x else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"sentence\"]\n",
    "y = df.drop(columns=[\"article_id\", \"sentence_id\", \"sentence\", \"persuasion_technique\", \"persuasion_technique_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Michael Swadling: I guess her only chance is i...\n",
       "1    There is a chance; as unfortunately there are ...\n",
       "2    Michael Swadling: The EU withdrawal act is in ...\n",
       "3    I often use the example of an iPhone to people...\n",
       "4    Michael Swadling: The EU makes a profit on its...\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False_Dilemma-No_Choice</th>\n",
       "      <th>Loaded_Language</th>\n",
       "      <th>Name_Calling-Labeling</th>\n",
       "      <th>Conversation_Killer</th>\n",
       "      <th>Red_Herring</th>\n",
       "      <th>Obfuscation-Vagueness-Confusion</th>\n",
       "      <th>Exaggeration-Minimisation</th>\n",
       "      <th>Repetition</th>\n",
       "      <th>Slogans</th>\n",
       "      <th>Flag_Waving</th>\n",
       "      <th>Doubt</th>\n",
       "      <th>Whataboutism</th>\n",
       "      <th>Appeal_to_Fear-Prejudice</th>\n",
       "      <th>Causal_Oversimplification</th>\n",
       "      <th>Appeal_to_Hypocrisy</th>\n",
       "      <th>Appeal_to_Popularity</th>\n",
       "      <th>Appeal_to_Authority</th>\n",
       "      <th>Straw_Man</th>\n",
       "      <th>Guilt_by_Association</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   False_Dilemma-No_Choice  Loaded_Language  Name_Calling-Labeling  \\\n",
       "0                        1                1                      0   \n",
       "1                        1                1                      1   \n",
       "2                        0                0                      0   \n",
       "3                        0                0                      0   \n",
       "4                        0                0                      0   \n",
       "\n",
       "   Conversation_Killer  Red_Herring  Obfuscation-Vagueness-Confusion  \\\n",
       "0                    0            0                                0   \n",
       "1                    0            0                                0   \n",
       "2                    1            0                                0   \n",
       "3                    1            1                                0   \n",
       "4                    0            0                                1   \n",
       "\n",
       "   Exaggeration-Minimisation  Repetition  Slogans  Flag_Waving  Doubt  \\\n",
       "0                          0           0        0            0      0   \n",
       "1                          0           0        0            0      0   \n",
       "2                          0           0        0            0      0   \n",
       "3                          0           0        0            0      0   \n",
       "4                          0           0        0            0      0   \n",
       "\n",
       "   Whataboutism  Appeal_to_Fear-Prejudice  Causal_Oversimplification  \\\n",
       "0             0                         0                          0   \n",
       "1             0                         0                          0   \n",
       "2             0                         0                          0   \n",
       "3             0                         0                          0   \n",
       "4             0                         0                          0   \n",
       "\n",
       "   Appeal_to_Hypocrisy  Appeal_to_Popularity  Appeal_to_Authority  Straw_Man  \\\n",
       "0                    0                     0                    0          0   \n",
       "1                    0                     0                    0          0   \n",
       "2                    0                     0                    0          0   \n",
       "3                    0                     0                    0          0   \n",
       "4                    0                     0                    0          0   \n",
       "\n",
       "   Guilt_by_Association  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 1120)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\elias\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] Die angegebene Prozedur wurde nicht gefunden\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\elias\\AppData\\Local\\Temp\\tmpt9i9kftq\\config.json as plain json\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "from allennlp_models.structured_prediction.models import srl_bert\n",
    "\n",
    "# Load the SRL predictor\n",
    "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def extract_srl_components(article, predictor):\n",
    "    \"\"\"\n",
    "    Extract SRL components for an article.\n",
    "    \"\"\"\n",
    "    srl = predictor.predict(sentence=article)\n",
    "    \n",
    "    extracted_data = []\n",
    "    for verb_entry in srl['verbs']:\n",
    "        predicate = verb_entry['verb']\n",
    "        tags = verb_entry['tags']\n",
    "        \n",
    "        arg0_indices = [i for i, tag in enumerate(tags) if tag in ['B-ARG0', 'I-ARG0']]\n",
    "        arg1_indices = [i for i, tag in enumerate(tags) if tag in ['B-ARG1', 'I-ARG1']]\n",
    "        \n",
    "        arg0 = [srl['words'][i] for i in arg0_indices] if arg0_indices else []\n",
    "        arg1 = [srl['words'][i] for i in arg1_indices] if arg1_indices else []\n",
    "        \n",
    "        extracted_data.append({\n",
    "            'predicate': [predicate],\n",
    "            'ARG0': arg0,\n",
    "            'ARG1': arg1\n",
    "        })\n",
    "        \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'predicate': ['turned'], 'ARG0': [], 'ARG1': ['The', 'red', 'horse']},\n",
       " {'predicate': ['fought'],\n",
       "  'ARG0': ['The', 'red', 'horse'],\n",
       "  'ARG1': ['the', 'fly']}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_srl_components(\"The red horse simply turned around and fought off the fly with its tail.\", predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_srl = X.apply(lambda x: extract_srl_components(x, predictor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_srl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\elias\\OneDrive\\Dokumente\\Git\\MasterThesis\\notebooks\\friss-frameaxis-SPAN-LEVEL.ipynb Cell 14\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mX_srl.pkl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/elias/OneDrive/Dokumente/Git/MasterThesis/notebooks/friss-frameaxis-SPAN-LEVEL.ipynb#X35sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     pickle\u001b[39m.\u001b[39mdump(X_srl, f)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_srl' is not defined"
     ]
    }
   ],
   "source": [
    "# pickle X_srl to disk\n",
    "import pickle\n",
    "\n",
    "with open(\"X_srl.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X_srl, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [{'predicate': ['guess'], 'ARG0': ['I'], 'ARG1...\n",
       "1       [{'predicate': ['is'], 'ARG0': [], 'ARG1': ['a...\n",
       "2       [{'predicate': ['is'], 'ARG0': [], 'ARG1': ['T...\n",
       "3       [{'predicate': ['use'], 'ARG0': ['I'], 'ARG1':...\n",
       "4       [{'predicate': ['makes'], 'ARG0': ['The', 'EU'...\n",
       "                              ...                        \n",
       "1115    [{'predicate': ['do'], 'ARG0': [], 'ARG1': []}...\n",
       "1116    [{'predicate': ['are'], 'ARG0': [], 'ARG1': ['...\n",
       "1117    [{'predicate': ['added'], 'ARG0': ['Trump', 'J...\n",
       "1118    [{'predicate': ['seen'], 'ARG0': [], 'ARG1': [...\n",
       "1119    [{'predicate': ['came'], 'ARG0': [], 'ARG1': [...\n",
       "Name: sentence, Length: 1120, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_srl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_word_embedding(word):\n",
    "    \"\"\"\n",
    "    Get the BERT embedding for a given word.\n",
    "    \n",
    "    Args:\n",
    "    - word (str): The input word.\n",
    "    \n",
    "    Returns:\n",
    "    - torch.Tensor: The BERT embedding for the word.\n",
    "    \"\"\"\n",
    "    # Tokenize the word and get the corresponding IDs\n",
    "    tokens = tokenizer.tokenize(word)\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    \n",
    "    # Convert token IDs to a torch tensor and add batch dimension\n",
    "    token_tensor = torch.tensor([token_ids])\n",
    "    \n",
    "    # Forward pass through the BERT model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(token_tensor)\n",
    "        embeddings = outputs.last_hidden_state\n",
    "    \n",
    "    # If the word was split into multiple tokens, average their embeddings\n",
    "    embedding = embeddings.mean(dim=1)\n",
    "    \n",
    "    return embedding.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "max_articles = len(X_srl)\n",
    "embedding_dim = 768\n",
    "\n",
    "max_srls = 10\n",
    "max_words = 10\n",
    "\n",
    "# Pre-allocate tensors\n",
    "predicates_tensor = torch.zeros((max_articles, max_srls, embedding_dim))\n",
    "arg0_tensor = torch.zeros((max_articles, max_srls, max_words, embedding_dim))\n",
    "arg1_tensor = torch.zeros((max_articles, max_srls, max_words, embedding_dim))\n",
    "\n",
    "for i, article_srls in enumerate(X_srl[:100]):\n",
    "    for j, srl_dict in enumerate(article_srls[:max_srls]):\n",
    "        # Handle predicate\n",
    "        predicates_tensor[i, j] = get_word_embedding(srl_dict['predicate'][0])\n",
    "        \n",
    "        # Handle ARG0\n",
    "        if srl_dict['ARG0']:\n",
    "            arg0_embeddings = torch.stack([get_word_embedding(word) for word in srl_dict['ARG0'][:max_words]])\n",
    "            arg0_tensor[i, j, :arg0_embeddings.shape[0]] = arg0_embeddings\n",
    "        \n",
    "        # Handle ARG1\n",
    "        if srl_dict['ARG1']:\n",
    "            arg1_embeddings = torch.stack([get_word_embedding(word) for word in srl_dict['ARG1'][:max_words]])\n",
    "            arg1_tensor[i, j, :arg1_embeddings.shape[0]] = arg1_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1120, 10, 768]),\n",
       " torch.Size([1120, 10, 10, 768]),\n",
       " torch.Size([1120, 10, 10, 768]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicates_tensor.shape, arg0_tensor.shape, arg1_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SRLAutoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=384, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=384, out_features=192, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=192, out_features=384, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=384, out_features=768, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define the Autoencoder for SRL embeddings\n",
    "class SRLAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(SRLAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, encoding_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(encoding_dim, encoding_dim//2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim//2, encoding_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(encoding_dim, input_dim),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the SRL autoencoder\n",
    "input_dim = 768  # Embedding dimension\n",
    "encoding_dim = 384  # Reduced dimension after encoding\n",
    "srl_autoencoder = SRLAutoencoder(input_dim, encoding_dim)\n",
    "\n",
    "srl_autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointClassifierModel(nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_labels=19, hidden_dropout_prob=0.1, encoding_dim=384):\n",
    "        super(JointClassifierModel, self).__init__()\n",
    "        \n",
    "        # RoBERTa Model for sentence embeddings (assuming it will be loaded separately)\n",
    "        self.roberta = None\n",
    "        \n",
    "        # SRL Autoencoder\n",
    "        self.srl_autoencoder = SRLAutoencoder(input_dim=hidden_size, encoding_dim=encoding_dim)\n",
    "        \n",
    "        # Classifier Head\n",
    "        self.classifier_head_dim = hidden_size + encoding_dim*4  # Adding encoding_dim for predicate, arg0, and arg1\n",
    "        self.classifier = nn.Linear(hidden_size*4, num_labels)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(hidden_dropout_prob)\n",
    "        \n",
    "        # Softmax layer (if you're using it for multi-class classification)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        # Loss for multi-label classification\n",
    "        self.loss_fct = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor, labels=None):\n",
    "        # Assuming the RoBERTa model is loaded and available\n",
    "        outputs = self.roberta(input_ids, attention_mask=attention_mask)\n",
    "        sentence_embeddings = outputs[0][:, 0, :]  # Extracting the CLS token embeddings\n",
    "        \n",
    "        # Averaging SRL embeddings over the word dimension\n",
    "        avg_predicates = predicates_tensor.mean(dim=1)\n",
    "        avg_arg0 = arg0_tensor.mean(dim=2)\n",
    "        avg_arg1 = arg1_tensor.mean(dim=2)\n",
    "        \n",
    "        # Pass SRL embeddings through the autoencoder to get encoded representations\n",
    "        encoded_predicates = self.srl_autoencoder(avg_predicates)\n",
    "        encoded_arg0 = self.srl_autoencoder(avg_arg0)\n",
    "        encoded_arg1 = self.srl_autoencoder(avg_arg1)\n",
    "        \n",
    "        encoded_arg0 = encoded_arg0.mean(dim=1)\n",
    "        encoded_arg1 = encoded_arg1.mean(dim=1)\n",
    "\n",
    "        # Concatenate encoded SRL representations with sentence embeddings\n",
    "        joint_representation = self.dropout(torch.cat([sentence_embeddings, encoded_predicates, encoded_arg0, encoded_arg1], dim=1))\n",
    "        \n",
    "        # Pass through classifier\n",
    "        logits = self.classifier(joint_representation)\n",
    "        \n",
    "        # Compute Loss\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fct(logits, labels.float())\n",
    "            return loss, logits\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from transformers import RobertaModel\n",
    "\n",
    "def train_joint_model(train_dataloader, validation_dataloader=None, epochs=3, learning_rate=3e-4):\n",
    "    # Initializing the model\n",
    "    model = JointClassifierModel(hidden_size=768, num_labels=len(y.columns), hidden_dropout_prob=0.1)\n",
    "    model.roberta = RobertaModel.from_pretrained('roberta-base')  # Load the RoBERTa model\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Define the optimizer\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in train_dataloader:\n",
    "            # Assuming batch is a tuple (input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor, labels)\n",
    "            input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor, labels = batch\n",
    "            input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor, labels = \\\n",
    "                input_ids.to(device), attention_mask.to(device), predicates_tensor.to(device), \\\n",
    "                arg0_tensor.to(device), arg1_tensor.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            loss, logits = model(input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {total_loss/len(train_dataloader)}\")\n",
    "        \n",
    "        # Validation loop (optional)\n",
    "        if validation_dataloader:\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for batch in validation_dataloader:\n",
    "                    input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor, labels = batch\n",
    "                    input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor, labels = \\\n",
    "                        input_ids.to(device), attention_mask.to(device), predicates_tensor.to(device), \\\n",
    "                        arg0_tensor.to(device), arg1_tensor.to(device), labels.to(device)\n",
    "                    \n",
    "                    loss, _ = model(input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor, labels)\n",
    "                    val_loss += loss.item()\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Validation Loss: {val_loss/len(validation_dataloader)}\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "\n",
    "class PersuasionTechniqueDataset(Dataset):\n",
    "    def __init__(self, sentences, predicates, arg0, arg1, labels, tokenizer):\n",
    "        self.sentences = sentences.tolist() if isinstance(sentences, pd.Series) else sentences\n",
    "        self.predicates = predicates\n",
    "        self.arg0 = arg0\n",
    "        self.arg1 = arg1\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Tokenize the sentence\n",
    "        encoded_sentence = self.tokenizer.encode_plus(\n",
    "            self.sentences[idx], add_special_tokens=True, max_length=256,\n",
    "            padding='max_length', return_tensors='pt', truncation=True\n",
    "        )\n",
    "        input_ids = encoded_sentence['input_ids'].squeeze()\n",
    "        attention_mask = encoded_sentence['attention_mask'].squeeze()\n",
    "\n",
    "        # Get SRL tensors\n",
    "        predicate_tensor = self.predicates[idx]\n",
    "        arg0_tensor = self.arg0[idx]\n",
    "        arg1_tensor = self.arg1[idx]\n",
    "\n",
    "        # Get labels\n",
    "        label = torch.tensor(self.labels.iloc[idx])\n",
    "\n",
    "        return input_ids, attention_mask, predicate_tensor, arg0_tensor, arg1_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your data is loaded into the variables: X, predicates_tensor, arg0_tensor, arg1_tensor, and y\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test by default)\n",
    "X_train, X_test, predicates_train, predicates_test, arg0_train, arg0_test, arg1_train, arg1_test, y_train, y_test = \\\n",
    "    train_test_split(X, predicates_tensor, arg0_tensor, arg1_tensor, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Create datasets for training and testing sets\n",
    "train_dataset = PersuasionTechniqueDataset(X_train, predicates_train, arg0_train, arg1_train, y_train, tokenizer)\n",
    "test_dataset = PersuasionTechniqueDataset(X_test, predicates_test, arg0_test, arg1_test, y_test, tokenizer)\n",
    "\n",
    "# Create dataloaders for training and testing sets\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=8)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=8)\n",
    "\n",
    "del X_train, X_test, predicates_train, predicates_test, arg0_train, arg0_test, arg1_train, arg1_test, y_train, y_test\n",
    "del arg0_tensor, arg1_tensor, predicates_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 384\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\elias\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\modeling_utils.py\", line 461, in load_state_dict\n",
      "    return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\serialization.py\", line 815, in load\n",
      "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\serialization.py\", line 1043, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\serialization.py\", line 975, in persistent_load\n",
      "    obj = cast(Storage, torch.UntypedStorage(nbytes))\n",
      "RuntimeError: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 9437184 bytes.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_11440\\1934149134.py\", line 2, in <module>\n",
      "    trained_model = train_joint_model(train_loader, epochs=3, learning_rate=3e-4)\n",
      "  File \"C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_11440\\2126430760.py\", line 8, in train_joint_model\n",
      "    model.roberta = RobertaModel.from_pretrained('roberta-base')  # Load the RoBERTa model\n",
      "  File \"C:\\Users\\elias\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\modeling_utils.py\", line 2132, in from_pretrained\n",
      "    state_dict = load_state_dict(resolved_archive_file)\n",
      "  File \"C:\\Users\\elias\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\modeling_utils.py\", line 465, in load_state_dict\n",
      "    if f.read().startswith(\"version\"):\n",
      "MemoryError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 969, in format_record\n",
      "    _format_traceback_lines(\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 215, in _format_traceback_lines\n",
      "    line = stack_line.render(pygmented=has_colors).rstrip('\\n') + '\\n'\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\stack_data\\core.py\", line 360, in render\n",
      "    start_line, lines = self.frame_info._pygmented_scope_lines\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\stack_data\\core.py\", line 780, in _pygmented_scope_lines\n",
      "    lines = _pygmented_with_ranges(formatter, code, ranges)\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\stack_data\\utils.py\", line 165, in _pygmented_with_ranges\n",
      "    return pygments.highlight(code, lexer, formatter).splitlines()\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\pygments\\__init__.py\", line 82, in highlight\n",
      "    return format(lex(code, lexer), formatter, outfile)\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\pygments\\__init__.py\", line 64, in format\n",
      "    formatter.format(tokens, realoutfile)\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\pygments\\formatters\\terminal256.py\", line 250, in format\n",
      "    return Formatter.format(self, tokensource, outfile)\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\pygments\\formatter.py\", line 124, in format\n",
      "    return self.format_unencoded(tokensource, outfile)\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\pygments\\formatters\\terminal256.py\", line 256, in format_unencoded\n",
      "    for ttype, value in tokensource:\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\stack_data\\utils.py\", line 158, in get_tokens\n",
      "    for ttype, value in super().get_tokens(text):\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\pygments\\lexer.py\", line 250, in streamer\n",
      "    for _, t, v in self.get_tokens_unprocessed(text):\n",
      "  File \"c:\\Users\\elias\\anaconda3\\envs\\nlp\\lib\\site-packages\\pygments\\lexer.py\", line 693, in get_tokens_unprocessed\n",
      "    m = rexmatch(text, pos)\n",
      "MemoryError\n"
     ]
    }
   ],
   "source": [
    "# 3. Call the Training Function\n",
    "trained_model = train_joint_model(train_loader, epochs=3, learning_rate=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
=======
{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TLloI8BR92PC","executionInfo":{"status":"ok","timestamp":1696447151655,"user_tz":-120,"elapsed":1819,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}},"outputId":"ffe3f48b-b83b-4bd1-c6f3-53817e963855"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"A68Ul7IM9pIj","executionInfo":{"status":"ok","timestamp":1696447163598,"user_tz":-120,"elapsed":234,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}}},"outputs":[],"source":["import os\n","\n","os.chdir('drive/MyDrive/Git/MasterThesis/data')\n","\n","labels_path = \"data/en/dev-labels-subtask-3.txt\"\n","articles_path = \"data/en/dev-articles-subtask-3/\""]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"OYSJqTo79pIm","executionInfo":{"status":"ok","timestamp":1696447164467,"user_tz":-120,"elapsed":3,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}},"outputId":"283c6819-2e89-448f-87ad-97db5b712ade"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   article_id  sentence_id persuasion_technique\n","0   813452859            1                  NaN\n","1   813452859            3                  NaN\n","2   813452859            4                  NaN\n","3   813452859            5                  NaN\n","4   813452859            6                  NaN"],"text/html":["\n","  <div id=\"df-f16e67a2-762a-49f0-a6f1-f063a4eec542\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>article_id</th>\n","      <th>sentence_id</th>\n","      <th>persuasion_technique</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>813452859</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>813452859</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>813452859</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>813452859</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>813452859</td>\n","      <td>6</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f16e67a2-762a-49f0-a6f1-f063a4eec542')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f16e67a2-762a-49f0-a6f1-f063a4eec542 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f16e67a2-762a-49f0-a6f1-f063a4eec542');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-200b90e4-109c-4bfa-bd94-8ef672279646\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-200b90e4-109c-4bfa-bd94-8ef672279646')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-200b90e4-109c-4bfa-bd94-8ef672279646 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":10}],"source":["import pandas as pd\n","\n","# Read the dev-labels-subtask-2.txt file\n","labels_df = pd.read_csv(labels_path, sep='\\t', header=None, names=[\"article_id\", \"sentence_id\", \"persuasion_technique\"])\n","\n","labels_df.head()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"epbjw7zN9pIo","executionInfo":{"status":"ok","timestamp":1696447165818,"user_tz":-120,"elapsed":601,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}},"outputId":"72a3dd03-43cd-454d-aa90-ea7493ead7c7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   article_id  sentence_id                                           sentence  \\\n","0   813452859            7  Michael Swadling: I guess her only chance is i...   \n","1   813452859            9  There is a chance; as unfortunately there are ...   \n","2   813452859           11  Michael Swadling: The EU withdrawal act is in ...   \n","3   813452859           12  I often use the example of an iPhone to people...   \n","4   813452859           15  Michael Swadling: The EU makes a profit on its...   \n","\n","                                persuasion_technique  \n","0            False_Dilemma-No_Choice,Loaded_Language  \n","1  False_Dilemma-No_Choice,Loaded_Language,Name_C...  \n","2                                Conversation_Killer  \n","3                    Conversation_Killer,Red_Herring  \n","4                    Obfuscation-Vagueness-Confusion  "],"text/html":["\n","  <div id=\"df-60b931b1-bcc1-4028-bbac-bf6081771a8e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>article_id</th>\n","      <th>sentence_id</th>\n","      <th>sentence</th>\n","      <th>persuasion_technique</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>813452859</td>\n","      <td>7</td>\n","      <td>Michael Swadling: I guess her only chance is i...</td>\n","      <td>False_Dilemma-No_Choice,Loaded_Language</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>813452859</td>\n","      <td>9</td>\n","      <td>There is a chance; as unfortunately there are ...</td>\n","      <td>False_Dilemma-No_Choice,Loaded_Language,Name_C...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>813452859</td>\n","      <td>11</td>\n","      <td>Michael Swadling: The EU withdrawal act is in ...</td>\n","      <td>Conversation_Killer</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>813452859</td>\n","      <td>12</td>\n","      <td>I often use the example of an iPhone to people...</td>\n","      <td>Conversation_Killer,Red_Herring</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>813452859</td>\n","      <td>15</td>\n","      <td>Michael Swadling: The EU makes a profit on its...</td>\n","      <td>Obfuscation-Vagueness-Confusion</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60b931b1-bcc1-4028-bbac-bf6081771a8e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-60b931b1-bcc1-4028-bbac-bf6081771a8e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-60b931b1-bcc1-4028-bbac-bf6081771a8e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-be7a4ef1-87c5-4223-a744-3aad9489cb61\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-be7a4ef1-87c5-4223-a744-3aad9489cb61')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-be7a4ef1-87c5-4223-a744-3aad9489cb61 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":11}],"source":["# Get unique article IDs from the dev-labels data\n","unique_article_ids = labels_df['article_id'].unique()\n","\n","# Initialize an empty list to store results\n","results = []\n","\n","# For each unique article ID, read the corresponding article file and join with the dev-labels data\n","for article_id in unique_article_ids:\n","    # Construct the file path for the article\n","    file_path = f\"{articles_path}/article{article_id}.txt\"\n","\n","    try:\n","        # Load the article file\n","        with open(file_path, 'r') as file:\n","            # Read the article sentences into a list\n","            sentences = file.readlines()\n","\n","        # Filter dev-labels data for the current article_id and where persuasion_technique is not NaN\n","        relevant_rows = labels_df[(labels_df['article_id'] == article_id) & (~labels_df['persuasion_technique'].isna())]\n","\n","        # For each relevant row, get the corresponding sentence and persuasion technique and append to the results list\n","        for _, row in relevant_rows.iterrows():\n","            sentence = sentences[row['sentence_id'] - 1].strip()  # Subtracting 1 because list indexing starts from 0\n","            technique = row['persuasion_technique']\n","            results.append([article_id, row['sentence_id'], sentence, technique])\n","\n","    except FileNotFoundError:\n","        # If the file for an article_id doesn't exist, continue to the next one\n","        continue\n","\n","# Convert the results list to a dataframe\n","df = pd.DataFrame(results, columns=['article_id', 'sentence_id', 'sentence', 'persuasion_technique'])\n","\n","df.head()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":585},"id":"d0EwfJ2g9pIp","executionInfo":{"status":"ok","timestamp":1696447167117,"user_tz":-120,"elapsed":348,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}},"outputId":"38b14929-ebdf-4686-c8d9-7b18a6b053c7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   article_id  sentence_id                                           sentence  \\\n","0   813452859            7  Michael Swadling: I guess her only chance is i...   \n","1   813452859            9  There is a chance; as unfortunately there are ...   \n","2   813452859           11  Michael Swadling: The EU withdrawal act is in ...   \n","3   813452859           12  I often use the example of an iPhone to people...   \n","4   813452859           15  Michael Swadling: The EU makes a profit on its...   \n","\n","                                persuasion_technique  \\\n","0            False_Dilemma-No_Choice,Loaded_Language   \n","1  False_Dilemma-No_Choice,Loaded_Language,Name_C...   \n","2                                Conversation_Killer   \n","3                    Conversation_Killer,Red_Herring   \n","4                    Obfuscation-Vagueness-Confusion   \n","\n","                           persuasion_technique_list  False_Dilemma-No_Choice  \\\n","0         [False_Dilemma-No_Choice, Loaded_Language]                        1   \n","1  [False_Dilemma-No_Choice, Loaded_Language, Nam...                        1   \n","2                              [Conversation_Killer]                        0   \n","3                 [Conversation_Killer, Red_Herring]                        0   \n","4                  [Obfuscation-Vagueness-Confusion]                        0   \n","\n","   Loaded_Language  Name_Calling-Labeling  Conversation_Killer  Red_Herring  \\\n","0                1                      0                    0            0   \n","1                1                      1                    0            0   \n","2                0                      0                    1            0   \n","3                0                      0                    1            1   \n","4                0                      0                    0            0   \n","\n","   ...  Flag_Waving  Doubt  Whataboutism  Appeal_to_Fear-Prejudice  \\\n","0  ...            0      0             0                         0   \n","1  ...            0      0             0                         0   \n","2  ...            0      0             0                         0   \n","3  ...            0      0             0                         0   \n","4  ...            0      0             0                         0   \n","\n","   Causal_Oversimplification  Appeal_to_Hypocrisy  Appeal_to_Popularity  \\\n","0                          0                    0                     0   \n","1                          0                    0                     0   \n","2                          0                    0                     0   \n","3                          0                    0                     0   \n","4                          0                    0                     0   \n","\n","   Appeal_to_Authority  Straw_Man  Guilt_by_Association  \n","0                    0          0                     0  \n","1                    0          0                     0  \n","2                    0          0                     0  \n","3                    0          0                     0  \n","4                    0          0                     0  \n","\n","[5 rows x 24 columns]"],"text/html":["\n","  <div id=\"df-c38ea6b5-f53b-4e7a-b75b-7ab92b109873\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>article_id</th>\n","      <th>sentence_id</th>\n","      <th>sentence</th>\n","      <th>persuasion_technique</th>\n","      <th>persuasion_technique_list</th>\n","      <th>False_Dilemma-No_Choice</th>\n","      <th>Loaded_Language</th>\n","      <th>Name_Calling-Labeling</th>\n","      <th>Conversation_Killer</th>\n","      <th>Red_Herring</th>\n","      <th>...</th>\n","      <th>Flag_Waving</th>\n","      <th>Doubt</th>\n","      <th>Whataboutism</th>\n","      <th>Appeal_to_Fear-Prejudice</th>\n","      <th>Causal_Oversimplification</th>\n","      <th>Appeal_to_Hypocrisy</th>\n","      <th>Appeal_to_Popularity</th>\n","      <th>Appeal_to_Authority</th>\n","      <th>Straw_Man</th>\n","      <th>Guilt_by_Association</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>813452859</td>\n","      <td>7</td>\n","      <td>Michael Swadling: I guess her only chance is i...</td>\n","      <td>False_Dilemma-No_Choice,Loaded_Language</td>\n","      <td>[False_Dilemma-No_Choice, Loaded_Language]</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>813452859</td>\n","      <td>9</td>\n","      <td>There is a chance; as unfortunately there are ...</td>\n","      <td>False_Dilemma-No_Choice,Loaded_Language,Name_C...</td>\n","      <td>[False_Dilemma-No_Choice, Loaded_Language, Nam...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>813452859</td>\n","      <td>11</td>\n","      <td>Michael Swadling: The EU withdrawal act is in ...</td>\n","      <td>Conversation_Killer</td>\n","      <td>[Conversation_Killer]</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>813452859</td>\n","      <td>12</td>\n","      <td>I often use the example of an iPhone to people...</td>\n","      <td>Conversation_Killer,Red_Herring</td>\n","      <td>[Conversation_Killer, Red_Herring]</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>813452859</td>\n","      <td>15</td>\n","      <td>Michael Swadling: The EU makes a profit on its...</td>\n","      <td>Obfuscation-Vagueness-Confusion</td>\n","      <td>[Obfuscation-Vagueness-Confusion]</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 24 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c38ea6b5-f53b-4e7a-b75b-7ab92b109873')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c38ea6b5-f53b-4e7a-b75b-7ab92b109873 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c38ea6b5-f53b-4e7a-b75b-7ab92b109873');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-8689ed6c-7c01-4fd6-82ea-51a14a054221\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8689ed6c-7c01-4fd6-82ea-51a14a054221')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-8689ed6c-7c01-4fd6-82ea-51a14a054221 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":12}],"source":["# Split the frames column into a list of frames\n","df[\"persuasion_technique_list\"] = df[\"persuasion_technique\"].str.split(\",\")\n","\n","# create for each frame a new column with the frame as name and 1 if the frame is present in the article and 0 if not\n","for frame in df[\"persuasion_technique_list\"].explode().unique():\n","    df[frame] = df[\"persuasion_technique_list\"].apply(lambda x: 1 if frame in x else 0)\n","\n","df.head()"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"CmVgh6X79pIp","executionInfo":{"status":"ok","timestamp":1696447168276,"user_tz":-120,"elapsed":327,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}}},"outputs":[],"source":["X = df[\"sentence\"]\n","y = df.drop(columns=[\"article_id\", \"sentence_id\", \"sentence\", \"persuasion_technique\", \"persuasion_technique_list\"])"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dXwQsumL9pIq","executionInfo":{"status":"ok","timestamp":1696447169259,"user_tz":-120,"elapsed":2,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}},"outputId":"87fc36b7-751d-40f2-b454-a40f5394b485"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    Michael Swadling: I guess her only chance is i...\n","1    There is a chance; as unfortunately there are ...\n","2    Michael Swadling: The EU withdrawal act is in ...\n","3    I often use the example of an iPhone to people...\n","4    Michael Swadling: The EU makes a profit on its...\n","Name: sentence, dtype: object"]},"metadata":{},"execution_count":14}],"source":["X.head()"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":261},"id":"_wPDj5R19pIq","executionInfo":{"status":"ok","timestamp":1696447169974,"user_tz":-120,"elapsed":4,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}},"outputId":"163428ae-366a-41e9-8090-6c3fb8da8011"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   False_Dilemma-No_Choice  Loaded_Language  Name_Calling-Labeling  \\\n","0                        1                1                      0   \n","1                        1                1                      1   \n","2                        0                0                      0   \n","3                        0                0                      0   \n","4                        0                0                      0   \n","\n","   Conversation_Killer  Red_Herring  Obfuscation-Vagueness-Confusion  \\\n","0                    0            0                                0   \n","1                    0            0                                0   \n","2                    1            0                                0   \n","3                    1            1                                0   \n","4                    0            0                                1   \n","\n","   Exaggeration-Minimisation  Repetition  Slogans  Flag_Waving  Doubt  \\\n","0                          0           0        0            0      0   \n","1                          0           0        0            0      0   \n","2                          0           0        0            0      0   \n","3                          0           0        0            0      0   \n","4                          0           0        0            0      0   \n","\n","   Whataboutism  Appeal_to_Fear-Prejudice  Causal_Oversimplification  \\\n","0             0                         0                          0   \n","1             0                         0                          0   \n","2             0                         0                          0   \n","3             0                         0                          0   \n","4             0                         0                          0   \n","\n","   Appeal_to_Hypocrisy  Appeal_to_Popularity  Appeal_to_Authority  Straw_Man  \\\n","0                    0                     0                    0          0   \n","1                    0                     0                    0          0   \n","2                    0                     0                    0          0   \n","3                    0                     0                    0          0   \n","4                    0                     0                    0          0   \n","\n","   Guilt_by_Association  \n","0                     0  \n","1                     0  \n","2                     0  \n","3                     0  \n","4                     0  "],"text/html":["\n","  <div id=\"df-f63bdb27-48f5-44b4-8c61-713d52825d0f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>False_Dilemma-No_Choice</th>\n","      <th>Loaded_Language</th>\n","      <th>Name_Calling-Labeling</th>\n","      <th>Conversation_Killer</th>\n","      <th>Red_Herring</th>\n","      <th>Obfuscation-Vagueness-Confusion</th>\n","      <th>Exaggeration-Minimisation</th>\n","      <th>Repetition</th>\n","      <th>Slogans</th>\n","      <th>Flag_Waving</th>\n","      <th>Doubt</th>\n","      <th>Whataboutism</th>\n","      <th>Appeal_to_Fear-Prejudice</th>\n","      <th>Causal_Oversimplification</th>\n","      <th>Appeal_to_Hypocrisy</th>\n","      <th>Appeal_to_Popularity</th>\n","      <th>Appeal_to_Authority</th>\n","      <th>Straw_Man</th>\n","      <th>Guilt_by_Association</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f63bdb27-48f5-44b4-8c61-713d52825d0f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f63bdb27-48f5-44b4-8c61-713d52825d0f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f63bdb27-48f5-44b4-8c61-713d52825d0f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-78c460f7-0fa3-416c-9e76-66119772b98c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-78c460f7-0fa3-416c-9e76-66119772b98c')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-78c460f7-0fa3-416c-9e76-66119772b98c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":15}],"source":["y.head()"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YtBjBN1L9pIq","executionInfo":{"status":"ok","timestamp":1696447171816,"user_tz":-120,"elapsed":234,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}},"outputId":"1e149c72-7065-40e9-d5d7-e78bed9f6f7f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1120, 1120)"]},"metadata":{},"execution_count":16}],"source":["len(X), len(y)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"wcVRMe7Z9pIr","executionInfo":{"status":"ok","timestamp":1696447172833,"user_tz":-120,"elapsed":343,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}}},"outputs":[],"source":["import torch\n","# Define the device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["!pip install allennlp_models"],"metadata":{"id":"ahes0PZf-0Pb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install spacy==3.6.0\n"],"metadata":{"id":"HUHBJ7lUAyEh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n5CLw4gD9pIr","executionInfo":{"status":"ok","timestamp":1696447116949,"user_tz":-120,"elapsed":32667,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}},"outputId":"aac79e19-5f68-4223-cdeb-f1f50213a6e8"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["from allennlp.predictors.predictor import Predictor\n","from allennlp_models.structured_prediction.models import srl_bert\n","\n","# Load the SRL predictor\n","predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"yH-v-Fz19pIr","executionInfo":{"status":"ok","timestamp":1696447122030,"user_tz":-120,"elapsed":224,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}}},"outputs":[],"source":["import random\n","\n","def extract_srl_components(article, predictor):\n","    \"\"\"\n","    Extract SRL components for an article.\n","    \"\"\"\n","    srl = predictor.predict(sentence=article)\n","\n","    extracted_data = []\n","    for verb_entry in srl['verbs']:\n","        predicate = verb_entry['verb']\n","        tags = verb_entry['tags']\n","\n","        arg0_indices = [i for i, tag in enumerate(tags) if tag in ['B-ARG0', 'I-ARG0']]\n","        arg1_indices = [i for i, tag in enumerate(tags) if tag in ['B-ARG1', 'I-ARG1']]\n","\n","        arg0 = [srl['words'][i] for i in arg0_indices] if arg0_indices else []\n","        arg1 = [srl['words'][i] for i in arg1_indices] if arg1_indices else []\n","\n","        extracted_data.append({\n","            'predicate': [predicate],\n","            'ARG0': arg0,\n","            'ARG1': arg1\n","        })\n","\n","    return extracted_data"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ihBUSW_9pIr","executionInfo":{"status":"ok","timestamp":1696447131735,"user_tz":-120,"elapsed":590,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}},"outputId":"3a3e96cd-8fbc-48e1-a70f-405648113def"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'predicate': ['turned'], 'ARG0': [], 'ARG1': ['The', 'red', 'horse']},\n"," {'predicate': ['fought'],\n","  'ARG0': ['The', 'red', 'horse'],\n","  'ARG1': ['the', 'fly']}]"]},"metadata":{},"execution_count":4}],"source":["extract_srl_components(\"The red horse simply turned around and fought off the fly with its tail.\", predictor)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"ZxASceMo9pIr","executionInfo":{"status":"ok","timestamp":1696448103191,"user_tz":-120,"elapsed":920123,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}}},"outputs":[],"source":["X_srl = X.apply(lambda x: extract_srl_components(x, predictor))"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BTv8VAXv9pIs","executionInfo":{"status":"ok","timestamp":1696448103191,"user_tz":-120,"elapsed":11,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}},"outputId":"75bf22a5-6a59-4d8b-dea4-b4742b874078"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       [{'predicate': ['guess'], 'ARG0': ['I'], 'ARG1...\n","1       [{'predicate': ['is'], 'ARG0': [], 'ARG1': ['a...\n","2       [{'predicate': ['is'], 'ARG0': [], 'ARG1': ['T...\n","3       [{'predicate': ['use'], 'ARG0': ['I'], 'ARG1':...\n","4       [{'predicate': ['makes'], 'ARG0': ['The', 'EU'...\n","                              ...                        \n","1115    [{'predicate': ['do'], 'ARG0': [], 'ARG1': []}...\n","1116    [{'predicate': ['are'], 'ARG0': [], 'ARG1': ['...\n","1117    [{'predicate': ['added'], 'ARG0': ['Trump', 'J...\n","1118    [{'predicate': ['seen'], 'ARG0': [], 'ARG1': [...\n","1119    [{'predicate': ['came'], 'ARG0': [], 'ARG1': [...\n","Name: sentence, Length: 1120, dtype: object"]},"metadata":{},"execution_count":19}],"source":["X_srl"]},{"cell_type":"code","source":["# pickle X_srl to disk\n","import pickle\n","\n","with open(\"X_srl.pkl\", \"wb\") as f:\n","    pickle.dump(X_srl, f)"],"metadata":{"id":"17P7XDO8MmAx","executionInfo":{"status":"ok","timestamp":1696448278317,"user_tz":-120,"elapsed":2,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["X_srl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ge0yJaBuX579","executionInfo":{"status":"ok","timestamp":1696451246213,"user_tz":-120,"elapsed":333,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}},"outputId":"27837636-1b79-4dcf-f9c5-99f4058d57d4"},"execution_count":151,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       [{'predicate': ['guess'], 'ARG0': ['I'], 'ARG1...\n","1       [{'predicate': ['is'], 'ARG0': [], 'ARG1': ['a...\n","2       [{'predicate': ['is'], 'ARG0': [], 'ARG1': ['T...\n","3       [{'predicate': ['use'], 'ARG0': ['I'], 'ARG1':...\n","4       [{'predicate': ['makes'], 'ARG0': ['The', 'EU'...\n","                              ...                        \n","1115    [{'predicate': ['do'], 'ARG0': [], 'ARG1': []}...\n","1116    [{'predicate': ['are'], 'ARG0': [], 'ARG1': ['...\n","1117    [{'predicate': ['added'], 'ARG0': ['Trump', 'J...\n","1118    [{'predicate': ['seen'], 'ARG0': [], 'ARG1': [...\n","1119    [{'predicate': ['came'], 'ARG0': [], 'ARG1': [...\n","Name: sentence, Length: 1120, dtype: object"]},"metadata":{},"execution_count":151}]},{"cell_type":"code","execution_count":167,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SzOGKOU09pIs","executionInfo":{"status":"ok","timestamp":1696451535120,"user_tz":-120,"elapsed":5571,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}},"outputId":"0159a747-3cf5-44a3-c59b-567fab6c3968"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["import torch\n","from transformers import BertTokenizer, BertModel\n","\n","# Initialize the tokenizer and model\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-base-uncased')\n","\n","def get_word_embedding(word):\n","    \"\"\"\n","    Get the BERT embedding for a given word.\n","\n","    Args:\n","    - word (str): The input word.\n","\n","    Returns:\n","    - torch.Tensor: The BERT embedding for the word.\n","    \"\"\"\n","    # Tokenize the word and get the corresponding IDs\n","    tokens = tokenizer.tokenize(word)\n","    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","    # Convert token IDs to a torch tensor and add batch dimension\n","    token_tensor = torch.tensor([token_ids])\n","\n","    # Forward pass through the BERT model\n","    with torch.no_grad():\n","        outputs = model(token_tensor)\n","        embeddings = outputs.last_hidden_state\n","\n","    # If the word was split into multiple tokens, average their embeddings\n","    embedding = embeddings.mean(dim=1)\n","\n","    return embedding.squeeze()\n"]},{"cell_type":"code","execution_count":168,"metadata":{"id":"ZI_W_--a9pIs","executionInfo":{"status":"ok","timestamp":1696451660459,"user_tz":-120,"elapsed":125349,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}}},"outputs":[],"source":["# Parameters\n","max_articles = len(X_srl)\n","embedding_dim = 768\n","\n","max_srls = 10\n","max_words = 10\n","\n","# Pre-allocate tensors\n","predicates_tensor = torch.zeros((max_articles, max_srls, embedding_dim))\n","arg0_tensor = torch.zeros((max_articles, max_srls, max_words, embedding_dim))\n","arg1_tensor = torch.zeros((max_articles, max_srls, max_words, embedding_dim))\n","\n","for i, article_srls in enumerate(X_srl[:100]):\n","    for j, srl_dict in enumerate(article_srls[:max_srls]):\n","        # Handle predicate\n","        predicates_tensor[i, j] = get_word_embedding(srl_dict['predicate'][0])\n","\n","        # Handle ARG0\n","        if srl_dict['ARG0']:\n","            arg0_embeddings = torch.stack([get_word_embedding(word) for word in srl_dict['ARG0'][:max_words]])\n","            arg0_tensor[i, j, :arg0_embeddings.shape[0]] = arg0_embeddings\n","\n","        # Handle ARG1\n","        if srl_dict['ARG1']:\n","            arg1_embeddings = torch.stack([get_word_embedding(word) for word in srl_dict['ARG1'][:max_words]])\n","            arg1_tensor[i, j, :arg1_embeddings.shape[0]] = arg1_embeddings\n"]},{"cell_type":"code","execution_count":169,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n_I7xch79pIs","executionInfo":{"status":"ok","timestamp":1696451677398,"user_tz":-120,"elapsed":218,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}},"outputId":"15d8dc0a-e4e9-4c89-d757-d3b99f51961a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1120, 10, 768]),\n"," torch.Size([1120, 10, 10, 768]),\n"," torch.Size([1120, 10, 10, 768]))"]},"metadata":{},"execution_count":169}],"source":["predicates_tensor.shape, arg0_tensor.shape, arg1_tensor.shape"]},{"cell_type":"code","execution_count":170,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yTfyiKQT9pIs","executionInfo":{"status":"ok","timestamp":1696451678738,"user_tz":-120,"elapsed":43,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}},"outputId":"4a009914-8ef9-46e0-f26c-b8e2e8bc1625"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["SRLAutoencoder(\n","  (encoder): Sequential(\n","    (0): Linear(in_features=768, out_features=384, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Linear(in_features=384, out_features=192, bias=True)\n","    (3): ReLU(inplace=True)\n","  )\n","  (decoder): Sequential(\n","    (0): Linear(in_features=192, out_features=384, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Linear(in_features=384, out_features=768, bias=True)\n","    (3): ReLU(inplace=True)\n","  )\n",")"]},"metadata":{},"execution_count":170}],"source":["import torch.nn as nn\n","\n","# Define the Autoencoder for SRL embeddings\n","class SRLAutoencoder(nn.Module):\n","    def __init__(self, input_dim, encoding_dim):\n","        super(SRLAutoencoder, self).__init__()\n","\n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Linear(input_dim, encoding_dim),\n","            nn.ReLU(True),\n","            nn.Linear(encoding_dim, encoding_dim//2),\n","            nn.ReLU(True)\n","        )\n","\n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.Linear(encoding_dim//2, encoding_dim),\n","            nn.ReLU(True),\n","            nn.Linear(encoding_dim, input_dim),\n","            nn.ReLU(True)\n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x\n","\n","# Instantiate the SRL autoencoder\n","input_dim = 768  # Embedding dimension\n","encoding_dim = 384  # Reduced dimension after encoding\n","srl_autoencoder = SRLAutoencoder(input_dim, encoding_dim)\n","\n","srl_autoencoder\n"]},{"cell_type":"code","execution_count":171,"metadata":{"id":"VosPmqvh9pIs","executionInfo":{"status":"ok","timestamp":1696451678738,"user_tz":-120,"elapsed":42,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}}},"outputs":[],"source":["class JointClassifierModel(nn.Module):\n","    def __init__(self, hidden_size=768, num_labels=19, hidden_dropout_prob=0.1, encoding_dim=384):\n","        super(JointClassifierModel, self).__init__()\n","\n","        # RoBERTa Model for sentence embeddings (assuming it will be loaded separately)\n","        self.roberta = None\n","\n","        # SRL Autoencoder\n","        self.srl_autoencoder = SRLAutoencoder(input_dim=hidden_size, encoding_dim=encoding_dim)\n","\n","        # Classifier Head\n","        self.classifier_head_dim = hidden_size + encoding_dim*4  # Adding encoding_dim for predicate, arg0, and arg1\n","        self.classifier = nn.Linear(hidden_size*4, num_labels)\n","\n","        # Dropout layer\n","        self.dropout = nn.Dropout(hidden_dropout_prob)\n","\n","        # Softmax layer (if you're using it for multi-class classification)\n","        self.log_softmax = nn.LogSoftmax(dim=1)\n","\n","        # Loss for multi-label classification\n","        self.loss_fct = nn.BCEWithLogitsLoss()\n","\n","    def forward(self, input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor, labels=None):\n","        # Assuming the RoBERTa model is loaded and available\n","        outputs = self.roberta(input_ids, attention_mask=attention_mask)\n","        sentence_embeddings = outputs[0][:, 0, :]  # Extracting the CLS token embeddings\n","\n","        # Averaging SRL embeddings over the word dimension\n","        avg_predicates = predicates_tensor.mean(dim=1)\n","        avg_arg0 = arg0_tensor.mean(dim=2)\n","        avg_arg1 = arg1_tensor.mean(dim=2)\n","\n","        # Pass SRL embeddings through the autoencoder to get encoded representations\n","        encoded_predicates = self.srl_autoencoder(avg_predicates)\n","        encoded_arg0 = self.srl_autoencoder(avg_arg0)\n","        encoded_arg1 = self.srl_autoencoder(avg_arg1)\n","\n","        encoded_arg0 = encoded_arg0.mean(dim=1)\n","        encoded_arg1 = encoded_arg1.mean(dim=1)\n","\n","        # Concatenate encoded SRL representations with sentence embeddings\n","        joint_representation = self.dropout(torch.cat([sentence_embeddings, encoded_predicates, encoded_arg0, encoded_arg1], dim=1))\n","\n","        # Pass through classifier\n","        logits = self.classifier(joint_representation)\n","\n","        # Compute Loss\n","        if labels is not None:\n","            loss = self.loss_fct(logits, labels.float())\n","            return loss, logits\n","        return logits\n"]},{"cell_type":"markdown","metadata":{"id":"J2MMrxt69pIt"},"source":["# Train Model"]},{"cell_type":"code","execution_count":172,"metadata":{"id":"Qfgdd0GV9pIu","executionInfo":{"status":"ok","timestamp":1696451681302,"user_tz":-120,"elapsed":2,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}}},"outputs":[],"source":["import torch\n","from torch.optim import Adam\n","from transformers import RobertaModel\n","from sklearn.metrics import accuracy_score\n","\n","def train_joint_model(train_dataloader, validation_dataloader=None, epochs=3, learning_rate=3e-4):\n","    # Initializing the model\n","    model = JointClassifierModel(hidden_size=768, num_labels=len(y.columns), hidden_dropout_prob=0.1)\n","    model.roberta = RobertaModel.from_pretrained('roberta-base')  # Load the RoBERTa model\n","\n","    # Move model to GPU if available\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    # Define the optimizer\n","    optimizer = Adam(model.parameters(), lr=learning_rate)\n","\n","    # Training loop\n","    for epoch in range(epochs):\n","        model.train()\n","        total_loss = 0\n","        total_accuracy = 0\n","\n","        for batch in train_dataloader:\n","            # Assuming batch is a tuple (input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor, labels)\n","            input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor, labels = batch\n","            input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor, labels = \\\n","                input_ids.to(device), attention_mask.to(device), predicates_tensor.to(device), \\\n","                arg0_tensor.to(device), arg1_tensor.to(device), labels.to(device)\n","\n","            # Zero the gradients\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            loss, logits = model(input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor, labels)\n","\n","            # Calculate accuracy\n","            preds = (torch.sigmoid(logits) > 0.5).float()\n","            batch_accuracy = accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())\n","            total_accuracy += batch_accuracy\n","\n","            # Backward pass\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","\n","        avg_accuracy = total_accuracy / len(train_dataloader)\n","        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {total_loss/len(train_dataloader)}, Training Accuracy: {avg_accuracy}\")\n","\n","        # Validation loop (optional)\n","        if validation_dataloader:\n","            model.eval()\n","            val_loss = 0\n","            val_accuracy = 0\n","            with torch.no_grad():\n","                for batch in validation_dataloader:\n","                    input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor, labels = batch\n","                    input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor, labels = \\\n","                        input_ids.to(device), attention_mask.to(device), predicates_tensor.to(device), \\\n","                        arg0_tensor.to(device), arg1_tensor.to(device), labels.to(device)\n","\n","                    loss, logits = model(input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor, labels)\n","                    val_loss += loss.item()\n","\n","                    # Calculate validation accuracy\n","                    preds = (torch.sigmoid(logits) > 0.5).float()\n","                    batch_accuracy = accuracy_score(labels.cpu().numpy(), preds.cpu().numpy(), average='samples')\n","                    val_accuracy += batch_accuracy\n","\n","            avg_val_accuracy = val_accuracy / len(validation_dataloader)\n","            print(f\"Epoch {epoch+1}/{epochs}, Validation Loss: {val_loss/len(validation_dataloader)}, Validation Accuracy: {avg_val_accuracy}\")\n","\n","    return model"]},{"cell_type":"code","execution_count":173,"metadata":{"id":"5Gf1g92i9pIu","executionInfo":{"status":"ok","timestamp":1696451681302,"user_tz":-120,"elapsed":2,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}}},"outputs":[],"source":["from transformers import RobertaTokenizer\n","from torch.utils.data import Dataset, DataLoader, RandomSampler\n","\n","class PersuasionTechniqueDataset(Dataset):\n","    def __init__(self, sentences, predicates, arg0, arg1, labels, tokenizer):\n","        self.sentences = sentences.tolist() if isinstance(sentences, pd.Series) else sentences\n","        self.predicates = predicates\n","        self.arg0 = arg0\n","        self.arg1 = arg1\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):\n","        return len(self.sentences)\n","\n","    def __getitem__(self, idx):\n","        # Tokenize the sentence\n","        encoded_sentence = self.tokenizer.encode_plus(\n","            self.sentences[idx], add_special_tokens=True, max_length=256,\n","            padding='max_length', return_tensors='pt', truncation=True\n","        )\n","        input_ids = encoded_sentence['input_ids'].squeeze()\n","        attention_mask = encoded_sentence['attention_mask'].squeeze()\n","\n","        # Get SRL tensors\n","        predicate_tensor = self.predicates[idx]\n","        arg0_tensor = self.arg0[idx]\n","        arg1_tensor = self.arg1[idx]\n","\n","        # Get labels\n","        label = torch.tensor(self.labels.iloc[idx])\n","\n","        return input_ids, attention_mask, predicate_tensor, arg0_tensor, arg1_tensor, label"]},{"cell_type":"code","execution_count":174,"metadata":{"id":"Z_IokSZX9pIu","executionInfo":{"status":"ok","timestamp":1696451687549,"user_tz":-120,"elapsed":6248,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Assuming your data is loaded into the variables: X, predicates_tensor, arg0_tensor, arg1_tensor, and y\n","\n","# Split the data into training and testing sets (80% train, 20% test by default)\n","X_train, X_test, predicates_train, predicates_test, arg0_train, arg0_test, arg1_train, arg1_test, y_train, y_test = \\\n","    train_test_split(X, predicates_tensor, arg0_tensor, arg1_tensor, y, test_size=0.2, random_state=42)\n","\n","# Tokenizer\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","\n","# Create datasets for training and testing sets\n","train_dataset = PersuasionTechniqueDataset(X_train, predicates_train, arg0_train, arg1_train, y_train, tokenizer)\n","test_dataset = PersuasionTechniqueDataset(X_test, predicates_test, arg0_test, arg1_test, y_test, tokenizer)\n","\n","# Create dataloaders for training and testing sets\n","train_loader = DataLoader(train_dataset, shuffle=True, batch_size=8)\n","test_loader = DataLoader(test_dataset, shuffle=False, batch_size=8)\n","\n","del X_train, X_test, predicates_train, predicates_test, arg0_train, arg0_test, arg1_train, arg1_test, y_train, y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TqSVWlc29pIu","outputId":"9ef28883-fe9b-4cc4-af37-5d727ff96ae8"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Training Loss: 0.2387250852105873, Training Accuracy: 0.022321428571428572\n","Epoch 2/10, Training Loss: 0.21953473519533873, Training Accuracy: 0.03236607142857143\n","Epoch 3/10, Training Loss: 0.21777255048177072, Training Accuracy: 0.0546875\n","Epoch 4/10, Training Loss: 0.21774065906980208, Training Accuracy: 0.033482142857142856\n","Epoch 5/10, Training Loss: 0.2178434098937682, Training Accuracy: 0.0390625\n","Epoch 6/10, Training Loss: 0.2169793067233903, Training Accuracy: 0.011160714285714286\n","Epoch 7/10, Training Loss: 0.21612998417445592, Training Accuracy: 0.022321428571428572\n"]}],"source":["# 3. Call the Training Function\n","trained_model = train_joint_model(train_loader, epochs=10, learning_rate=3e-4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j1wRcWH09pIu"},"outputs":[],"source":["def predict(model, input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor, threshold=0.5):\n","    \"\"\"\n","    Predict the labels for given inputs using the provided model.\n","\n","    Args:\n","    - model (torch.nn.Module): The trained model.\n","    - input_ids (torch.Tensor): Tensor of token ids.\n","    - attention_mask (torch.Tensor): Tensor indicating which tokens are padding and which aren't.\n","    - predicates_tensor (torch.Tensor): Tensor of predicates embeddings.\n","    - arg0_tensor (torch.Tensor): Tensor of arg0 embeddings.\n","    - arg1_tensor (torch.Tensor): Tensor of arg1 embeddings.\n","    - threshold (float): Threshold for classifying logits as 0 or 1.\n","\n","    Returns:\n","    - predictions (torch.Tensor): Predicted labels for each input.\n","    \"\"\"\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    model.to(device)\n","    input_ids = input_ids.to(device)\n","    attention_mask = attention_mask.to(device)\n","    predicates_tensor = predicates_tensor.to(device)\n","    arg0_tensor = arg0_tensor.to(device)\n","    arg1_tensor = arg1_tensor.to(device)\n","\n","    # Set the model to evaluation mode\n","    model.eval()\n","\n","    # Disable gradient computation\n","    with torch.no_grad():\n","        logits = model(input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor)\n","\n","        # Convert logits to probabilities\n","        probs = torch.sigmoid(logits)\n","\n","        # Convert probabilities to binary predictions based on the threshold\n","        predictions = (probs > threshold).float()\n","\n","    return predictions"]},{"cell_type":"code","source":["# Assuming `model` is your loaded trained JointClassifierModel\n","\n","# Extracting a few samples from the test_loader\n","sample_data = next(iter(test_loader))\n","input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor, labels = sample_data\n","\n","labels.shape"],"metadata":{"id":"n2oUo3dLQ8-T","executionInfo":{"status":"aborted","timestamp":1696451460805,"user_tz":-120,"elapsed":4,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Using the predict function to get predictions\n","predictions = predict(trained_model, input_ids, attention_mask, predicates_tensor, arg0_tensor, arg1_tensor)\n","\n","# Converting tensor predictions to numpy for display\n","predictions_np = predictions.cpu().numpy()\n","\n","predictions_np.shape\n"],"metadata":{"id":"CSxTsNYAVgJ6","executionInfo":{"status":"aborted","timestamp":1696451460805,"user_tz":-120,"elapsed":4,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_np"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WWNTUuztVhAC","executionInfo":{"status":"ok","timestamp":1696450873386,"user_tz":-120,"elapsed":3,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}},"outputId":"810c0fbb-8275-4ca7-d576-b21a592f886f"},"execution_count":142,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0.]], dtype=float32)"]},"metadata":{},"execution_count":142}]},{"cell_type":"code","source":["print(f\"Allocated Memory: {torch.cuda.memory_allocated() / (1024**2)} MB\")\n","print(f\"Reserved Memory: {torch.cuda.memory_reserved() / (1024**2)} MB\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ILg9ZO6VSyG-","executionInfo":{"status":"ok","timestamp":1696450437708,"user_tz":-120,"elapsed":214,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}},"outputId":"db7387d6-1ed2-4a4e-c2db-6eb6c1b58022"},"execution_count":118,"outputs":[{"output_type":"stream","name":"stdout","text":["Allocated Memory: 973.13330078125 MB\n","Reserved Memory: 14156.0 MB\n"]}]},{"cell_type":"code","source":["def tensor_memory(tensor):\n","    return tensor.element_size() * tensor.nelement()\n","\n","print(f\"Tensor Memory Usage: {tensor_memory(arg1_embeddings) / (1024**2)} MB\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MyNv7DXgTQTU","executionInfo":{"status":"ok","timestamp":1696450328840,"user_tz":-120,"elapsed":230,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}},"outputId":"2b04acd6-dba0-4df2-c56d-2d485b0e98bb"},"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor Memory Usage: 0.005859375 MB\n"]}]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"jOF2XB5vSBYS","executionInfo":{"status":"ok","timestamp":1696450198175,"user_tz":-120,"elapsed":233,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}}},"execution_count":101,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-iZ4OamFThL6","executionInfo":{"status":"ok","timestamp":1696450435533,"user_tz":-120,"elapsed":213,"user":{"displayName":"Elias Anderlohr","userId":"15301978580987406749"}},"outputId":"ace01922-4176-4d1b-8501-a9a9078febe3"},"execution_count":117,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Oct  4 20:13:55 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   64C    P0    30W /  70W |  15085MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["import sys\n","def sizeof_fmt(num, suffix='B'):\n","    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n","    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n","        if abs(num) < 1024.0:\n","            return \"%3.1f %s%s\" % (num, unit, suffix)\n","        num /= 1024.0\n","    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n","\n","for name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n","                          locals().items())), key= lambda x: -x[1]):\n","    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"],"metadata":{"id":"axIdHd1SUvDv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Y34as64fWSnJ"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"orig_nbformat":4,"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}
>>>>>>> 354c2de65b11667dacfada1a4ce2e3e904753d02
